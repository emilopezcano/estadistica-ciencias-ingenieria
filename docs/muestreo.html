<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capítulo 8 Muestreo y estimación | Estadística Aplicada a las Ciencias y la Ingeniería</title>
<meta name="author" content="Emilio L. Cano">
<meta name="description" content="8.1 Muestreo Estadístico El muestreo estadístico es el mecanismo por el que se selecciona la muestra a partir de una población. A grandes rasgos, hay que determinar cómo se seleccionan los...">
<meta name="generator" content="bookdown 0.46 with bs4_book()">
<meta property="og:title" content="Capítulo 8 Muestreo y estimación | Estadística Aplicada a las Ciencias y la Ingeniería">
<meta property="og:type" content="book">
<meta property="og:url" content="https://emilopezcano.github.io/estadistica-ciencias-ingenieria/muestreo.html">
<meta property="og:image" content="https://emilopezcano.github.io/estadistica-ciencias-ingenieria/images/cover.png">
<meta property="og:description" content="8.1 Muestreo Estadístico El muestreo estadístico es el mecanismo por el que se selecciona la muestra a partir de una población. A grandes rasgos, hay que determinar cómo se seleccionan los...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Capítulo 8 Muestreo y estimación | Estadística Aplicada a las Ciencias y la Ingeniería">
<meta name="twitter:description" content="8.1 Muestreo Estadístico El muestreo estadístico es el mecanismo por el que se selecciona la muestra a partir de una población. A grandes rasgos, hay que determinar cómo se seleccionan los...">
<meta name="twitter:image" content="https://emilopezcano.github.io/estadistica-ciencias-ingenieria/images/cover.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet">
<script src="libs/tabwid-1.1.3/tabwid.js"></script><link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script><script src="libs/viz-1.8.2/viz.js"></script><link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">
<script src="libs/grViz-binding-1.0.11/grViz.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="bs4_book.css">
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Estadística Aplicada a las Ciencias y la Ingeniería</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Buscar" aria-label="Buscar">
</form>

      <nav aria-label="Contenido"><h2>Contenido</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Bienvenida</a></li>
<li class="book-part">Estadística descriptiva</li>
<li><a class="" href="intro.html"><span class="header-section-number">1</span> Introducción</a></li>
<li><a class="" href="aed-uni.html"><span class="header-section-number">2</span> Análisis exploratorio univariante</a></li>
<li><a class="" href="aed-bi.html"><span class="header-section-number">3</span> Análisis exploratorio bivariante</a></li>
<li class="book-part">Probabilidad</li>
<li><a class="" href="introp.html"><span class="header-section-number">4</span> Introducción a la Probabilidad</a></li>
<li><a class="" href="vauni.html"><span class="header-section-number">5</span> Variable aleatoria univariante</a></li>
<li><a class="" href="vabi.html"><span class="header-section-number">6</span> Variable aleatoria bivariante</a></li>
<li><a class="" href="modelos.html"><span class="header-section-number">7</span> Modelos de distribución de probabilidad</a></li>
<li class="book-part">Inferencia estadística</li>
<li><a class="active" href="muestreo.html"><span class="header-section-number">8</span> Muestreo y estimación</a></li>
<li><a class="" href="comparacion2.html"><span class="header-section-number">9</span> Comparación de dos grupos</a></li>
<li><a class="" href="anova.html"><span class="header-section-number">10</span> Análisis de la Varianza</a></li>
<li><a class="" href="doe.html"><span class="header-section-number">11</span> Diseño de experimentos</a></li>
<li><a class="" href="regresion.html"><span class="header-section-number">12</span> Modelos de regresión</a></li>
<li class="book-part">Control estadístico de la calidad</li>
<li><a class="" href="introc.html"><span class="header-section-number">13</span> Introducción</a></li>
<li><a class="" href="spc.html"><span class="header-section-number">14</span> Control Estadístico de Procesos</a></li>
<li><a class="" href="aceptacion.html"><span class="header-section-number">15</span> Inspección por muestreo</a></li>
<li class="book-part">Apéndices</li>
<li><a class="" href="s%C3%ADmbolos-abreviaturas-y-acr%C3%B3nimos.html"><span class="header-section-number">A</span> Símbolos, abreviaturas y acrónimos</a></li>
<li><a class="" href="formulario.html"><span class="header-section-number">B</span> Formulario</a></li>
<li><a class="" href="tablas.html"><span class="header-section-number">C</span> Tablas estadísticas</a></li>
<li><a class="" href="repaso.html"><span class="header-section-number">D</span> Repaso</a></li>
<li><a class="" href="ampliaci%C3%B3n.html"><span class="header-section-number">E</span> Ampliación</a></li>
<li><a class="" href="demostraciones.html"><span class="header-section-number">F</span> Demostraciones</a></li>
<li><a class="" href="ampliaciones.html"><span class="header-section-number">G</span> Ampliaciones</a></li>
<li><a class="" href="creditos.html"><span class="header-section-number">H</span> Créditos</a></li>
<li><a class="" href="referencias.html">Referencias</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/emilopezcano/estadistica-ciencias-ingenieria">Ver repositorio <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="muestreo" class="section level1" number="8">
<h1>
<span class="header-section-number">Capítulo 8</span> Muestreo y estimación<a class="anchor" aria-label="anchor" href="#muestreo"><i class="fas fa-link"></i></a>
</h1>
<div id="muestreo-estadístico" class="section level2" number="8.1">
<h2>
<span class="header-section-number">8.1</span> Muestreo Estadístico<a class="anchor" aria-label="anchor" href="#muestreo-estad%C3%ADstico"><i class="fas fa-link"></i></a>
</h2>
<p>El muestreo estadístico es el mecanismo por el que se selecciona la muestra a partir de una población. A grandes rasgos, hay que determinar cómo se seleccionan los elementos de la muestra y cuántos se seleccionan. Este tamaño muestral lo representamos por <span class="math inline">\(n\)</span>, y a menudo se habla de “la <span class="math inline">\(n\)</span>” del experimento (o del estudio, en general). El tamaño de la muestra lo determina la característica que queremos estudiar, que se representada por una <strong>variable aleatoria</strong>. En función del modelo de distribución de probabilidad que sigue la variable aleatoria, se determina el tamaño de la muestra.</p>
<div class="rmdcafe">
<p>Es importante diferenciar las muestras estadísticas de las muestras “biológicas” o de materiales. A veces estarán relacionadas, pero otras veces serán cosas totalmente distintas y no relacionadas.</p>
</div>
<p>El muestreo es muy importante en cualquier estudio estadístico para poder extraer
conclusiones válidas y tomar decisiones sobre la poblaciónrespaldadas por los datos. El aspecto
más importante es que tienen que ser muestras representativas de la la población.
Para asegurar esta representatividad, utilizamos métodos probabilísticos, de forma
que los sesgos (falta de representatividad) que se produzcan sean achacables
únicamente al azar, y no a otro tipo de cuestiones.</p>
<p>No siempre realizamos estudios estadísticos basados en una muestra extraída ad-hoc, sino
que analizamos datos disponibles que se han recogido o están disponibles sin
realizar un muestreo. Con estos datos podemos hacer estudios observacionales
(frente a los experimentos diseñados) siempre teniendo en cuenta que puede
haber sesgos y la muestra no represente a la población. Por otra parte,
muchas veces no es posible hacer un muestreo completamente aleatorizado,
y entonces podemos recurrir a muestreos cuasi-probabilísticos. En cualquier
caso, hay que intentar evitar a toda costa las muestras “de conveniencia”,
y plantearnos en todo momento si podemos considerar que es representativa
de la población.</p>
<div class="rmdinfo">
<p>La muestra debe <strong>representar</strong> a la población.</p>
</div>
</div>
<div id="muestreo-probabilístico" class="section level2" number="8.2">
<h2>
<span class="header-section-number">8.2</span> Muestreo probabilístico<a class="anchor" aria-label="anchor" href="#muestreo-probabil%C3%ADstico"><i class="fas fa-link"></i></a>
</h2>
<p>Entre los muestreos probabilísticos, podemos elegir entre muestreo aleatorio simple (MAS), muestreo estratificado, muestreo por conglomerados y muestreo sistemático. Salvo en este último, en los demás necesitamos una enumeración e identificación de los individuos de la población. En el muestreo sistemático, necesitamos solamente un orden.</p>
<p>El <strong>muestreo aleatorio simple</strong> es el más sencillo. Todos los elementos de la población tienen la misma probabilidad de pertenecer a la muestra. Requiere tener identificados de alguna manera a los individuos de la población, y es adecuado en poblaciones pequeñas, homogéneas, en las que no hay patrones conocidos.</p>
<div class="rmdejemplo">
<p>Se dispone del listado de depuradoras de agua de una región y se quiere estudiar alguna
característica específica de instalaciones sin hacer análisis a todas las depuradoras. Se seleccionan
al azar un número de depuradoras determinado.</p>
</div>
<p>El <strong>muestreo estratificado</strong> es más adecuado en poblaciones no homogéneas.
Se conocen grupos dentro de la población, que son diferentes entre ellos,
pero las subpoblaciones dentro de los grupos son homogéneas. Además, se
conoce algo sobre la distribución de la característica en cada grupo.
Entonces se obtiene una muestra aleatoria de cada uno de los grupos (estratos).
Este tipo de muestreo no es apropiado en poblaciones pequeñas.</p>
<div class="rmdejemplo">
<p>Si estamos estudiando una población en la que se sabe que la variable de interés se comporta de forma diferente en distintas CCAA, se consideran estos estratos y se obtiene una submuestra de cada uno (por ejemplo en el caso anterior de las depuradoras).</p>
</div>
<p>El <strong>muestreo por conglomerados</strong> también asume que se dispone de grupos en la población,
la diferencia es que en este caso los grupos son homogéneos entre sí (se parecen).
Pero dentro de cada grupo la variable se comporta de forma heterogénea.
Puede existir una jerarquía (conglomerados dentro de los conglomerados).
Entonces se obtiene una muestra de grupos (no de individuos).
Después se pueden estudiar TODOS los individuos de los grupos de la muestra, o aplicar otro muestreo dentro (por ejemplo, estratificado). Es adecuado cuando es más fácil llegar a todos los elementos de un grupo.</p>
<div class="rmdejemplo">
<p>Se estudian hábitos de higiene en las familias en una ciudad. Se divide en barrios y se elige muestra de barrios. Dentro de cada barrio, se eligen aleatoriamente edificios, y se estudian todas las familias del edificio</p>
</div>
<p>No siempre tenemos la lista de elementos, como en los casos anteriores. Pero sí podemos “ordenarlos” de alguna manera,
por ejemplo, conforme llegan muestras (en el sentido biológico) a un laboratorio. Entonces podemos
realizar un <strong>muestreo sistemático</strong>. Para poder usarlo es importante estar
seguro de que la característica no depende del orden.
Entonces, se elige un punto de partida (idealmente aleatorio) y se toman elementos separados a distancia <span class="math inline">\(k\)</span> (coeficiente de elevación). Esta distancia puede referirse al número de individuos, por ejemplo, cada 10 individuos que llegan, o a un periodo de tiempo si llegan de forma más o menos regular, por ejemplo, cada 20 minutos. Se puede aplicar en vez de MAS en cualquiera de las situaciones anteriores.</p>
<div class="rmdejemplo">
<p>En la producción de un fertilizante en bolas, se tomarán muestras de 10 bolas cada hora. Se elige aleatoriamente un instante la primera hora, y a partir de ahí cada 60 minutos se tomarán las siguientes 10 bolas.</p>
</div>
<p>Cuando no es posible hacer un muestreo probabilístico, algunas veces pueden ser válidos
muestreos no probabilísticos. Entonces podremos hacer estudios observacionales,
e incluso aplicar técnicas de inferencia estadística, pero con ciertas precauciones.
Las conclusiones pueden no ser válidas para toda la población, y hay que tenerlo en cuenta.
Hay que procurar que, al menos cualitativamente, podamos presumir que la muestra representa a la población,
o al menos no tener evidencias de que no es así. Los estudios observacionales (sobre datos que están ahí) son también muy valiosos. Si estos estudios nos dan luz sobre algo suficientemente importante, puede merecer la pena diseñar un experimento para confirmar las conclusiones.</p>
</div>
<div id="parámetros-y-estimadores" class="section level2" number="8.3">
<h2>
<span class="header-section-number">8.3</span> Parámetros y estimadores<a class="anchor" aria-label="anchor" href="#par%C3%A1metros-y-estimadores"><i class="fas fa-link"></i></a>
</h2>
<p>Recordemos que los parámetros se definen sobre una Variable Aleatoria <span class="math inline">\(X\)</span> de la <strong>población</strong>. Son <strong>Desconocidos</strong>, pero siguen un modelo de distribución de probabilidad teórica de la variable aleatoria subyacente. En general, los queremos <strong>estimar</strong> mediante inferencia paramétrica. Los estadísticos son valores que se calculan con los datos de la <strong>muestra</strong>. En cada muestra serán distintos, es decir, habrá variabilidad, y por tanto son variables aleatorias, que siguen también una <strong>distribución</strong> de probabilidad. Esa distribución de probabilidad del estadístico es lo que llamamos distribución en el muestreo.</p>
<div class="rmdinfo">
<p><span class="math inline">\(\mu, \sigma^2 \text{ y }  \pi\)</span> representan los parámetros media, varianza y proporción de una determinada característica en la población. Son desconocidos, y dependen de la distribución de la característica en estudio.
<span class="math inline">\(\bar x, s^2 \text{ y } p\)</span> son estadísticos calculados con los <span class="math inline">\(n\)</span> datos de una muestra.</p>
</div>
<p>Un estimador es un estadístico mediante el cual estimamos el valor de un
parámetro. Esa estimación estará sujeta a un error, que se puede cuantificar si se ha seguido un muestreo probabilístico. El error va a depender de las propiedades del estimador y del tamaño de la muestra.
Representamos con <span class="math inline">\(\hat \mu = \bar x\)</span> que la media muestral <span class="math inline">\(\bar x\)</span> es un estimador de la media poblacional <span class="math inline">\(\mu\)</span></p>
<div class="rmdinfo">
<ul>
<li>Proporción: <span class="math inline">\(\hat \pi = p\)</span>
</li>
<li>Media: <span class="math inline">\(\hat \mu = \bar x\)</span>
</li>
<li>Varianza: <span class="math inline">\(\hat \sigma^2 = s^2 = \frac{1}{n-1}\left( \sum x_i^2 - n \bar x^2 \right )\)</span>
</li>
</ul>
</div>
<p>Para determinar qué estimador utilizar para un parámetro, se estudia su
distribución en el muestreo. Las siguientes son propiedades deseables de los estimadores:</p>
<ul>
<li><p><strong>Insesgado</strong>: Que la esperanza del estimador sea igual al verdadero valor del parámetro.</p></li>
<li><p><strong>Eficiente</strong>: Que tenga la mínima varianza posible.</p></li>
<li><p><strong>Consistente</strong>: Que tenga menor variabilidad a mayor tamaño de muestra.</p></li>
</ul>
</div>
<div id="distribución-en-el-muestreo-de-los-principales-estadísticos" class="section level2" number="8.4">
<h2>
<span class="header-section-number">8.4</span> Distribución en el muestreo de los principales estadísticos<a class="anchor" aria-label="anchor" href="#distribuci%C3%B3n-en-el-muestreo-de-los-principales-estad%C3%ADsticos"><i class="fas fa-link"></i></a>
</h2>
<div id="media-muestral" class="section level3" number="8.4.1">
<h3>
<span class="header-section-number">8.4.1</span> Media muestral<a class="anchor" aria-label="anchor" href="#media-muestral"><i class="fas fa-link"></i></a>
</h3>
<p>Sea la variable aleatoria <span class="math inline">\(X\)</span> con <span class="math inline">\(E[X] = \mu\)</span> y <span class="math inline">\(V[X] = \sigma^2\)</span>. Obtenemos muestras de tamaño <span class="math inline">\(n\)</span>: <span class="math inline">\(x_1, \ldots, x_i, \ldots, x_n\)</span>. Usamos la media muestral como estimador de la media poblacional:</p>
<p><span class="math display">\[\hat  \mu = \bar x = \frac 1 n \sum\limits_1^n x_i.\]</span></p>
<p>Entonces <span class="math inline">\(\overline X_{\{n\}}\)</span> es la variable aleatoria “media de la característica <span class="math inline">\(X\)</span> en muestras de tamaño <span class="math inline">\(n\)</span>”, y por
las propiedades de la esperanza y la varianza:</p>
<ul>
<li><p><span class="math inline">\(E[\overline X_{\{n\}}]\)</span> = <span class="math inline">\(\mu\)</span>,</p></li>
<li><p><span class="math inline">\(V[\overline X_{\{n\}}] = \frac{\sigma^2}{n}\)</span>.</p></li>
</ul>
</div>
<div id="teorema-central-del-límite-1" class="section level3" number="8.4.2">
<h3>
<span class="header-section-number">8.4.2</span> Teorema Central del Límite<a class="anchor" aria-label="anchor" href="#teorema-central-del-l%C3%ADmite-1"><i class="fas fa-link"></i></a>
</h3>
<p>Sean <span class="math inline">\(X_1, \ldots, X_n\)</span> variables aleatorias independientes e idénticamente distribuidas, con
media <span class="math inline">\(\mu\)</span> y varianza <span class="math inline">\(\sigma^2\)</span>. Y sea <span class="math inline">\(\overline X\)</span> el promedio de esas variables aleatorias:</p>
<p><span class="math display">\[\overline X = \frac 1 n \sum\limits_{i=1}^n X_i.\]</span></p>
<p>Entonces, para <span class="math inline">\(n\)</span> suficientemente grande, la variable aleatoria <span class="math inline">\(\overline X_{\{n\}}\)</span> sigue una distribución normal de media <span class="math inline">\(\mu\)</span> y varianza <span class="math inline">\(\frac{\sigma^2}{n}\)</span>:</p>
<p><span class="math display">\[\overline X_{\{n\}} \sim N\left(\mu; \frac{\sigma}{\sqrt{n}} \right).\]</span></p>
<p>El Teorema Central del Límite nos va a permitir hacer inferencia de cualquier variable aleatoria <span class="math inline">\(X\)</span> utilizando las propiedades de la distribución normal.</p>
</div>
<div id="varianza-muestral" class="section level3" number="8.4.3">
<h3>
<span class="header-section-number">8.4.3</span> Varianza muestral<a class="anchor" aria-label="anchor" href="#varianza-muestral"><i class="fas fa-link"></i></a>
</h3>
<p>La varianza poblacional, calculada con <span class="math inline">\(n\)</span> en el denominador, es un estimador <strong>sesgado</strong>:</p>
<p><span class="math display">\[E\left[\frac 1 n \sum (x_i-\bar x)^2 \right] = \frac{n}{n-1}\sigma^2.\]</span></p>
<p>Por eso usamos la “cuasivarianza” o varianza muestral:</p>
<p><span class="math display">\[\hat \sigma^2 = s^2 = \frac{ 1}{ n-1} \sum (x_i-\bar x)^2.\]</span>
Se cumple que:</p>
<ul>
<li><span class="math inline">\(E[s^2] = \sigma^2\)</span></li>
<li><span class="math inline">\(V[s^2] = \frac{2\sigma^4}{n-1}\)</span></li>
</ul>
<p>Para determinar la distribución en el muestreo de la varianza muestral, primero tenemos
que definir la distribución <span class="math inline">\(\chi^2\)</span>, que tiene un único parámetro, los grados de libertad <span class="math inline">\(n\)</span>.
Se define como la suma de <span class="math inline">\(n\)</span> variables aleatorias normales independientes estandarizadas al cuadrado:</p>
<p><span class="math display">\[\chi^2_n = Z_1^2 + \ldots + Z_n^2;\quad Z_i \sim N(0; 1)\forall i; \quad E[\chi^2_{n}]=n; \quad V[\chi^2_{n}]=2n.\]</span></p>
<p>Se cumple, independientemente de la distribución de <span class="math inline">\(X\)</span>, que:</p>
<p><span class="math display">\[\frac{(n-1)s^2}{\sigma^2}\sim \chi^2_{n-1},\]</span>
que es la distribución que usaremos para hacer inferencia sobre la varianza de la población.</p>
<div class="rmdinfo">
<p>La distribución <span class="math inline">\(\chi^2\)</span> es positiva y asimétrica. Esta asimetría puede tomar formas muy diversas. A medida que aumentan los grados de libertad, esta asimetría es menos pronunciada, véase la Fig. <a href="muestreo.html#fig:chi">8.1</a>.</p>
</div>
<div class="figure">
<span style="display:block;" id="fig:chi"></span>
<img src="08-muestreo_files/figure-html/chi-1.png" alt="Distribución $\chi^2$ para distintos grados de libertad" width="672"><p class="caption">
Figura 8.1: Distribución <span class="math inline">\(\chi^2\)</span> para distintos grados de libertad
</p>
</div>
</div>
<div id="proporción-muestral" class="section level3" number="8.4.4">
<h3>
<span class="header-section-number">8.4.4</span> Proporción muestral<a class="anchor" aria-label="anchor" href="#proporci%C3%B3n-muestral"><i class="fas fa-link"></i></a>
</h3>
<p>Sea la variable aleatoria <span class="math inline">\(X:\)</span> Número de elementos de la muestra de tamaño <span class="math inline">\(n\)</span> que presentan la característica en estudio.
Entonces al extraer la muestra, se obtienen valores <span class="math inline">\(x \in \{1, \ldots, n\}\)</span>, y el estadístico proporción muestral será <span class="math inline">\(p = \frac x n\)</span>. Entonces, la probabilidad de que el parámetro <span class="math inline">\(\pi\)</span> tome un valor determinado <span class="math inline">\(p=\frac x n\)</span>, es equivalente a la probabilidad de que la variable <span class="math inline">\(X\)</span> tome el valor <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[P[\pi = p] = P\left [\pi = \frac x n\right] = P[X = x].\]</span></p>
<p>Por tanto, la distribución exacta en el muestreo de <span class="math inline">\(\hat \pi = p\)</span> es una Binomial de parámetros <span class="math inline">\(n\)</span> y <span class="math inline">\(\pi\)</span>.</p>
<p>Como la binomial es una suma de distribuciones de Bernoulli, entonces <span class="math inline">\(p\)</span> es una media: <span class="math inline">\(p=\frac X n = \frac{\sum X_i}{n}\)</span>, y por el Teorema Central del Límite:</p>
<p><span class="math display">\[P = \frac{X}{n}\approx N\left(\pi, \sqrt{\frac{\pi(1-\pi)}{n}}\right).\]</span>
También se puede definir la distribución en el muestreo del número de elementos de la muestra con la característica, <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[X=np \sim N(n\pi, \sqrt{n\pi(1-\pi)}.\]</span></p>
</div>
</div>
<div id="tamaño-muestral-para-estimar-la-media" class="section level2" number="8.5">
<h2>
<span class="header-section-number">8.5</span> Tamaño muestral para estimar la media<a class="anchor" aria-label="anchor" href="#tama%C3%B1o-muestral-para-estimar-la-media"><i class="fas fa-link"></i></a>
</h2>
<p>Recordemos que no conocemos los parámetros de la población, por tanto necesitamos una forma de estimar el error que estamos cometiendo. Definimos entonces el error estándar de la media (<em>Standard Error</em>, SE) como:</p>
<p><span class="math display">\[SE=\frac{s}{\sqrt{n}}\]</span></p>
<p>como medida de dispersión del promedio muestral. A veces se usa error típico como sinónimo.</p>
<div class="rmdinfo">
<p>A mayor tamaño muestral, menor variabilidad, y menor error en las estimaciones.</p>
</div>
<p>El error depende del tamaño muestral, y también podemos determinar cuál debe ser
el tamaño de la muestra <span class="math inline">\(n\)</span> para cometer, como máximo, un determinado error <span class="math inline">\(e\)</span>.
Y esto lo haremos con una cierta <strong>confianza</strong>.
En los métodos paramétricos, este nivel de confianza tiene que ver con el <strong>muestreo</strong>.
Indica la proporción de veces que cometo un error inferior a <span class="math inline">\(e\)</span> si repito el muestreo
un número grande de veces. Se suele expresar como porcentaje, por ejemplo 95%, 99%, etc.</p>
<p>Definimos el <strong>nivel de significación</strong> <span class="math inline">\(\alpha\)</span> como el complementario del nivel de confianza. Por ejemplo,
para un nivel de confianza del 95% tendríamos un nivel de significación de 0,05. Entonces, para la media de una variable aleatoria <span class="math inline">\(X\)</span> que sigue una distribución normal, si tipificamos:</p>
<p><span class="math display">\[\frac{\overline X- \mu}{\frac{\sigma}{\sqrt{n}}}\sim N(0; 1).\]</span></p>
<p>Entonces para cumplir la confianza indicada anteriormente, se debe dar la siguiente condición:</p>
<p><span class="math display" id="eq:n1">\[\begin{equation}
  P\left[-z_{\frac{\alpha}{2}}&lt;\frac{\overline x- \mu}{\frac{\sigma}{\sqrt{n}}}&lt;z_{\frac{\alpha}{2}}\right] = 1-\alpha,
  \tag{8.1}
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(z_{\frac{\alpha}{2}}\)</span> es el cuantil de la distribución normal estandarizada para una probabilidad de <span class="math inline">\(1-\frac{\alpha}{2}\)</span>.</p>
<div class="rmdinfo">
<p>Normalmente se omite en <span class="math inline">\(z_{\frac{\alpha}{2}}\)</span> el símbolo “<span class="math inline">\(1-\)</span>” por comodidad al ser simétricos: <span class="math inline">\(z_\frac \alpha 2= - z_{1-\frac \alpha 2}\)</span>, véase la Fig. <a href="muestreo.html#fig:zalfamedios">8.2</a>.</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:zalfamedios"></span>
<img src="08-muestreo_files/figure-html/zalfamedios-1.png" alt="Representación del nivel de confianza , 1-$lpha$, y el nivel se significación, $lpha$, repartido en las dos colas de la distribución normal." width="60%"><p class="caption">
Figura 8.2: Representación del nivel de confianza , 1-<span class="math inline">\(lpha\)</span>, y el nivel se significación, <span class="math inline">\(lpha\)</span>, repartido en las dos colas de la distribución normal.
</p>
</div>
<div class="rmdejemplo">
<p>Para un nivel de significación <span class="math inline">\(\alpha = 0{,}05\)</span>, <span class="math inline">\(z_{\frac{\alpha}{2}} \simeq 1{,}96\)</span>. Podemos encontrar este valor en las tablas o con más precisión usando la siguiente expresión de R:</p>
<pre><code>qnorm(0.95)</code></pre>
</div>
<p>Despejando <span class="math inline">\(\mu\)</span> en la ecuación <a href="muestreo.html#eq:n1">(8.1)</a>:</p>
<p><span class="math display">\[P\left[\overline x-z_{\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}&lt; \mu &lt; \overline x+z_{\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}\right] = 1-\alpha.\]</span></p>
<p>De aquí, el error que estoy cometiendo un <span class="math inline">\(100 \times (1-\alpha)\)</span>% de las veces al estimar la media <span class="math inline">\(\mu\)</span> con la media muestral <span class="math inline">\(\bar x\)</span> y muestras de tamaño <span class="math inline">\(n\)</span> es:</p>
<p><span class="math display">\[e=z_{\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}},\]</span></p>
<p>de donde despejando <span class="math inline">\(n\)</span>, tenemos una expresión general para calcular el tamaño de muestra:</p>
<p><span class="math display">\[n = \frac{z_{\frac{\alpha}{2}}^2 \sigma^2}{e^2}.\]</span></p>
<p>Esta expresión nos sirve tal cual para calcular el tamaño de muestra necesario para estimar la
media poblacional de una variable aleatoria normal con <strong>varianza conocida</strong> <span class="math inline">\(\sigma^2\)</span>,
y tamaño poblacional grande. Si el tamaño de la población es pequeño y conocido, <span class="math inline">\(N\)</span>, entonces
el tamaño de la muestra se calcula con esta otra fórmula:</p>
<p><span class="math display">\[n = \frac{N\cdot z_{\frac{\alpha}{2}}^2 \cdot \sigma^2}{e^2\cdot (N-1)+ z_{\frac{\alpha}{2}}^2 \cdot \sigma^2},\]</span></p>
<p>Si la varianza es desconocida, sustituimos <span class="math inline">\(\sigma\)</span> por <span class="math inline">\(s\)</span>. Si no tenemos <span class="math inline">\(s\)</span>, se estima el caso más desfavorable.</p>
<div class="rmdejemplo">
<p>Queremos estimar la valoración que hacen los clientes de un determinado servicio energético en una puntuación de 0 a 10. El caso más desfavorable (para el tamaño de la varianza) sería que la mitad de los clientes contestaran un 0 y la otra mitad un 10. O, equivalentemente, que contestara un cliente con un cero y otro con un 10. Entonces, la varianza <span class="math inline">\(s^2\)</span> estaría entre 50 <span class="math inline">\((n=2)\)</span> y 25 (<span class="math inline">\(n\)</span> grande). El tamaño de muestra mínimo para estimar la puntuación media en una población grande y no equivocarnos en más de <span class="math inline">\(e = 1\)</span> punto con una confianza del 95% sería de <span class="math inline">\(n =192\)</span> clientes.</p>
<p><span class="math display">\[n = \frac{1.96^2\cdot 50}{1^2}\simeq 192\]</span></p>
</div>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 50</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, each <span class="op">=</span> <span class="fl">100</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 25.12563</span></span>
<span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.975</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">*</span><span class="fl">50</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 192.0729</span></span></code></pre></div>
<div class="rmdinfo">
<p>Lo más normal es que el cálculo de <span class="math inline">\(n\)</span> nos dé un número decimal. Tomaremos siempre el número entero redondeando <strong>al alza</strong>, para garantizar que la confianza es, al menos, de <span class="math inline">\((1-\alpha)%\)</span>, ya que a mayor tamaño muestral, mayor confianza. Si se hiciera un redondeo al entero inferior, la confianza sería menor de la deseada.</p>
</div>
</div>
<div id="tamaño-muestral-para-estimar-la-proporción" class="section level2" number="8.6">
<h2>
<span class="header-section-number">8.6</span> Tamaño muestral para estimar la proporción<a class="anchor" aria-label="anchor" href="#tama%C3%B1o-muestral-para-estimar-la-proporci%C3%B3n"><i class="fas fa-link"></i></a>
</h2>
<p>Asumimos que serán muestras grandes, y aplicando la aproximación de la distribución binomial por la normal, tenemos que para poblaciones grandes:</p>
<p><span class="math display">\[n = \frac{z_{\frac{\alpha}{2}}^2 \cdot \pi\cdot(1-\pi)}{e^2},\]</span>
y para poblaciones pequeñas de tamaño <span class="math inline">\(N\)</span>:</p>
<p><span class="math display">\[n = \frac{N\cdot z_{\frac{\alpha}{2}}^2\cdot \pi\cdot(1-\pi)}{e^2\cdot (N-1)+ z_{\frac{\alpha}{2}}^2 \cdot \pi\cdot(1-\pi)}.\]</span></p>
<p>Si no hay información sobre el parámetro <span class="math inline">\(\pi\)</span>, se toma el caso más desfavorable, que siempre es: <span class="math inline">\(\pi = (1-\pi) = 0{,}5.\)</span></p>
</div>
<div id="estimación-puntual" class="section level2" number="8.7">
<h2>
<span class="header-section-number">8.7</span> Estimación puntual<a class="anchor" aria-label="anchor" href="#estimaci%C3%B3n-puntual"><i class="fas fa-link"></i></a>
</h2>
<p>Uno de los objetivos de la inferencia estadística es la estimación de los parámetros de la
población, a partir de los datos de la muestra. Mediante la estimación puntual daremos
un valor único como <strong>estimación del parámetro</strong>, mediante un <strong>estadístico</strong> (función aplicada a los datos de
la muestra) que usaremos como <strong>estimador</strong>.
Así, para los parámetros más importantes se han establecido los siguientes estimadores puntuales:</p>
<ul>
<li>Proporción: <span class="math inline">\(\hat \pi = p = \frac x n\)</span>.</li>
<li>Media: <span class="math inline">\(\hat \mu = \bar x = \frac{\sum x_i}{n}\)</span>.</li>
<li>Varianza: <span class="math inline">\(\hat \sigma^2 = s^2 = \frac{1}{n-1}\left( \sum x_i^2 - n \bar x^2 \right )\)</span>.</li>
</ul>
<p>Se pueden determinar los mejores estimadores para cualquier parámetro de una
distribución de probabilidad concreta, que cumplan las características de insesgadez, eficiencia y consistencia.
Para ello se pueden utilizar diversos métodos, como el método de los momentos o el de máxima verosimilitud,
que no se tratan en este texto aplicado.</p>
<div class="rmdejemplo">
<p><svg aria-hidden="true" role="img" viewbox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:green;overflow:visible;position:relative;"><path d="M210.6 5.9L62 169.4c-3.9 4.2-6 9.8-6 15.5C56 197.7 66.3 208 79.1 208H104L30.6 281.4c-4.2 4.2-6.6 10-6.6 16C24 309.9 34.1 320 46.6 320H80L5.4 409.5C1.9 413.7 0 419 0 424.5c0 13 10.5 23.5 23.5 23.5H192v32c0 17.7 14.3 32 32 32s32-14.3 32-32V448H424.5c13 0 23.5-10.5 23.5-23.5c0-5.5-1.9-10.8-5.4-15L368 320h33.4c12.5 0 22.6-10.1 22.6-22.6c0-6-2.4-11.8-6.6-16L344 208h24.9c12.7 0 23.1-10.3 23.1-23.1c0-5.7-2.1-11.3-6-15.5L237.4 5.9C234 2.1 229.1 0 224 0s-10 2.1-13.4 5.9z"></path></svg> La normativa de calidad del agua<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://www.boe.es/buscar/act.php?id=BOE-A-2003-3596" class="uri"&gt;https://www.boe.es/buscar/act.php?id=BOE-A-2003-3596&lt;/a&gt;&lt;/p&gt;'><sup>72</sup></a> determina que el parámetro pH debe estar
entre 6.5 y 9.5 unidades de pH. Se obtienen 30 muestras aleatorias en hogares y se mide el pH, registrando también si el edificio tiene depósito de agua y la cantidad de antimonio en <span class="math inline">\(\mu\)</span>g/l. Los datos se
muestran en la tabla <a href="muestreo.html#tab:ph1">8.1</a>. Podríamos estimar con estos datos la media de pH en la población, la varianza, y la proporción de edificios con depósito de agua, utilizando los estimadores indicados anteriormente.</p>
</div>
<div class="tabwid">
<style>.cl-2dcb3c7a{}.cl-2dc7c7fc{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2dc927a0{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2dc927aa{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2dc935d8{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2dc935e2{width:0.863in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2dc935e3{width:0.948in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2dc935e4{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2dc935ec{width:0.863in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2dc935ed{width:0.948in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2dc935ee{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2dc935f6{width:0.863in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2dc935f7{width:0.948in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2dc935f8{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2dc93600{width:0.863in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2dc93601{width:0.948in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style>
<div class="inline-table"><table data-quarto-disable-processing="true" class="cl-2dcb3c7a">
<caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;">
<span id="tab:ph1">Tabla 8.1: </span><span>Datos de pH del agua del grifo en 30 viviendas</span>
</caption>
<thead><tr style="overflow-wrap:break-word;">
<th class="cl-2dc935d8"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">pH</span></p></th>
<th class="cl-2dc935e2"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">deposito</span></p></th>
<th class="cl-2dc935e3"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">antimonio</span></p></th>
</tr></thead>
<tbody>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935e4"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">7.687</span></p></td>
<td class="cl-2dc935ec"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">Sí</span></p></td>
<td class="cl-2dc935ed"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">0.94</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.092</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.03</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">7.582</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.06</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.798</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">0.99</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.165</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.07</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">7.590</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.03</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.244</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">0.95</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935e4"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.369</span></p></td>
<td class="cl-2dc935ec"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">Sí</span></p></td>
<td class="cl-2dc935ed"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.03</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.288</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">0.91</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935e4"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">7.847</span></p></td>
<td class="cl-2dc935ec"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">Sí</span></p></td>
<td class="cl-2dc935ed"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.11</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.756</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.16</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935e4"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.195</span></p></td>
<td class="cl-2dc935ec"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">Sí</span></p></td>
<td class="cl-2dc935ed"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">0.97</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">7.689</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">0.92</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">6.893</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.05</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.562</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">0.99</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935e4"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">7.978</span></p></td>
<td class="cl-2dc935ec"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">Sí</span></p></td>
<td class="cl-2dc935ed"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.19</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935e4"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">7.992</span></p></td>
<td class="cl-2dc935ec"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">Sí</span></p></td>
<td class="cl-2dc935ed"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.00</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.472</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.06</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935e4"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.411</span></p></td>
<td class="cl-2dc935ec"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">Sí</span></p></td>
<td class="cl-2dc935ed"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.00</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935e4"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.297</span></p></td>
<td class="cl-2dc935ec"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">Sí</span></p></td>
<td class="cl-2dc935ed"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">0.94</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.459</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.02</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935e4"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.391</span></p></td>
<td class="cl-2dc935ec"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">Sí</span></p></td>
<td class="cl-2dc935ed"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">0.86</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.037</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.12</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">7.005</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.01</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935e4"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.310</span></p></td>
<td class="cl-2dc935ec"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">Sí</span></p></td>
<td class="cl-2dc935ed"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.17</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">7.972</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.04</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935e4"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">7.922</span></p></td>
<td class="cl-2dc935ec"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">Sí</span></p></td>
<td class="cl-2dc935ed"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">0.94</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">7.265</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">1.05</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935ee"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">7.761</span></p></td>
<td class="cl-2dc935f6"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc935f7"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">0.93</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-2dc935f8"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">8.209</span></p></td>
<td class="cl-2dc93600"><p class="cl-2dc927aa"><span class="cl-2dc7c7fc">No</span></p></td>
<td class="cl-2dc93601"><p class="cl-2dc927a0"><span class="cl-2dc7c7fc">0.90</span></p></td>
</tr>
</tbody>
</table></div>
</div>
<div class="rmdpractica">
<p><svg aria-hidden="true" role="img" viewbox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:steelblue;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"></path></svg> El siguiente código calcula la media muestral del pH, la varianza muestral del pH, y la
proporción muestral de edificios con depósito de agua (y por tanto también sin depósito de agua). Los datos se importan directamente
de una url. Resultan las siguientes estimaciones puntuales:</p>
<p><span class="math display">\[\hat{\mu} = \bar{x} = 8.04\]</span>
<span class="math display">\[\hat{\sigma}^2= s^2 = 0.21\]</span>
<span class="math display">\[\hat{\pi}= p = \frac{11}{30} = 0.37\]</span></p>
</div>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">ph1</span><span class="op">$</span><span class="va">pH</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 8.041267</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">ph1</span><span class="op">$</span><span class="va">pH</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.2134909</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/proportions.html">prop.table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">ph1</span><span class="op">$</span><span class="va">deposito</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;        No        Sí </span></span>
<span><span class="co">#&gt; 0.6333333 0.3666667</span></span></code></pre></div>
</div>
<div id="estimación-por-intervalos" class="section level2" number="8.8">
<h2>
<span class="header-section-number">8.8</span> Estimación por intervalos<a class="anchor" aria-label="anchor" href="#estimaci%C3%B3n-por-intervalos"><i class="fas fa-link"></i></a>
</h2>
<p>Al hacer la estimación puntual de cualquier parámetro, digamos genéricamente <span class="math inline">\(\theta\)</span>, estamos cometiendo un error <span class="math inline">\(e\)</span>. Este error se puede cuantificar gracias a la distribución en el muestreo del estadístico que estemos usando como estimador. Y entonces podemos construir <strong>intervalos de confianza</strong> (IC) para el parámetro que estamos estimando.</p>
<p>El intervalo puede ser bilateral, con dos límites inferior <span class="math inline">\((LI)\)</span> y superior <span class="math inline">\((LS)\)</span>, de modo que <span class="math inline">\(\theta \in[\mathit{LI}, \mathit{LS}]\)</span>
para los que se cumpla que:</p>
<p><span class="math display">\[P[\mathit{LI} &lt; \theta &lt; \mathit{LS}]=1-\alpha.\]</span>
Nótese que la probabilidad de que el parámetro sea mayor que el límite
superior o menor que el límite inferior será <span class="math inline">\(\frac \alpha 2\)</span>, véase la Fig. <a href="muestreo.html#fig:zalfamedios">8.2</a>. Aquí, <span class="math inline">\(1-\alpha\)</span> es el nivel de confianza (se expresa a menudo como porcentaje), y <span class="math inline">\(\alpha\)</span> es el nivel de significación.</p>
<p>Los intervalos de confianza también pueden ser unilaterales, cuando solamente nos interesa saber un umbral mínimo o máximo del verdadero valor del parámetro. Estos intervalos tienen un único límite inferior o superior, y se pueden expresar como:</p>
<ul>
<li>
<span class="math inline">\([LI, \infty)\)</span>: <span class="math inline">\(P[\theta &gt; LI] = 1-\alpha\)</span>.</li>
<li>
<span class="math inline">\((-\infty, LS]\)</span>: <span class="math inline">\(P\theta &lt; LS] = 1-\alpha\)</span>.</li>
</ul>
<p>La diferencia principal es que, con la misma confianza, queremos asegurarnos de que el verdadero valor del parámetro no es mayor que el límite superior o no es menor que el límite inferior (pero el lado opuesto nos da igual).</p>
<div class="rmdejemplo">
<p><svg aria-hidden="true" role="img" viewbox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:green;overflow:visible;position:relative;"><path d="M210.6 5.9L62 169.4c-3.9 4.2-6 9.8-6 15.5C56 197.7 66.3 208 79.1 208H104L30.6 281.4c-4.2 4.2-6.6 10-6.6 16C24 309.9 34.1 320 46.6 320H80L5.4 409.5C1.9 413.7 0 419 0 424.5c0 13 10.5 23.5 23.5 23.5H192v32c0 17.7 14.3 32 32 32s32-14.3 32-32V448H424.5c13 0 23.5-10.5 23.5-23.5c0-5.5-1.9-10.8-5.4-15L368 320h33.4c12.5 0 22.6-10.1 22.6-22.6c0-6-2.4-11.8-6.6-16L344 208h24.9c12.7 0 23.1-10.3 23.1-23.1c0-5.7-2.1-11.3-6-15.5L237.4 5.9C234 2.1 229.1 0 224 0s-10 2.1-13.4 5.9z"></path></svg> La normativa de calidad del agua mencionada en el
ejemplo del pH, determina un valor paramétrico de 5 <span class="math inline">\(\mu\)</span>g/l de antimonio como
límite máximo. En este caso, el intervalo de confianza que nos interesará es
un intervalo unilateral con un único límite superior, ya que la característica en
estudio es “cuanto menor, mejor”.</p>
</div>
<p>Para determinar los intervalos de confianza, nos basamos en la distribución
en el muestreo de cada estimador <span class="math inline">\(\hat \theta\)</span>. A continuación deduciremos
las fórmulas para los intervalos de confianza de la media, la varianza y
la proporción.</p>
<div id="intervalo-de-confianza-para-mu-sigma2-conocida" class="section level3" number="8.8.1">
<h3>
<span class="header-section-number">8.8.1</span> Intervalo de confianza para <span class="math inline">\(\mu\)</span>: <span class="math inline">\(\sigma^2\)</span> conocida<a class="anchor" aria-label="anchor" href="#intervalo-de-confianza-para-mu-sigma2-conocida"><i class="fas fa-link"></i></a>
</h3>
<p>La media muestral de tamaño <span class="math inline">\(n\)</span> sigue una distribución Normal con media <span class="math inline">\(\mu\)</span> y
varianza <span class="math inline">\(\frac{\sigma^2}{n}\)</span>. Por tanto, tipificando, tenemos la siguiente distribución en
el muestreo:</p>
<p><span class="math display" id="eq:dmz">\[\begin{equation}
\frac{\overline X- \mu}{\frac{\sigma}{\sqrt{n}}}\sim N(0; 1).
  \tag{8.2}
\end{equation}\]</span></p>
<p>Para un nivel de confianza <span class="math inline">\(1-\alpha\)</span> determinado, si buscamos un <strong>intervalo bilateral</strong> tenemos que:</p>
<p><span class="math display">\[P\left[-z_{\frac{\alpha}{2}}&lt;\frac{\overline x- \mu}{\frac{\sigma}{\sqrt{n}}}&lt;z_{\frac{\alpha}{2}}\right] = 1-\alpha.\]</span></p>
<p>Y despejando <span class="math inline">\(\mu\)</span> tendremos que, con una confianza de <span class="math inline">\(1-\alpha\)</span>, el verdadero valor del parámetro <span class="math inline">\(\mu\)</span> estará en el
intervalo:</p>
<p><span class="math display">\[\mu \in \left [\bar x - z_{\frac{\alpha}{2}}\cdot \frac{\sigma}{\sqrt{n}};\; \bar x + z_{\frac{\alpha}{2}}\cdot \frac{\sigma}{\sqrt{n}}\right].\]</span></p>
<p>O, de forma más compacta:</p>
<p><span class="math display" id="eq:icz">\[\begin{equation}
\boxed{\bar x \pm z_{\frac{\alpha}{2}}\cdot \frac{\sigma}{\sqrt{n}}}
  \tag{8.3}
\end{equation}\]</span></p>
<div class="rmdpractica">
<p><svg aria-hidden="true" role="img" viewbox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:steelblue;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"></path></svg> La estimación puntual de la media del pH en las
30 viviendas muestreadas en el ejemplo anterior, está sujeta a un cierto error. Vamos a
dar la estimación como un intervalo de confianza al 95%. Supongamos que la varianza
es conocida e igual a <span class="math inline">\(\sigma^2 = 0{,}25\)</span>. Para varianza conocida
no hay una función específica que nos dé el intervalo de confianza, pero es
muy fácil obtenerlo con la siguiente expresión, donde <code>c(-1,1)*</code> nos permite
obtener dos números, uno sumando y otro restando aquello a lo que multiplica,
y <code>qnorm(0.975)</code> nos da el valor de <span class="math inline">\(z_{\frac \alpha 2}\)</span>, dado que si
<span class="math inline">\(1-\alpha=0{,}95 \implies \frac \alpha 2 = \frac{ 0{,}05}{ 2} = 0{,}025\)</span>.</p>
</div>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">ph1</span><span class="op">$</span><span class="va">pH</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.975</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">0.25</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">30</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 7.862347 8.220186</span></span></code></pre></div>
<div class="rmdinfo">
<p>Recordemos que por simplicidad escribimos <span class="math inline">\(z_{\frac{\alpha}{2}}\)</span> pero tomamos
el cuantil de la distribución normal en <span class="math inline">\(1-\frac \alpha 2\)</span>, es decir, 0,975.
En la práctica, en este caso daría igual, porque <span class="math inline">\(z_{\frac \alpha 2} = - z_{1- \frac \alpha 2}\)</span>
y al aplicar la fórmula con <span class="math inline">\(\pm\)</span> el resultado serían los mismos límites.
Sin embargo, en los intervalos bilaterales tenemos que poner cuidado con los cálculos.</p>
</div>
<p>Los <strong>intervalos unilaterales</strong> se deducen análogamente, pero acotando el valor
de la distribución normal
solo en una de las colas. Por ejemplo, para un intervalo unilateral por la derecha:</p>
<p><span class="math display">\[P\left[\frac{\overline x- \mu}{\frac{\sigma}{\sqrt{n}}}&lt;z_{\alpha}\right] = 1-\alpha.\]</span>
Y el intervalo de confianza ahora será:</p>
<p><span class="math display">\[\boxed{\mu &lt; \bar x + z_{\alpha}\cdot \frac{\sigma}{\sqrt{n}}}.\]</span>
Análogamente, para un intervalo por la izquierda, el intervalo de
confianza será:</p>
<p><span class="math display">\[\boxed{\mu &gt; \bar x - z_{\alpha}\cdot \frac{\sigma}{\sqrt{n}}}.\]</span></p>
<p>Nótese que en los intervalos unilaterales utilizamos <span class="math inline">\(z_\alpha\)</span> en vez de <span class="math inline">\(z_{\frac \alpha 2}\)</span>.
Esto es porque concentramos toda la probabilidad de error en una de las colas,
lo que además reduce el error en la estimación. Por eso, cuando solo estemos interesados
en uno de los límites, el superior o el inferior, siempre es preferible obtener
intervalos unilaterales. La figura <a href="muestreo.html#fig:zalpha">8.3</a> muestra una representación
de las tres situaciones.</p>
<div class="figure">
<span style="display:block;" id="fig:zalpha"></span>
<img src="08-muestreo_files/figure-html/zalpha-1.png" alt="$z_{\frac \alpha 2}$ o $z_\alpha$, esa es la cuestión" width="672"><p class="caption">
Figura 8.3: <span class="math inline">\(z_{\frac \alpha 2}\)</span> o <span class="math inline">\(z_\alpha\)</span>, esa es la cuestión
</p>
</div>
<div class="rmdpractica">
<p><svg aria-hidden="true" role="img" viewbox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:steelblue;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"></path></svg> En el ejemplo del antimonio, queremos obtener
un intervalo de confianza al 99%
para dar cuenta de la incertidumbre en la estimación puntual, pero
con mucha confianza. Además, para
aumentar la precisión de nuestra estimación por intervalos, solo
nos interesa el límite superior, que es donde podemos tener el riesgo
para la salud. Supongamos que la varianza es conocida, <span class="math inline">\(\sigma^2 = 0{,}0064\)</span>.
Entonces el límite superior sería el calculado con la siguiente
expresión. Esto quiere decir que, con una confianza del 99%, la media del
antimonio en el agua potable es menor de 1,05 <span class="math inline">\(\mu\)</span>g/l, muy lejos del límite
marcado por la legislación (téngase en cuenta que hacemos estimaciones sobre la media, no
sobre posibles valores individuales).</p>
</div>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">ph1</span><span class="op">$</span><span class="va">antimonio</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.99</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">0.0064</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">30</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1.048645</span></span></code></pre></div>
</div>
<div id="intervalo-de-confianza-para-mu-sigma2-desconocida" class="section level3" number="8.8.2">
<h3>
<span class="header-section-number">8.8.2</span> Intervalo de confianza para <span class="math inline">\(\mu\)</span>: <span class="math inline">\(\sigma^2\)</span> desconocida<a class="anchor" aria-label="anchor" href="#intervalo-de-confianza-para-mu-sigma2-desconocida"><i class="fas fa-link"></i></a>
</h3>
<p>En la ecuación <a href="muestreo.html#eq:icz">(8.3)</a> asumimos que la varianza de la población <span class="math inline">\(\sigma^2\)</span>
es conocida. Pero esto rara vez lo podemos dar por hecho, y en su lugar
lo que tenemos es una estimación a través de una muestra y el estadístico <span class="math inline">\(s^2\)</span>.
Si sustituimos en la ecuación <a href="muestreo.html#eq:dmz">(8.2)</a>, la distribución en el muestreo ya no
es una distribución normal sino una <span class="math inline">\(t\)</span> de Student.</p>
<p><span class="math display">\[\frac{\overline X- \mu}{\frac{s}{\sqrt{n}}}\sim t_{n-1},\]</span></p>
<p>Para un nivel de confianza <span class="math inline">\(1-\alpha\)</span> determinado, si buscamos un <strong>intervalo bilateral</strong> tenemos que:</p>
<p><span class="math display">\[P\left[-t_{n-1,\frac{\alpha}{2}}&lt;\frac{\overline x- \mu}{\frac{s}{\sqrt{n}}}&lt;t_{n-1,\frac{\alpha}{2}}\right] = 1-\alpha.\]</span></p>
<p>Y despejando <span class="math inline">\(\mu\)</span> tendremos que, con una confianza de <span class="math inline">\(1-\alpha\)</span>, el verdadero valor del parámetro <span class="math inline">\(\mu\)</span> estará en el
intervalo:</p>
<p><span class="math display">\[\boxed{IC_\mu=\bar x \pm t_{n-1, \frac{\alpha}{2}}\cdot \frac{s}{\sqrt{n}}}\]</span></p>
<p>La distribución <span class="math inline">\(t\)</span> de Student tiene un único parámetro <span class="math inline">\(n\)</span>, que son los grados de libertad.
Sean las variables aleatorias <span class="math inline">\(Z, Z_1, \cdots, Z_n \sim N(0;1)\)</span>. Entonces, la variable aleatoria
definida por:</p>
<p><span class="math display">\[T = \frac{Z}{\frac{1}{n}\sum Z_i^2}\sim t_{n},\]</span>
sigue una distribución <span class="math inline">\(t\)</span> de Student con <span class="math inline">\(n\)</span> grados de libertad, y que tiene
las siguientes características:</p>
<ul>
<li><p><span class="math inline">\(E[T]=0\)</span></p></li>
<li><p><span class="math inline">\(V[T]=\frac{n}{n-2}\)</span></p></li>
<li><p><span class="math inline">\(n&gt;30 \implies t_n \sim N(0;1)\)</span></p></li>
</ul>
<p>En la práctica, obtendremos los valores <span class="math inline">\(t_{n-1; \frac\alpha 2}\)</span> en tablas o con
software, y sustituiremos los valores en la fórmula. O bien obtendremos directamente los
intervalos con el software.</p>
<div class="rmdcafe">
<p>¿Por qué este nombre tan raro de la distribución? Realmente Student es el seudónimo
que utilizó el estadístico inglés William Sealy Gosset para publicar el trabajo
en el que la definió, ya que la empresa en la que trabajaba no permitía a sus empleados
publicar con su nombre para no desvelar secretos industriales.
A muchxs estadísticxs nos gusta la historia, y el producto que fabricaba la empresa
en la que trabajaba el bueno de Gosset<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://es.wikipedia.org/wiki/Prueba_t_de_Student" class="uri"&gt;https://es.wikipedia.org/wiki/Prueba_t_de_Student&lt;/a&gt;&lt;/p&gt;'><sup>73</sup></a>.</p>
</div>
<div class="rmdinfo">
<p>Lo explicado en el apartado anterior sobre los intervalos unilaterales aplica exactamente
igual a este caso, por lo que no lo repetiremos. La distribución <span class="math inline">\(t\)</span>
es también simétrica como la normal estándar, y prácticamente igual para <span class="math inline">\(n &gt; 30\)</span>. La figura
<a href="muestreo.html#fig:t">8.4</a> muestra la distribución normal estándar y la distribución <span class="math inline">\(t\)</span> para varios valores de <span class="math inline">\(n\)</span>.</p>
</div>
<div class="figure">
<span style="display:block;" id="fig:t"></span>
<img src="08-muestreo_files/figure-html/t-1.png" alt="Distribución $t$ vs la normal" width="672"><p class="caption">
Figura 8.4: Distribución <span class="math inline">\(t\)</span> vs la normal
</p>
</div>
<div class="rmdpractica">
<p><svg aria-hidden="true" role="img" viewbox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:steelblue;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"></path></svg>
Vamos a obtener los intervalos de confianza para el pH (bilateral) y para el
antimonio (unilateral) de los ejemplos anteriores, pero en este caso
asumiendo que la varianza es desconocida.</p>
<p>En este caso sí tenemos una función que nos proporciona el intervalo de confianza,
y es la función <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code>. En realidad calcula más cosas, pero obtenemos solo
el elemento <code>conf.int</code> que tiene el intervalo de confianza. El código a
continuación obtiene los intervalos de confianza pedidos. El argumento <code>alternative</code>
controla que sea bilateral (por defecto, <em>two-sided</em>) o unilateral (solo límite superior, <em>less</em>, o
solo límite inferior, <em>greater</em>). El argumento <code>conf.level</code> controla el
nivel de confianza (<em>confidence level</em>).</p>
<p>Nótese cómo, para la misma confianza, los intervalos obtenidos son más amplios
al no conocer la varianza (tenemos menos información, y por tanto el error que
cometemos es mayor).</p>
<p>Se deja como ejercicio comprobar que aplicando la fórmula como en los casos
anteriores, se tiene el mismo intervalo. El cuantil de la distribución <span class="math inline">\(t\)</span>
lo obtendríamos con la función <code><a href="https://rdrr.io/r/stats/TDist.html">qt()</a></code>, por ejemplo para el intervalo unilateral
al 95% de confianza:</p>
<pre><code>qt(0.975, 29)</code></pre>
</div>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">ph1</span><span class="op">$</span><span class="va">pH</span><span class="op">)</span><span class="op">$</span><span class="va">conf.int</span></span>
<span><span class="co">#&gt; [1] 7.868734 8.213799</span></span>
<span><span class="co">#&gt; attr(,"conf.level")</span></span>
<span><span class="co">#&gt; [1] 0.95</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">ph1</span><span class="op">$</span><span class="va">antimonio</span>, alternative <span class="op">=</span> <span class="st">"less"</span>, conf.level <span class="op">=</span> <span class="fl">0.99</span> <span class="op">)</span><span class="op">$</span><span class="va">conf.int</span></span>
<span><span class="co">#&gt; [1]     -Inf 1.051616</span></span>
<span><span class="co">#&gt; attr(,"conf.level")</span></span>
<span><span class="co">#&gt; [1] 0.99</span></span></code></pre></div>
</div>
<div id="intervalo-de-confianza-para-la-proporción" class="section level3" number="8.8.3">
<h3>
<span class="header-section-number">8.8.3</span> Intervalo de confianza para la proporción<a class="anchor" aria-label="anchor" href="#intervalo-de-confianza-para-la-proporci%C3%B3n"><i class="fas fa-link"></i></a>
</h3>
<p>Por el teorema central del límite, si <span class="math inline">\(n&gt;30\)</span> la variable aleatoria “proporción muestral en muestras de tamaño <span class="math inline">\(n\)</span>”, sigue una distribución normal con media la proporción poblacional <span class="math inline">\(\pi\)</span> y varianza <span class="math inline">\(\frac{\pi(1-\pi)}{n}\)</span>. Por tanto, tipificando, tenemos la siguiente distribución en
el muestreo:</p>
<p><span class="math display" id="eq:dpz">\[\begin{equation}
\frac{p - \pi}{\sqrt{\frac{\pi(1-\pi)}{n}}}\sim N(0; 1).
  \tag{8.4}
\end{equation}\]</span></p>
<p>Para un nivel de confianza <span class="math inline">\(1-\alpha\)</span> determinado, si buscamos un <strong>intervalo bilateral</strong> tenemos que:</p>
<p><span class="math display">\[\boxed{IC_\pi=p\pm z_{\frac{\alpha}{2}}\cdot \sqrt{\frac{\pi \cdot (1-\pi)}{n}}}.\]</span>
El parámetro <span class="math inline">\(\pi\)</span> es desconocido y se sustituye por la proporción muestral <span class="math inline">\(p\)</span>. Los intervalos unilaterales se obtendrían de forma análoga a los de la media, acumulando la significatividad <span class="math inline">\(\alpha\)</span> solo en uno de los extremos.</p>
<div class="rmdpractica">
<p><svg aria-hidden="true" role="img" viewbox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:steelblue;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"></path></svg>
Vamos a obtener el intervalo de confianza bilateral para la proporción de edificios de viviendas con depósito de agua. Ya habíamos calculado la proporción muestral como <span class="math inline">\(p = 0.37\)</span>. El intervalo de confianza al 95% con la aproximación normal sería el siguiente:</p>
<p><span class="math display">\[IC_\pi=p\pm z_{\frac{\alpha}{2}}\cdot \sqrt{\frac{p \cdot (1-p)}{n}} = 0.37 \pm 1.96 \cdot \sqrt{\frac{0.37 \cdot 0.63}{30}}\\=[0.197, 0.543].\]</span>
En general, esta aproximación es más conservadora (intervalos amplios) que otros métodos más precisos.
En R podemos obtener un intervalo exacto para la proporción de viviendas utilizando la binomial, y otro mediante la distribución chi-cuadrado que no vemos en más detalle. Este último aplica por defecto la llamada “corrección por continuidad de Yates” (Véase la ayuda de la función <code><a href="https://rdrr.io/r/stats/prop.test.html">prop.test()</a></code>.</p>
</div>
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/binom.test.html">binom.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">11</span>, n <span class="op">=</span> <span class="fl">30</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Exact binomial test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  11 and 30</span></span>
<span><span class="co">#&gt; number of successes = 11, number of trials = 30,</span></span>
<span><span class="co">#&gt; p-value = 0.2005</span></span>
<span><span class="co">#&gt; alternative hypothesis: true probability of success is not equal to 0.5</span></span>
<span><span class="co">#&gt; 95 percent confidence interval:</span></span>
<span><span class="co">#&gt;  0.1992986 0.5614402</span></span>
<span><span class="co">#&gt; sample estimates:</span></span>
<span><span class="co">#&gt; probability of success </span></span>
<span><span class="co">#&gt;              0.3666667</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/prop.test.html">prop.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">11</span>, n <span class="op">=</span> <span class="fl">30</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  1-sample proportions test with continuity correction</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  11 out of 30, null probability 0.5</span></span>
<span><span class="co">#&gt; X-squared = 1.6333, df = 1, p-value = 0.2012</span></span>
<span><span class="co">#&gt; alternative hypothesis: true p is not equal to 0.5</span></span>
<span><span class="co">#&gt; 95 percent confidence interval:</span></span>
<span><span class="co">#&gt;  0.2054281 0.5609198</span></span>
<span><span class="co">#&gt; sample estimates:</span></span>
<span><span class="co">#&gt;         p </span></span>
<span><span class="co">#&gt; 0.3666667</span></span></code></pre></div>
</div>
<div id="intervalo-de-confianza-para-la-varianza" class="section level3" number="8.8.4">
<h3>
<span class="header-section-number">8.8.4</span> Intervalo de confianza para la varianza<a class="anchor" aria-label="anchor" href="#intervalo-de-confianza-para-la-varianza"><i class="fas fa-link"></i></a>
</h3>
<p>La variable aleatoria que vamos a utilizar para construir el intervalo de confianza de la varianza es la siguiente:</p>
<p><span class="math display">\[\frac{(n-1)s^2}{\sigma^2}\sim \chi^2_{n-1}.\]</span></p>
<p>A diferencia de las distribuciones normal y <span class="math inline">\(t\)</span>, la distribución <span class="math inline">\(\chi^2\)</span> no es simétrica (véase la figura <a href="muestreo.html#fig:chi">8.1</a>). Entonces el intervalo tampoco lo va a ser. Es decir, el centro del intervalo no va a ser la estimación puntual de la varianza, y los límites hay que calcularlos con los cuantiles específicos.</p>
<p>A partir del nivel de confianza determinado <span class="math inline">\(1-\alpha\)</span>, establecemos la condición de probabilidad:</p>
<p><span class="math display">\[P\left[\chi^2_{n-1,\frac{\alpha}{2}}&lt;\frac{s^2\cdot(n-1)}{\sigma^2}&lt;\chi^2_{n-1,1-\frac{\alpha}{2}}\right] = 1-\alpha,\]</span></p>
<p>y despejando <span class="math inline">\(\sigma^2\)</span> tenemos los límites del intervalo de confianza para la varianza como:</p>
<p><span class="math display">\[\boxed{IC_\sigma=\left[ \frac{s^2\cdot(n-1)}{\chi^2_{n-1,1-\frac{\alpha}{2}}}; \frac{s^2\cdot(n-1)}{\chi^2_{n-1,\frac{\alpha}{2}}}\right]}.\]</span>
Aquí, $ $ y <span class="math inline">\(1 - \frac{\alpha}{2}\)</span> toman su sentido original al no ser simétricos como en la normal y la <span class="math inline">\(t\)</span>.</p>
<div class="rmdpractica">
<p>En el ejemplo del pH, teníamos la estimación puntual de la varianza como:</p>
<p><span class="math display">\[\hat{\sigma}^2= s^2 = 0.21\]</span></p>
<p>El intervalo de confianza se puede calcular a mano con la fórmula anterior,
teniendo en cuenta que los cuantiles de la distribución <span class="math inline">\(\chi^2\)</span> se obtendrían
con la función <code><a href="https://rdrr.io/r/stats/Chisquare.html">qchisq()</a></code>. No hay una función específica en <strong>R</strong> base para obtener
el intervalo de confianza, pero se puede calcular con las siguientes expresiones.</p>
</div>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">LS</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">ph1</span><span class="op">$</span><span class="va">pH</span><span class="op">)</span><span class="op">*</span><span class="fl">29</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">qchisq</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">29</span><span class="op">)</span></span>
<span><span class="va">LI</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">ph1</span><span class="op">$</span><span class="va">pH</span><span class="op">)</span><span class="op">*</span><span class="fl">29</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">qchisq</a></span><span class="op">(</span><span class="fl">0.975</span>, <span class="fl">29</span><span class="op">)</span></span>
<span><span class="va">LI</span>;<span class="va">LS</span></span>
<span><span class="co">#&gt; [1] 0.1354096</span></span>
<span><span class="co">#&gt; [1] 0.3858172</span></span></code></pre></div>
</div>
</div>
<div id="intervalos-de-confianza-para-comparaciones" class="section level2" number="8.9">
<h2>
<span class="header-section-number">8.9</span> Intervalos de confianza para comparaciones<a class="anchor" aria-label="anchor" href="#intervalos-de-confianza-para-comparaciones"><i class="fas fa-link"></i></a>
</h2>
<p>Uno de los principales usos de la estadística aplicada es la comparación de muestras para determinar si pueden venir de la misma población, o por el contrario se puede demostrar que hay diferencias significativas en algunos de sus parámetros. Normalmente estas comparaciones las haremos con los contrastes de hipótesis que veremos en el siguiente capítulo. No obstante, a veces es útil obtener intervalos de confianza para la diferencia de la media o para la razón de varianzas.</p>
<p>En general, tenemos dos muestras, <span class="math inline">\(x_1, x_2\)</span> que posiblemente estén relacionadas. Se puede dar el caso de que las varianzas sean conocidas e iguales, conocidas y distintas, o bien desconocidas. Los tamaños de muestra de ambas muestras pueden ser iguales o distintos, por ejemplo <span class="math inline">\(n_1, n_2\)</span>.</p>
<div id="intervalos-de-confianza-para-la-diferencia-de-medias" class="section level3" number="8.9.1">
<h3>
<span class="header-section-number">8.9.1</span> Intervalos de confianza para la diferencia de medias<a class="anchor" aria-label="anchor" href="#intervalos-de-confianza-para-la-diferencia-de-medias"><i class="fas fa-link"></i></a>
</h3>
<p>En el caso del intervalo de confianza para la media de dos muestras, estaremos interesados en la diferencia de medias, <span class="math inline">\(\theta = \mu_1- \mu_2\)</span>. Entonces, como las medias siguen una distribución normal, entonces aplicando las propiedades de la esperanza y la varianza:</p>
<p><span class="math display">\[\frac{\bar{x}-\bar{y}-\theta}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}\sim N(0;1)\]</span></p>
<p>Entonces, para <strong>varianzas conocidas</strong> tenemos que el intervalo de confianza para la diferencia medias: <span class="math inline">\(\mu_1 - \mu_2\)</span>, <span class="math inline">\(\sigma_1. \sigma_2\)</span> conocidas es:</p>
<p><span class="math display">\[IC_{\mu_1-\mu_2} = (\bar x_1 - \bar x_2) \pm z_{\frac \alpha 2}\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}\]</span></p>
<p>Para el caso de <strong>varianzas desconocidas</strong>, pero que se pueden asumir <strong>iguales</strong> <span class="math inline">\((\sigma_1 \ne \sigma_2)\)</span>, se calcula la
varianza agrupada, o conjunta (<em>pooled</em>) como:</p>
<p><span class="math display">\[s_p^2= \frac{(n_1 -1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2},\]</span></p>
<p>y entonces a través de la siguiente distribución en el muestreo:</p>
<p><span class="math display">\[\frac{\bar{x}-\bar{y}-\theta}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}\sim t_{n_1+n_2-1}\]</span></p>
<p>obtenemos la siguiente expresión para el intervalo de confianza de la diferencia de medias con varianzas desconocidas pero iguales:</p>
<p><span class="math display">\[IC_{\mu_1-\mu_2} = (\bar x_1 - \bar x_2) \pm t_{n_1+n_2-2, \frac \alpha 2}\cdot s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}.\]</span>
Por último, en el caso en que las varianzas son desconocidas y no se puede aceptar que sean iguales <span class="math inline">\((\sigma_1 \ne \sigma_2)\)</span>, tenemos
la siguiente distribución en el muestreo:</p>
<p><span class="math display">\[\frac{\bar{x}-\bar{y}-\theta}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}\sim t_f,\]</span></p>
<p>donde:</p>
<p><span class="math display">\[f=\left[ \frac{\left (\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}\right )^2}{\frac{\left(\frac{s_1^2}{n_1}\right)^2}{n_1-1}+\frac{\left(\frac{s_2^2}{n_2}\right)^2}{n_2-1}}\right],\]</span></p>
<p>redondeando al entero menor. Y entonces el intervalo de confianza es:</p>
<p><span class="math display">\[IC_{\mu_1-\mu_2} = (\bar x_1 - \bar x_2) \pm t_{f, \frac \alpha 2}\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}.\]</span></p>
<p>Este método se conoce como la aproximación de Welch.</p>
<div class="rmdejemplo">
<p>En el conjunto de datos del pH podemos comparar estimar intervalos de confianza para la diferencia en la media del pH entre los edificios que tienen depósito de agua y los que no. La función <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code> que ya utilizamos para el intervalo de confianza de la media no sirve para este nuevo intervalo de confianza. Por defecto asume varianzas desconocidas y distintas (correción de Welch). Con el argumento <code>var.equal</code> se puede cambiar este comportamiento por defecto.</p>
</div>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">pH</span> <span class="op">~</span> <span class="va">deposito</span>, data <span class="op">=</span> <span class="va">ph1</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Welch Two Sample t-test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  pH by deposito</span></span>
<span><span class="co">#&gt; t = -0.92268, df = 27.004, p-value = 0.3643</span></span>
<span><span class="co">#&gt; alternative hypothesis: true difference in means between group No and group Sí is not equal to 0</span></span>
<span><span class="co">#&gt; 95 percent confidence interval:</span></span>
<span><span class="co">#&gt;  -0.4373191  0.1660081</span></span>
<span><span class="co">#&gt; sample estimates:</span></span>
<span><span class="co">#&gt; mean in group No mean in group Sí </span></span>
<span><span class="co">#&gt;         7.991526         8.127182</span></span></code></pre></div>
<div class="rmdinfo">
<p>Cuando las muestras están relacionadas, habría que proceder de forma distinta. En vez de calcular las medias de los dos grupos y después hacer la diferencia, habría que calcular las diferencias de las observaciones relacionadas, y entonces trabajar con esa variable aleatoria <span class="math inline">\(Y = X_1 - X_2\)</span>. Por ejemplo, supongamos que en el estudio del pH volvemos a hacer mediciones al cabo de un tiempo después de aplicar un determinado tratamiento a las aguas de la ciudad. Entonces tendremos otras 30 mediciones en los mismos edificios, y haríamos la diferencia entre el tiempo 2 y el tiempo 1 de cada una de los 30 edificios. A partir de ahí se obtendría el intervalos de confianza de la media de la diferencia.</p>
</div>
</div>
<div id="intervalo-de-confianza-para-la-diferencia-de-proporciones" class="section level3" number="8.9.2">
<h3>
<span class="header-section-number">8.9.2</span> Intervalo de confianza para la diferencia de proporciones<a class="anchor" aria-label="anchor" href="#intervalo-de-confianza-para-la-diferencia-de-proporciones"><i class="fas fa-link"></i></a>
</h3>
<p>Aplicando el teorema central del límite y la aproximación normal para muestras grandes, tendremos que si <span class="math inline">\(\theta = \pi_1-\pi_2\)</span>:</p>
<p><span class="math display">\[\frac{p_1 - p_2 - \theta}{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}\sim N(0; 1).\]</span>
y entonces el intervalo de confianza para la diferencia de proporciones será:</p>
<p><span class="math display">\[p_1-p_2 \pm z_{\frac \alpha 2}\cdot \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}.\]</span></p>
</div>
<div id="intervalos-de-confianza-para-la-razón-de-varianzas" class="section level3" number="8.9.3">
<h3>
<span class="header-section-number">8.9.3</span> Intervalos de confianza para la razón de varianzas<a class="anchor" aria-label="anchor" href="#intervalos-de-confianza-para-la-raz%C3%B3n-de-varianzas"><i class="fas fa-link"></i></a>
</h3>
<p>Para comparar varianzas y dar intervalos de confianza de su diferencia, no podemos seguir
el mismo proceso que con las medias, ya que las varianzas son siempre positivas, y la diferencia nunca va a ser cero.
En su lugar, aplicaremos que las varianzas serán iguales cuando su cociente sea igual a 1. Es decir, usamos el parámetro <span class="math inline">\(\theta = \frac{\sigma_1^2}{\sigma_2^2}\)</span> y la distribución en el muestreo siguiente:</p>
<p><span class="math display">\[\frac{s_1^2}{s_2^2}\cdot \frac{1}{\theta}\sim F_{n_1-1;n_2 -1},\]</span></p>
<p>donde F es la distribución F de Fisher-Snedecor, en la cual tenemos <span class="math inline">\(X_1, \ldots, X_{n_1}\)</span>; <span class="math inline">\(Y_1, \ldots, Y_{n_2}\)</span> variables aleatorias independientes e idénticamente distribuidas normales tipificadas, <span class="math inline">\(\sim N(0;1)\)</span>, de modo que:</p>
<p><span class="math display">\[F = \frac{\frac{ 1}{ n_1}\sum\limits_{i=1}^{n_1} X_i^2}{\frac{ 1}{ n_2}\sum\limits_{i=1}^{n_2} Y_i^2}\sim F_{n_1,n_2},\]</span></p>
<p>y que tiene las siguientes propiedades:</p>
<ul>
<li><p><span class="math inline">\(E[F] = \frac{n_2}{n_2-2}, \; n_2&gt;2\)</span>.</p></li>
<li><p><span class="math inline">\(V[F] = \frac{2n_2^2(n_1+n_2-2)}{n_1(n_2-2)^2(n_2-4)}, \; n_2&gt;4\)</span>.</p></li>
</ul>
<p>La distribución F puede tomar muchas formas dependiendo de los grados de libertad de numerador y denominador. Algunas combinaciones se muestran en la figura <a href="muestreo.html#fig:f">8.5</a>.</p>
<div class="figure">
<span style="display:block;" id="fig:f"></span>
<img src="08-muestreo_files/figure-html/f-1.png" alt="Forma de la densidad de F para varias combinaciones de parámetros" width="672"><p class="caption">
Figura 8.5: Forma de la densidad de F para varias combinaciones de parámetros
</p>
</div>
<p>Entonces el intervalo de confianza para la razón de varianzas se calcularía como se indica a continuación:</p>
<p><span class="math display">\[IC_{\frac{\sigma_1}{\sigma_2}} = \left[\frac{\frac{s_1^2}{s_2^2}}{F_{n_1-1, n_2-1, \frac{\alpha}{2}}};\frac{s_1^2}{s_2^2}\cdot F_{n_2-1, n_1-1, \frac{\alpha}{2}} \right].\]</span></p>
<div class="rmdejemplo">
<p>Vamos a calcular un intervalo de confianza para el cociente de varianzas de los edificios que no tienen depósito y los que sí tienen depósito. La función <code><a href="https://rdrr.io/r/stats/var.test.html">var.test()</a></code> nos da este resultado. Nótese que el intervalo no contiene al 1, y por tanto no es compatible con que las varianzas sean iguales. Esto se podría utilizar para decidir si tenemos varianzas iguales o no al calcular un intervalo de confianza de la diferencia de medias.</p>
</div>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/var.test.html">var.test</a></span><span class="op">(</span><span class="va">pH</span> <span class="op">~</span> <span class="va">deposito</span>, data <span class="op">=</span> <span class="va">ph1</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  F test to compare two variances</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  pH by deposito</span></span>
<span><span class="co">#&gt; F = 4.7878, num df = 18, denom df = 10, p-value =</span></span>
<span><span class="co">#&gt; 0.01526</span></span>
<span><span class="co">#&gt; alternative hypothesis: true ratio of variances is not equal to 1</span></span>
<span><span class="co">#&gt; 95 percent confidence interval:</span></span>
<span><span class="co">#&gt;   1.386414 13.723673</span></span>
<span><span class="co">#&gt; sample estimates:</span></span>
<span><span class="co">#&gt; ratio of variances </span></span>
<span><span class="co">#&gt;           4.787814</span></span></code></pre></div>
<p>Los intervalos de confianza de las comparaciones, además de la propia incertidumbre acerca de la estimación puntual del parámetro diferencia (o cociente), nos permite realizar las siguientes interpretaciones:</p>
<ul>
<li><p>Si el intervalo de confianza de la diferencia de medias contiene el cero, no podremos asegurar que haya diferencias entre las medias de las dos <strong>poblaciones</strong> (en general, nos interesará confirmar que sí hay diferencias).</p></li>
<li><p>Si el intervalo de confianza de la razón de varianzas contiene el 1, no podremos asegurar que haya diferencias entre las varianzas (en general, nos interesará comprobar que no hay diferencias).</p></li>
</ul>
<div class="rmdinfo">
<p>O lo que es lo mismo, las diferencias observadas en las <strong>muestras</strong> son debidas al azar, y no a una diferencia real entre los parámetros poblacionales.</p>
<p>Esto lo hacemos también con contrastes de hipótesis en el siguiente capítulo.</p>
</div>

</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="modelos.html"><span class="header-section-number">7</span> Modelos de distribución de probabilidad</a></div>
<div class="next"><a href="comparacion2.html"><span class="header-section-number">9</span> Comparación de dos grupos</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="Índice capítulo"><h2>Índice capítulo</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#muestreo"><span class="header-section-number">8</span> Muestreo y estimación</a></li>
<li><a class="nav-link" href="#muestreo-estad%C3%ADstico"><span class="header-section-number">8.1</span> Muestreo Estadístico</a></li>
<li><a class="nav-link" href="#muestreo-probabil%C3%ADstico"><span class="header-section-number">8.2</span> Muestreo probabilístico</a></li>
<li><a class="nav-link" href="#par%C3%A1metros-y-estimadores"><span class="header-section-number">8.3</span> Parámetros y estimadores</a></li>
<li>
<a class="nav-link" href="#distribuci%C3%B3n-en-el-muestreo-de-los-principales-estad%C3%ADsticos"><span class="header-section-number">8.4</span> Distribución en el muestreo de los principales estadísticos</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#media-muestral"><span class="header-section-number">8.4.1</span> Media muestral</a></li>
<li><a class="nav-link" href="#teorema-central-del-l%C3%ADmite-1"><span class="header-section-number">8.4.2</span> Teorema Central del Límite</a></li>
<li><a class="nav-link" href="#varianza-muestral"><span class="header-section-number">8.4.3</span> Varianza muestral</a></li>
<li><a class="nav-link" href="#proporci%C3%B3n-muestral"><span class="header-section-number">8.4.4</span> Proporción muestral</a></li>
</ul>
</li>
<li><a class="nav-link" href="#tama%C3%B1o-muestral-para-estimar-la-media"><span class="header-section-number">8.5</span> Tamaño muestral para estimar la media</a></li>
<li><a class="nav-link" href="#tama%C3%B1o-muestral-para-estimar-la-proporci%C3%B3n"><span class="header-section-number">8.6</span> Tamaño muestral para estimar la proporción</a></li>
<li><a class="nav-link" href="#estimaci%C3%B3n-puntual"><span class="header-section-number">8.7</span> Estimación puntual</a></li>
<li>
<a class="nav-link" href="#estimaci%C3%B3n-por-intervalos"><span class="header-section-number">8.8</span> Estimación por intervalos</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#intervalo-de-confianza-para-mu-sigma2-conocida"><span class="header-section-number">8.8.1</span> Intervalo de confianza para \(\mu\): \(\sigma^2\) conocida</a></li>
<li><a class="nav-link" href="#intervalo-de-confianza-para-mu-sigma2-desconocida"><span class="header-section-number">8.8.2</span> Intervalo de confianza para \(\mu\): \(\sigma^2\) desconocida</a></li>
<li><a class="nav-link" href="#intervalo-de-confianza-para-la-proporci%C3%B3n"><span class="header-section-number">8.8.3</span> Intervalo de confianza para la proporción</a></li>
<li><a class="nav-link" href="#intervalo-de-confianza-para-la-varianza"><span class="header-section-number">8.8.4</span> Intervalo de confianza para la varianza</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#intervalos-de-confianza-para-comparaciones"><span class="header-section-number">8.9</span> Intervalos de confianza para comparaciones</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#intervalos-de-confianza-para-la-diferencia-de-medias"><span class="header-section-number">8.9.1</span> Intervalos de confianza para la diferencia de medias</a></li>
<li><a class="nav-link" href="#intervalo-de-confianza-para-la-diferencia-de-proporciones"><span class="header-section-number">8.9.2</span> Intervalo de confianza para la diferencia de proporciones</a></li>
<li><a class="nav-link" href="#intervalos-de-confianza-para-la-raz%C3%B3n-de-varianzas"><span class="header-section-number">8.9.3</span> Intervalos de confianza para la razón de varianzas</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/emilopezcano/estadistica-ciencias-ingenieria/blob/master/08-muestreo.Rmd">Ver fuente <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/emilopezcano/estadistica-ciencias-ingenieria/edit/master/08-muestreo.Rmd">Editar esta página <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Estadística Aplicada a las Ciencias y la Ingeniería</strong>" escrito por <a href="https://lcano.com" class="text-light">Emilio L. Cano</a>. Generado por última vez el día 2026-02-18.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Este libro ha sido generado con el paquete de R <a class="text-light" href="https://bookdown.org">bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
