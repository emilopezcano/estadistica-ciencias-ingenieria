<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capítulo 4 Introducción a la Probabilidad | Estadística Aplicada a las Ciencias y la Ingeniería</title>
<meta name="author" content="Emilio L. Cano">
<meta name="description" content="4.1 Introducción En los capítulos anteriores, hemos visto cómo mediante la Estadística Descriptiva estudiamos variables estadísticas describiéndolas y representándolas. Mediante la Estadística...">
<meta name="generator" content="bookdown 0.24.3 with bs4_book()">
<meta property="og:title" content="Capítulo 4 Introducción a la Probabilidad | Estadística Aplicada a las Ciencias y la Ingeniería">
<meta property="og:type" content="book">
<meta property="og:url" content="https://emilopezcano.github.io/estadistica-ciencias-ingenieria/introp.html">
<meta property="og:image" content="https://emilopezcano.github.io/estadistica-ciencias-ingenieria/images/cover.png">
<meta property="og:description" content="4.1 Introducción En los capítulos anteriores, hemos visto cómo mediante la Estadística Descriptiva estudiamos variables estadísticas describiéndolas y representándolas. Mediante la Estadística...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Capítulo 4 Introducción a la Probabilidad | Estadística Aplicada a las Ciencias y la Ingeniería">
<meta name="twitter:description" content="4.1 Introducción En los capítulos anteriores, hemos visto cómo mediante la Estadística Descriptiva estudiamos variables estadísticas describiéndolas y representándolas. Mediante la Estadística...">
<meta name="twitter:image" content="https://emilopezcano.github.io/estadistica-ciencias-ingenieria/images/cover.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="bs4_book.css">
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Estadística Aplicada a las Ciencias y la Ingeniería</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Buscar" aria-label="Buscar">
</form>

      <nav aria-label="Contenido"><h2>Contenido</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Bienvenida</a></li>
<li class="book-part">Estadística descriptiva</li>
<li><a class="" href="intro.html"><span class="header-section-number">1</span> Introducción</a></li>
<li><a class="" href="aed-uni.html"><span class="header-section-number">2</span> Análisis exploratorio univariante</a></li>
<li><a class="" href="aed-bi.html"><span class="header-section-number">3</span> Análisis exploratorio bivariante</a></li>
<li class="book-part">Probabilidad</li>
<li><a class="active" href="introp.html"><span class="header-section-number">4</span> Introducción a la Probabilidad</a></li>
<li><a class="" href="vauni.html"><span class="header-section-number">5</span> Variable aleatoria univariante</a></li>
<li><a class="" href="vabi.html"><span class="header-section-number">6</span> Variable aleatoria bivariante</a></li>
<li><a class="" href="modelos.html"><span class="header-section-number">7</span> Modelos de distribución de probabilidad</a></li>
<li class="book-part">Inferencia estadística</li>
<li><a class="" href="muestreo.html"><span class="header-section-number">8</span> Muestreo y estimación</a></li>
<li><a class="" href="comparacion2.html"><span class="header-section-number">9</span> Comparación de dos grupos</a></li>
<li><a class="" href="anova.html"><span class="header-section-number">10</span> Análisis de la Varianza</a></li>
<li><a class="" href="doe.html"><span class="header-section-number">11</span> Diseño de experimentos</a></li>
<li><a class="" href="regresion.html"><span class="header-section-number">12</span> Modelos de regresión</a></li>
<li class="book-part">Control estadístico de la calidad</li>
<li><a class="" href="introc.html"><span class="header-section-number">13</span> Introducción</a></li>
<li><a class="" href="spc.html"><span class="header-section-number">14</span> Control Estadístico de Procesos</a></li>
<li><a class="" href="aceptacion.html"><span class="header-section-number">15</span> Inspección por muestreo</a></li>
<li class="book-part">Apéndices</li>
<li><a class="" href="s%C3%ADmbolos-abreviaturas-y-acr%C3%B3nimos.html"><span class="header-section-number">A</span> Símbolos, abreviaturas y acrónimos</a></li>
<li><a class="" href="formulario.html"><span class="header-section-number">B</span> Formulario</a></li>
<li><a class="" href="tablas.html"><span class="header-section-number">C</span> Tablas estadísticas</a></li>
<li><a class="" href="repaso.html"><span class="header-section-number">D</span> Repaso</a></li>
<li><a class="" href="ampliaci%C3%B3n.html"><span class="header-section-number">E</span> Ampliación</a></li>
<li><a class="" href="demostraciones.html"><span class="header-section-number">F</span> Demostraciones</a></li>
<li><a class="" href="creditos.html"><span class="header-section-number">G</span> Créditos</a></li>
<li><a class="" href="referencias.html">Referencias</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/emilopezcano/estadistica-ciencias-ingenieria">Ver repositorio <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="introp" class="section level1" number="4">
<h1>
<span class="header-section-number">Capítulo 4</span> Introducción a la Probabilidad<a class="anchor" aria-label="anchor" href="#introp"><i class="fas fa-link"></i></a>
</h1>
<div id="sec-introprob" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> Introducción<a class="anchor" aria-label="anchor" href="#sec-introprob"><i class="fas fa-link"></i></a>
</h2>
<p>En los capítulos anteriores, hemos visto cómo mediante la <strong>Estadística Descriptiva</strong>
estudiamos variables estadísticas describiéndolas y representándolas. Mediante la
<strong>Estadística Inferencial</strong> lo que tratamos es de inferir (estimar, predecir)
las propiedades de una población basándonos en una muestra de
datos. La Teoría de
Probabilidades y el Cálculo de Probabilidades son las bases en las que
se sustentan estos métodos, partiendo de la estimación del modelo de
datos, es decir, la distribución de probabilidad de una determinada
característica en la población.
En este capítulo estudiaremos los conceptos fundamentales del
<strong>Cálculo de Probabilidades</strong>.</p>
<div id="estándares-de-aplicación" class="section level3 unnumbered">
<h3>Estándares de aplicación<a class="anchor" aria-label="anchor" href="#est%C3%A1ndares-de-aplicaci%C3%B3n"><i class="fas fa-link"></i></a>
</h3>
<p>En este capítulo se han aplicado los siguientes estándares:</p>
<ul>
<li>
<strong>UNE-ISO 3534-1</strong>: Estadística. Vocabulario y símbolos. Parte 1, Términos estadísticos generales y términos empleados en el cálculo de probabilidades</li>
</ul>
</div>
<div id="estadística-y-cálculo-de-probabilidades" class="section level3 unnumbered">
<h3>Estadística y Cálculo de Probabilidades<a class="anchor" aria-label="anchor" href="#estad%C3%ADstica-y-c%C3%A1lculo-de-probabilidades"><i class="fas fa-link"></i></a>
</h3>
<p>La figura <a href="introp.html#fig:dogma">4.1</a> representa la esencia de la Estadística, esto es,
su relación con la probabilidad y la inferencia, a través de la población y la muestra.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:dogma"></span>
<img src="04-introp_files/figure-html/dogma-1.png" alt="Relación entre la Estadística Descriptiva, el Cálculo de Probabilidades y la Estadística Inferencial" width="70%"><p class="caption">
Figura 4.1: Relación entre la Estadística Descriptiva, el Cálculo de Probabilidades y la Estadística Inferencial
</p>
</div>
<p>Es decir, partiendo de los datos de la muestra, estimaremos el modelo de
distribución de probabilidad que sigue la variable en estudio en toda la
población. A partir de ahí, podremos estimar sus parámetros,
calcular probabilidades y realizar contrastes de hipótesis usando técnicas
de inferencia estadística. La Estadística Descriptiva sobre los datos de la
muestra es una tarea permanente.
Necesitamos en primer lugar una
definición de la Probabilidad y sus propiedades.</p>
</div>
</div>
<div id="sucesos-aleatorios" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> Sucesos aleatorios<a class="anchor" aria-label="anchor" href="#sucesos-aleatorios"><i class="fas fa-link"></i></a>
</h2>
<p>Definamos un <strong>experimento</strong> como cualquier actividad
que deriva en un resultado observable e identificable, al que llamaremos <strong>suceso</strong>. Estos
resultados pueden ser deterministas o aleatorios.
<strong>Sucesos deterministas</strong> son los resultados de aquellos experimentos que,
bajo las mismas condiciones,
producen el mismo resultado. Por ejemplo, si observamos el número de eclipses de sol
que se producen en los próximos 12 meses, el resultado es determinista.
Por contra, <strong>Sucesos aleatorios</strong> son aquellos que están sujetos a incertidumbre. La
mayoría de los experimentos no son deterministas sino <strong>aleatorios</strong>. Por ejemplo,
el resultado al lanzar un dado, observar si un cliente compra o no al entrar a
una tienda, etc.</p>
<p>Llamamos <strong>sucesos elementales</strong>
a cada uno de los resultados posibles de un experimento. Al ser aleatorios,
no conocemos cuál de ellos va a ser el resultado final del experimento, pero sí
podemos conocer la probabilidad de que se produzca cada uno de los
resultados<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Muchas veces, lo que tendremos es una estimación o idea aproximada de esas probabilidades&lt;/p&gt;"><sup>42</sup></a>.
Por ejemplo: en una clase de 50 alumnos, si observamos
el número de alumnos que obtiene sobresaliente en un curso, no sabemos cuántos
van a ser. Pero sí podemos saber cuál es la probabilidad de cada uno de los
resultados posibles, en este caso entre 0 (ninguno) y 50 (todos) en base a
lo que ha sucedido en años anteriores.</p>
<p>Así, la <strong>Probabilidad</strong> es una medida del <strong>grado de incertidumbre</strong>
sobre el resultado de un experimento aleatorio. Los posibles resultados de un experimento
aleatorio forman un conjunto, y la teoría de probabilidades se sustenta en la
teoría de conjuntos.
A continuación vamos a definir
formalmente los sucesos en términos de <strong>conjuntos</strong>.</p>
<blockquote>
<p><strong>Espacio muestral, <span class="math inline">\(\Omega\)</span></strong></p>
<p>Conjunto de todos los resultados posibles</p>
<p>— ISO 3534-1 2.1</p>
</blockquote>
<p><span class="math inline">\(\Omega\)</span> estará formado por los posibles resultados del experimento o
sucesos elementales <span class="math inline">\(\omega_i\)</span>.</p>
<blockquote>
<p><strong>Suceso, <span class="math inline">\(A\)</span></strong></p>
<p>Subconjunto del espacio muestral</p>
<p>— ISO 3534-1 2.2</p>
</blockquote>
<blockquote>
<p><strong>Suceso complementario, <span class="math inline">\(A^c\)</span></strong></p>
<p>Espacio muestral excluyendo el suceso dado</p>
<p>— ISO 3534-1 2.3</p>
</blockquote>
<p>Así, un suceso cualquiera estará formado por uno o varios sucesos elementales <span class="math inline">\(\omega_i\)</span>
del espacio muestral. Un suceso <span class="math inline">\(A\)</span> ocurre si ocurre alguno de los sucesos
elementales que lo componen.</p>
<div id="sucesos-notables" class="section level3" number="4.2.1">
<h3>
<span class="header-section-number">4.2.1</span> Sucesos notables<a class="anchor" aria-label="anchor" href="#sucesos-notables"><i class="fas fa-link"></i></a>
</h3>
<p>Los siguientes sucesos tienen especial importancia en el cálculo de probabilidades:</p>
<ul>
<li>Suceso <span class="math inline">\(A \subseteq \Omega\)</span>.</li>
<li>Suceso complementario<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;También se suele representar por &lt;span class="math inline"&gt;\(\bar{A}\)&lt;/span&gt; o &lt;span class="math inline"&gt;\(A^*\)&lt;/span&gt;.&lt;/p&gt;'><sup>43</sup></a> <span class="math inline">\(A^c\)</span>.</li>
<li>Suceso seguro <span class="math inline">\(\Omega\)</span>.</li>
<li>Suceso imposible <span class="math inline">\(\emptyset\)</span>.</li>
</ul>
<p>La figura <a href="introp.html#fig:venn1">4.2</a> representa el espacio muestral, un suceso cualquiera <span class="math inline">\(A\)</span> y su
complementario <span class="math inline">\(A^c\)</span>. El suceso imposible no aparece representado, pero en
realidad sería:</p>
<p><span class="math display">\[\emptyset = \Omega^c\]</span></p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:venn1"></span>
<img src="04-introp_files/figure-html/venn1-1.png" alt="Representación del espacio muestral, un suceso cualquiera y su complementario" width="70%"><p class="caption">
Figura 4.2: Representación del espacio muestral, un suceso cualquiera y su complementario
</p>
</div>
<p>Habitualmente se utilizan ejemplos de juegos de azar para introducir el
cálculo de probabilidades, como lanzamiento de monedas y dados, o
combinaciones de cartas en barajas de naipes. Los ejemplos con juegos de azar
tienen la ventaja de que son fáciles de comprender.</p>

<div class="rmdejemplo">
<em>Lanzamiento de un dado</em>. El experimento consiste en lanzar un dado una vez;
Los sucesos elementales son los resultados del 1 al 6; El espacio muestral
es el conjunto de todos los sucesos elementales, es decir,
<span class="math inline">\(\Omega = \{1, 2, 3, 4, 5, 6\}\)</span>;
Si definimos el suceso <span class="math inline">\(A\)</span> “que salga número par”, entonces
<span class="math inline">\(A = \{2, 4, 6\}\)</span>; el suceso <span class="math inline">\(A\)</span>
ocurre si sale un 2, un 4, o un 6.
</div>
<p>La aplicación de la probabilidad en casos distintos
a los juegos de azar, sigue las mismas leyes, y los ejemplos se pueden asimilar
a situaciones reales de la empresa o cualquier otro ámbito. A continuación
se describe un ejemplo ilustrativo que,
aunque totalmente inventado, se puede encontrar el lector
en el futuro con ligeras variaciones según su ámbito de actuación.
Utilizaremos en lo posible las cifras usadas en los problemas de azar
para ver la utilidad de aquéllos ejemplos en casos más prácticos.</p>

<div class="rmdejemplo">
<p>En un estudio se cuenta con un conjunto de 52 sujetos,
los cuales están clasificados
según alguna característica.
Vamos a considerar el <em>experimento</em> de observar un sujeto
(por ejemplo cuando entra en la página web del estudio) y clasificarlo
según un criterio determinado. Tendremos los siguientes sucesos:</p>
<ul>
<li>52 posibles sujetos en estudio, <span class="math inline">\((\Omega)\)</span>
</li>
<li>La mitad son mujeres <span class="math inline">\((M)\)</span>
</li>
<li>4 investigadores <span class="math inline">\((I)\)</span> , 12 técnicos <span class="math inline">\((T)\)</span>, resto pacientes <span class="math inline">\((P)\)</span>
</li>
<li>13 jóvenes <span class="math inline">\((J)\)</span>, 26 adultos <span class="math inline">\((A)\)</span>, 13 mayores <span class="math inline">\((R)\)</span>; 5, 18 y 3 mujeres en cada
grupo respectivamente</li>
<li>1 de cada seis hombres <span class="math inline">\((H)\)</span> responderá al tratamiento <span class="math inline">\((S)\)</span>, el doble si es mujer</li>
</ul>
</div>
<p>¿Con qué juegos de azar relacionarías cada uno de los sucesos anteriores?
Piensa algunos ejemplos de sucesos en el entorno empresarial con datos similares.
El siguiente puede ser un ejemplo más real.</p>

<div class="rmdejemplo">
Estudiamos una serie de proyectos de inversión
y para ello queremos seleccionar dos de un total de cinco proyectos. El espacio muestral,
si asumimos que no nos importa el orden en el que se seleccionan y etiquetamos los proyectos
con los números del 1 al 5, es <span class="math inline">\(\Omega=\{\)</span> (1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (4, 5) <span class="math inline">\(\}\)</span>.
Es decir, el espacio muestral tiene 10 elementos. El mero recuento se puede realizar
mediante técnicas de combinatoria, véase al apéndice <a href="repaso.html#combinatoria">D.2</a>.
En este caso, <span class="math inline">\(C_{5, 2} = \binom{5}{2} = 10\)</span>.
</div>

<div class="rmdpractica">
<p><strong>CALCULADORA</strong></p>
<p>5 <span class="math inline">\(\boxed{\mathsf{nCr}}\)</span> 2 <span class="math inline">\(\rightarrow\)</span> 10</p>
<p><strong>HOJA DE CÁLCULO</strong></p>
<p><code>=COMBIN(5;2)</code> <span class="math inline">\(\boxed{\mathsf{10}}\)</span><br>
[EXCEL] <code>=COMBINAT(5;2)</code> <span class="math inline">\(\boxed{\mathsf{10}}\)</span></p>
<p><strong>R</strong></p>
La función <code>choose</code> obtiene el número de combinaciones como se ilustra a continuación.
</div>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Special.html">choose</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">2</span><span class="op">)</span>
<span class="co">#&gt; [1] 10</span></code></pre></div>
</div>
<div id="operaciones-con-sucesos" class="section level3" number="4.2.2">
<h3>
<span class="header-section-number">4.2.2</span> Operaciones con sucesos<a class="anchor" aria-label="anchor" href="#operaciones-con-sucesos"><i class="fas fa-link"></i></a>
</h3>
<p>Como se ha comentado anteriormente, los sucesos son conjuntos. Y como
tales, aplican las operaciones y propiedades de la teoría de conjuntos.</p>
<p><strong>Unión de sucesos</strong>. Dados dos sucesos <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span>, definimos
<span class="math inline">\(A \cup B\)</span><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;En ocasiones se utiliza la notación &lt;span class="math inline"&gt;\(A+B\)&lt;/span&gt; para la unión de sucesos.&lt;/p&gt;'><sup>44</sup></a>
como
el suceso que se cumple si:</p>
<ul>
<li>Ocurre <span class="math inline">\(A\)</span>, o</li>
<li>Ocurre <span class="math inline">\(B\)</span>, o</li>
<li>Ocurren <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> a la vez</li>
</ul>
<p>El suceso unión contiene los sucesos elementales comunes y los no comunes,
véase la figura <a href="introp.html#fig:union">4.3</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:union"></span>
<img src="04-introp_files/figure-html/union-1.png" alt="Representación de la unión de dos sucesos" width="70%"><p class="caption">
Figura 4.3: Representación de la unión de dos sucesos
</p>
</div>

<div class="rmdejemplo">
El suceso “ser investigador <strong>o</strong> mujer” en nuestro ejemplo de los sujetos en estudio (<span class="math inline">\(M \cup I\)</span>) incluirían a lo resultados elementales correspondientes con todas las mujeres (incluidas directivas) y los directivos hombres.
</div>
<p><strong>Intersección de sucesos</strong>. Dados dos sucesos <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span>, definimos
<span class="math inline">\(A \cap B\)</span><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;En ocasiones se utiliza la notación &lt;span class="math inline"&gt;\(A\cdot B\)&lt;/span&gt; o simplemente &lt;span class="math inline"&gt;\(AB\)&lt;/span&gt; para la intersección de sucesos.&lt;/p&gt;'><sup>45</sup></a>
como el suceso que se cumple si ocurren <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> simultáneamente. El suceso
intersección contiene únicamente los sucesos elementales comunes a ambos sucesos,
véase la figura <a href="introp.html#fig:intersec">4.4</a>.</p>
<p>Las operaciones de unión e intersección entre dos ducesos se extienden
inmediatamente a más de dos sucesos.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:intersec"></span>
<img src="04-introp_files/figure-html/intersec-1.png" alt="Representación de la intersección de dos sucesos" width="70%"><p class="caption">
Figura 4.4: Representación de la intersección de dos sucesos
</p>
</div>

<div class="rmdejemplo">
El suceso “ser hombre” <strong>y</strong> “ser investigador”, se corresponde con la
intersección (<span class="math inline">\(I \cap M^c\)</span>), e incluiría solo a los resultados del experimento
en el que los potenciales usuarios hombres son directivos.
</div>
<p><strong>Sucesos disjuntos</strong>. Dos sucesos <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> son disjuntos o mutuamente excluyentes si:</p>
<p><span class="math display">\[A \cap B = \emptyset.\]</span></p>
<p>Un suceso <span class="math inline">\(A\)</span> <strong>está contenido</strong> en otro suceso <span class="math inline">\(B\)</span>, <span class="math inline">\(A \subset B\)</span> si siempre que se
produce <span class="math inline">\(A\)</span>, se produce también <span class="math inline">\(B\)</span>.</p>
<p><strong>Diferencia de sucesos</strong>. El suceso diferencia <span class="math inline">\(A-B\)</span> es el suceso que se produce cuando
ocurre <span class="math inline">\(A\)</span> y no ocurre <span class="math inline">\(B\)</span>. Se verifica:</p>
<p><span class="math display">\[A-B = A\cap B^c.\]</span></p>
<p>La figura <a href="introp.html#fig:conjuntos">4.5</a> muestra una representación de sucesos disjuntos, sucesos incluidos en otros sucesos y diferencia de sucesos.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:conjuntos"></span>
<img src="04-introp_files/figure-html/conjuntos-1.png" alt="Representación de sucesos disjuntos (izquierda), suceso contenido en otro suceso (centro) y diferencia de sucesos (derecha)" width="90%"><p class="caption">
Figura 4.5: Representación de sucesos disjuntos (izquierda), suceso contenido en otro suceso (centro) y diferencia de sucesos (derecha)
</p>
</div>

<div class="rmdejemplo">
El suceso “ser hombre” y el suceso “ser mujer” son sucesos disjuntos (<span class="math inline">\(H \cap M = \emptyset\)</span>); El suceso “ser mujer joven” está incluido en el suceso “ser mujer”, e incluye a las mujeres jóvenes; El suceso “Ser hombre joven”,
se podría representar como <span class="math inline">\(J-M = J \cap M^c\)</span>.
</div>
<p><strong>Partición del espacio muestral</strong>. Dada una colección de sucesos <span class="math inline">\(A_1, A_2, \ldots\)</span>,
decimos que es una partición del espacio muestral <span class="math inline">\(\Omega\)</span> si:</p>
<ul>
<li><span class="math inline">\(A_1, A_2, \ldots: \quad A_i \subset \Omega \; \forall i\)</span></li>
<li>
<span class="math inline">\(A_i \cap A_j = \emptyset \; \forall i \neq j\)</span>,</li>
<li>
<span class="math inline">\(\displaystyle \underset{i}\bigcup A_i = \Omega\)</span>.</li>
</ul>
<p>La figura <a href="introp.html#fig:particion">4.6</a> representa gráficamente una partición del
espacio muestral <span class="math inline">\(\Omega\)</span> en cinco sucesos <span class="math inline">\(A_1, \ldots, A_5\)</span>.</p>
<p>Nótese que los sucesos elementales de un experimento <span class="math inline">\(\omega_i\)</span> constituyen una
partición del espacio muestral.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:particion"></span>
<img src="04-introp_files/figure-html/particion-1.png" alt="Representación de una partición del espacio muestral" width="70%"><p class="caption">
Figura 4.6: Representación de una partición del espacio muestral
</p>
</div>
<p>De la teoría de conjuntos se deducen fácilmente las siguientes propiedades
de las operaciones con sucesos:</p>
<ul>
<li>
<strong>Conmutativa</strong>:
<ul>
<li>
<span class="math inline">\(A\cup B= B\cup A\)</span>.</li>
<li>
<span class="math inline">\(A\cap B= B\cap A\)</span>.</li>
</ul>
</li>
<li>
<strong>Asociativa</strong>:
<ul>
<li>
<span class="math inline">\(A \cup (B \cup C) = (A \cup B) \cup C\)</span>.</li>
<li>
<span class="math inline">\(A \cap (B \cap C) = (A \cap B) \cap C\)</span>.</li>
</ul>
</li>
<li>
<strong>Distributiva</strong>:
<ul>
<li>
<span class="math inline">\(A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\)</span>.</li>
<li>
<span class="math inline">\(A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\)</span>.</li>
</ul>
</li>
<li>
<strong>Leyes de De Morgan</strong>:
<ul>
<li>
<span class="math inline">\((A \cup B)^c = A^c \cap B^c\)</span>.</li>
<li>
<span class="math inline">\((A \cap B)^c = A^c \cup B^c\)</span>.</li>
</ul>
</li>
<li>
<span class="math inline">\(A \cup A = A \cap A = A \cup \emptyset = A \cap \Omega = A\)</span>.</li>
<li>
<span class="math inline">\(A \cup \Omega = \Omega\)</span>.</li>
<li>
<span class="math inline">\(A \cap \emptyset = \emptyset\)</span>.</li>
</ul>
</div>
<div id="clasificación-de-los-espacios-muestrales" class="section level3" number="4.2.3">
<h3>
<span class="header-section-number">4.2.3</span> Clasificación de los espacios muestrales<a class="anchor" aria-label="anchor" href="#clasificaci%C3%B3n-de-los-espacios-muestrales"><i class="fas fa-link"></i></a>
</h3>
<p>La primera clasificación que haremos de un espacio muestral es en función
de su <em>tamaño</em>:</p>
<ul>
<li><p><strong>Finito</strong>: consta de un número finito de sucesos elementales. Por ejemplo
el lanzamiento de un dado: <span class="math inline">\(\Omega = \{1, 2, 3, 4, 5, 6 \}\)</span>.</p></li>
<li><p><strong>Infinito numerable</strong>: el resultado del experimento tiene (al menos teóricamente)
infinitos posibles resultados, pero se pueden numerar. Por ejemplo el número
de piezas correctas hasta que se
produce un fallo: <span class="math inline">\(\Omega = \{ 0, 1, 2, 3, \ldots \}\)</span>.</p></li>
<li><p><strong>Infinito no numerable</strong>: el resultado del experimento tiene
infinitos posibles resultados, que no se pueden numerar.
Por ejemplo el tiempo hasta el fallo en el
ejemplo
anterior<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Nótese que si midiéramos el tiempo, por ejemplo, en horas, sí podríamos numerar los posibles valores (0, 1, …). Pero esto es solo debido a la precisión con la que medimos, ya que teóricamente podríamos añadir toda la precisión necesaria. Esto será importante en los siguientes capítulos cuando diferenciemos las variables aleatorias discretas y continuas.&lt;/p&gt;"><sup>46</sup></a>:
<span class="math inline">\(\Omega = [0, \infty)\)</span>.</p></li>
</ul>
<div class="rmdejemplo">
Otro ejemplo de espacio muestral infinito no numerable consistiría en
el resultado de un experimento consistente en realizar
una medición de una magnitud continua que pueda tomar cualquier valor
entre, por ejemplo, 10 y 20: <span class="math inline">\(\Omega = x \in \mathbb{R}, 10 \leq x \leq 20\)</span>.
Una partición de este espacio muestral sería <span class="math inline">\(A_1 = [10, 15]\)</span>, <span class="math inline">\(A_2 = (15, 20]\)</span>.)
Nótese que los números (reales, naturales, etc.) son también conjuntos, y por tanto
las operaciones relacionadas con sucesos se extienden fácilmente a estos conjuntos.
</div>
<p>Definimos una sigma álgebra de sucesos <span class="math inline">\(\sigma\)</span>-álgebra o <span class="math inline">\(\aleph\)</span> (<em>aleph</em>) como un
conjunto de sucesos que verifican las siguientes propiedades:</p>
<ul>
<li>Pertenecen a <span class="math inline">\(\aleph\)</span>,</li>
<li>Si un suceso pertenece a <span class="math inline">\(\aleph\)</span>, entonces su suceso complementario también pertenece a <span class="math inline">\(\aleph\)</span>,</li>
<li>Si <span class="math inline">\(\{A_i\}\)</span> es un conjunto de sucesos en <span class="math inline">\(\aleph\)</span>, entonces la unión <span class="math inline">\(\displaystyle \underset{i}\bigcup A_i\)</span> y
la intersección <span class="math inline">\(\displaystyle \underset{i}\bigcap A_i\)</span> pertenecen a <span class="math inline">\(\aleph\)</span>.</li>
</ul>
<p>Nótese la diferencia entre <span class="math inline">\(\Omega\)</span> y <span class="math inline">\(\aleph\)</span>. Mientras el espacio muestral <span class="math inline">\(\Omega\)</span> es el
conjunto de todos los sucesos elementales del experimento, la <span class="math inline">\(\sigma\)</span>-álgebra de
sucesos <span class="math inline">\(\aleph\)</span> es el conjunto de todos los sucesos que podemos crear a partir
del espacio muestral <span class="math inline">\(\Omega\)</span> y las operaciones de unión, intersección y
complementariedad con esos sucesos. El par <span class="math inline">\((\Omega, \aleph)\)</span> se dice que es un <strong>espacio probabilizable</strong>.</p>

<div class="rmdejemplo">
<p>Observamos al azar el tipo de participante en el estudio de uno tomado al azar.
Entonces los posibles resultados del <em>experimento</em> o
sucesos elementales es:</p>
<p><span class="math display">\[\Omega = \{I, T, P\}\]</span></p>
<p>Haciendo todas las operaciones posibles de unión, intersección y complementariedad,
podemos llegar fácilmente a la siguiente <span class="math inline">\(\sigma\)</span>-álgebra de
sucesos:</p>
<span class="math display">\[\aleph = \{I, T, P, (I \cup T),(I \cup P), (T \cup P), \emptyset, \Omega \}\]</span>
</div>
</div>
</div>
<div id="definiciones-de-probabilidad-y-sus-propiedades" class="section level2" number="4.3">
<h2>
<span class="header-section-number">4.3</span> Definiciones de probabilidad y sus propiedades<a class="anchor" aria-label="anchor" href="#definiciones-de-probabilidad-y-sus-propiedades"><i class="fas fa-link"></i></a>
</h2>
<p>Ya hemos dicho anteriormente que la probabilidad es una medida del grado de
incertidumbre sobre el resultado de un experimento. Ahora necesitamos formalizar
la definición de probabilidad con el fin de trabajar matemáticamente
con ella.</p>
<div id="definición-clásica-o-de-laplace" class="section level3" number="4.3.1">
<h3>
<span class="header-section-number">4.3.1</span> Definición clásica o de Laplace<a class="anchor" aria-label="anchor" href="#definici%C3%B3n-cl%C3%A1sica-o-de-laplace"><i class="fas fa-link"></i></a>
</h3>
<p>La definición <em>clásica</em> de la probabilidad, también conocida
como definición de
Laplace<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Pierre-Simon Laplace (1749–1827), astrónomo y matemático francés. &lt;a href="https://es.wikipedia.org/wiki/Pierre-Simon_Laplace" class="uri"&gt;https://es.wikipedia.org/wiki/Pierre-Simon_Laplace&lt;/a&gt;.&lt;/p&gt;'><sup>47</sup></a>,
requiere disponer de un espacio muestral finito
referido a un experimento en el que todos los resultados posibles son igualmente probables.
Bajo estas condiciones, la probabilidad de un suceso cualquiera <span class="math inline">\(A\)</span> se obtiene
como el cociente entre el número de casos <em>favorables</em> al suceso, dividido
por el número total de casos <em>posibles</em> del experimento. Así:</p>
<p><span class="math display">\[P(A) = \frac{\text{casos favorables a } A}{\text{casos posibles}}.\]</span></p>
<p>Utilizaremos la definición de Laplace para asignar probabilidades a sucesos
cuando tengamos una enumeración completa del espacio muestral como en los
ejemplos anteriores.</p>

<div class="rmdejemplo">
<p>En el lanzamiento de un dado equilibrado de seis caras, la probabilidad de sacar
un seis es igual al cociente entre los casos favorables a sacar un 6 (1) y los
casos posibles del experimento (6):</p>
<p><span class="math display">\[A:\text{ Sacar un 6 en el lanzamiento de un dado}\]</span></p>
<span class="math display">\[P(A) = \frac{\text{casos favorables a } A}{\text{casos posibles}}= \frac{1}{6} \simeq 0.1667.\]</span>
</div>

<div class="rmdejemplo">
<p>En el ejemplo de los sujetos en estudio, la probabilidad de que
un sujeto al azar sea investigador es el cociente entre los casos favorables
a ser investigador (4) y los casos posibles (52):</p>
<span class="math display">\[P(I) = \frac{4}{52} = 0.0769\]</span>
</div>

<div class="rmdcafe">
Casi dos siglos antes de que Laplace publicara su <em>Teoría Analítica de las probabilidades</em>, Pascal y Fermat intercambiaron correspondencia para intentar
resolver los problemas que el <em>Caballero de Méré</em> le planteó al primero. Este
personaje era un jugador profesional de la época que planteaba estos problemas
en términos de si tenía ventaja al apostar a unos u otros resultados
en el lanzamiento de dos dados. Este fue para muchos el origen de la teoría
de la probabilidad. Una historia más detallada puede encontrarse en
<span class="citation">Fernando Corbalán and Gerardo Sanz<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;&lt;em&gt;La Conquista Del Azar. La Teoría de Probabilidades&lt;/em&gt;, Ensayo (RBA, 2010).&lt;/p&gt;"><sup>48</sup></a></span>.
</div>
</div>
<div id="ch07-defempirica" class="section level3" number="4.3.2">
<h3>
<span class="header-section-number">4.3.2</span> Definición frecuentista o empírica<a class="anchor" aria-label="anchor" href="#ch07-defempirica"><i class="fas fa-link"></i></a>
</h3>
<p>La definición clásica de probabilidad se encuentra con dificultades para
asignar probabilidades a medida que los experimentos alcanzan cierta complejidad.
Por una parte, no siempre tenemos una descripción completa del espacio muestral,
o, simplemente, es infinito, con lo cual no podemos aplicar la fórmula de Laplace.
otras veces no tenemos la información disponible necesaria. Pensemos en la
situación habitual descrita en la figura <a href="intro.html#fig:dogma1">1.1</a> al principio de este
capítulo. Queremos asignar
una probabilidad a un suceso referido a nuestra <strong>población</strong> objeto de estudio.
Sin embargo, no tenemos información de los casos posibles y favorables a la
ocurrencia del suceso. A lo sumo, tenemos acceso a una <strong>muestra</strong> de datos
de la población, a la que podemos aplicar el experimento y obtener las
<strong>frecuencias</strong> de ocurrencia de los sucesos en cuestión. Pues bien, la
definición frecuentista nos dice que si observamos la frecuencia
de ocurrencia del suceso <span class="math inline">\(A\)</span>, llamémosle <span class="math inline">\(n(A)\)</span>, en un número grande
de experimentos <span class="math inline">\(n\)</span>, la frecuencia relativa de ocurrencia del suceso <span class="math inline">\(A\)</span> <em>tiende</em>
a la probabilidad del suceso <span class="math inline">\(A\)</span>. Matemáticamente:</p>
<p><span class="math display">\[P(A) = \lim\limits_{n \to \infty} \frac{n(A)}{n}.\]</span></p>
<p>En experimentos fáciles de realizar, se puede comprobar <em>empíricamente</em>. Por
ejemplo, podemos lanzar una moneda e ir anotando la frecuencia
de caras con cada repetición. Este tipo de experimentos son también
fáciles de realizar mediante simulación. En la siguiente aplicación
se puede simular la elección de elementos de un conjunto<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Si no estás leyendo la versión html del libro puedes ver la aplicación en el siguiente enlace: &lt;a href="https://elcano.shinyapps.io/probability_as_relative_frequency/" class="uri"&gt;https://elcano.shinyapps.io/probability_as_relative_frequency/&lt;/a&gt;&lt;/p&gt;'><sup>49</sup></a>.</p>
<iframe src="https://elcano.shinyapps.io/probability_as_relative_frequency/?showcase=0" width="672" height="800px" data-external="1">
</iframe>
<p>En la práctica, utilizaremos esta definición para asignar probabilidades
a sucesos en base a datos históricos, experiencia previa, etc. En muchas
ocasiones, estos datos están disponibles en forma de porcentajes, y bastará
con dividir por 100 para transformarlos en una frecuencia relativa, que
se tomará como probabilidad.</p>

<div class="rmdejemplo">
En nuestro ejemplo de los sujetos en estudio, podemos
disponer de datos históricos que nos digan que 17 de 100 sujetos
varones respondieron al tratamiento en un estudio similar. De ahí podemos
asignar al suceso <span class="math inline">\(A=\)</span> “el sujeto masculino responde al tratamiento” una
probabilidad <span class="math inline">\(P(A)=\frac{17}{100} \approx \frac{1}{6}\)</span>, equivalente a
“uno de cada 6” que se decía en
la descripción del ejemplo.
</div>

<div class="rmdejemplo">
Históricamente, el 1% de las piezas producidas en una fábrica tienen algún
tipo de defecto. Entonces, la probabilidad de que una pieza tomada al azar
tenga defecto (<span class="math inline">\(D\)</span>) es <span class="math inline">\(P(D) = \frac{1}{100} = 0.01\)</span>.
</div>
</div>
<div id="definición-subjetivista" class="section level3" number="4.3.3">
<h3>
<span class="header-section-number">4.3.3</span> Definición subjetivista<a class="anchor" aria-label="anchor" href="#definici%C3%B3n-subjetivista"><i class="fas fa-link"></i></a>
</h3>
<p>En las dos definiciones anteriores de probabilidad, hemos asignado probabilidades
a sucesos en base a unos determinados datos, bien de recuento de posibilidades,
bien de frecuencias relativas. En ocasiones, no se dispone de absolutamente
ningún dato de este tipo. Entonces las probabilidades se han de asignar de
forma subjetiva, fijadas por un individuo en particular como su
<em>grado de creencia</em> acerca de la ocurrencia de un suceso. El individuo fija
un valor entre cero y uno en base a la evidencia de que dispone, que puede
incluir juicios personales, y también interpretaciones <em>a priori</em> sobre las dos
concepciones anteriores de la probabilidad, clásica y frecuentista. Por ejemplo,
puede considerar la frecuencia relativa de fenómenos similares, y combinar esta
información con sus conocimientos y percepciones sobre la materia de estudio.</p>
<p>El enfoque subjetivista tiene especial interés en fenómenos que no se prestan
a repetición, así como en métodos de estadística Bayesiana, donde se fija
una probabilidad <em>a priori</em> de los parámetros de la
población<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;En el enfoque &lt;em&gt;frecuentista&lt;/em&gt;, que es el que sigue este libro, los parámetros de la población son fijos, aunque desconocidos.&lt;/p&gt;"><sup>50</sup></a>.
Existen métodos
específicos para asignar probabilidades subjetivas
de forma racional, que quedan fuera de los objetivos de este libro, véase, por
ejemplo, <span class="citation">Bruno de Finetti<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span&gt;“Foresight: Its Logical Laws, Its Subjective Sources,”&lt;/span&gt; in &lt;em&gt;Breakthroughs in Statistics: Foundations and Basic Theory&lt;/em&gt;, ed. Samuel Kotz and Norman L. Johnson (New York, NY: Springer New York, 1992), 134–74, &lt;a href="https://doi.org/10.1007/978-1-4612-0919-5_10" role="doc-biblioref"&gt;https://doi.org/10.1007/978-1-4612-0919-5_10&lt;/a&gt;.&lt;/p&gt;'><sup>51</sup></a></span>.</p>

<div class="rmdejemplo">
¿Cuál es la probabilidad de que me contraten en mi primera entrevista de trabajo?
¿Cuál es la probabilidad de que un proyecto de inversión determinado sea rentable?
Podemos <em>asignar</em> probabilidades, pero no tenemos información previa acerca
de las frecuencias relativas o casos favorables/posibles.
</div>
</div>
<div id="definición-en-iso-3534-1" class="section level3" number="4.3.4">
<h3>
<span class="header-section-number">4.3.4</span> Definición en ISO 3534-1<a class="anchor" aria-label="anchor" href="#definici%C3%B3n-en-iso-3534-1"><i class="fas fa-link"></i></a>
</h3>
<p>La definición estandarizada que proporciona la norma UNE-ISO 3534-1 es la
siguiente para la probabilidad de un suceso <span class="math inline">\(A\)</span>:</p>
<blockquote>
<p><strong>Probabilidad de un suceso <span class="math inline">\(A\)</span>; <span class="math inline">\(P(A)\)</span></strong></p>
<p>Número real del intervalo cerrado <span class="math inline">\([0, 1]\)</span> asignado a un suceso</p>
<p>— ISO 3534-1 2.5</p>
</blockquote>
<p>Nótese que en el estándar no se entra en detalles matemáticos por el bien
de la aplicabilidad en los procesos empresariales. No obstante, esta
definición es en esencia compatible y congruente con el resto de definiciones
de probabilidad.</p>
</div>
<div id="definición-axiomática" class="section level3" number="4.3.5">
<h3>
<span class="header-section-number">4.3.5</span> Definición axiomática<a class="anchor" aria-label="anchor" href="#definici%C3%B3n-axiom%C3%A1tica"><i class="fas fa-link"></i></a>
</h3>
<p>Si bien todas las definiciones anteriores son válidas y útiles en determinados
contextos, todas presentaban problemas para desarrollar una teoría de
probabilidades que se pudiera aplicar a cualquier espacio probabilizable. La
siguiente definición
axiomática<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;O axiomática de &lt;em&gt;Kolmogorov&lt;/em&gt;, por Andrei Nikolaevich Kolmogorov (1903–1987), matemático ruso.&lt;/p&gt;"><sup>52</sup></a>
resolvió estos problemas.</p>
<p>Una probabilidad <span class="math inline">\(\wp\)</span> es una función:</p>
<p><span class="math display">\[
\begin{split}
\wp: &amp; \; \aleph \longrightarrow [0, 1]\\
&amp; A \longrightarrow P(A)
\end{split}
\]</span></p>
<p>que cumple:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Primer axioma</strong>: <span class="math inline">\(\forall A \in \aleph \; \exists \; P(A) \geq 0\)</span>.</p></li>
<li><p><strong>Segundo axioma</strong>: <span class="math inline">\(P(\Omega) = 1\)</span>.</p></li>
<li><p><strong>Tercer axioma</strong>: Dada la sucesión <span class="math inline">\(A_1, \ldots, A_i, \ldots: A_i \in \aleph \; \forall\, i, A_i \cap A_j = \emptyset \; \forall i \neq j\)</span>, se cumple:</p></li>
</ol>
<p><span class="math display">\[P \left (\bigcup\limits_{i=1}^{\infty} A_i \right ) = \sum\limits_{i=1}^{\infty} P(A_i).\]</span></p>
<p>En lenguaje natural, el primer axioma indica que a cada suceso le podemos asignar un número no negativo llamado “probabilidad del suceso <span class="math inline">\(A\)</span>”; el segundo axioma asigna al suceso seguro una
probabilidad igual a 1; el tercer axioma establece la forma de calcular probabilidades a la
unión de sucesos <strong>disjuntos</strong> o mutuamente excluyentes, mediante la suma de sus
respectivas probabilidades. Nótese que la formulación del axioma es válida para espacios
muestrales infinitos (numerables y no numerables).</p>
<p>A partir de estos tres axiomas, se deducen los siguientes teoremas:</p>
<ol style="list-style-type: decimal">
<li>Dados <span class="math inline">\(n\)</span> sucesos disjuntos dos a dos <span class="math inline">\(A_1, \ldots, A_n: A_i \cap A_j = \emptyset \; \forall i \neq j\)</span>:</li>
</ol>
<p><span class="math display">\[P \left (\bigcup\limits_{i=1}^{n} A_i \right ) = \sum\limits_{i=1}^{n} P(A_i).\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><p><span class="math inline">\(P(A^c)=1-P(A)\)</span>.</p></li>
<li><p><span class="math inline">\(P(\emptyset) = 0\)</span>.</p></li>
<li><p>Dados <span class="math inline">\(A_1, A_2: A_1 \subset A_2 \implies P(A_1) \leq P(A_2)\)</span>.</p></li>
<li><p><span class="math inline">\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</span>.</p></li>
<li><p><span class="math inline">\(P(\bigcup\limits_{i=1}^n A_i) = \sum\limits_{i=1}^n P(A_i) - \sum\limits_{i&lt;j} P(A_i \cap A_j) + \sum\limits_{i&lt;j&lt;k} P(A_i \cap A_j \cap A_k) -\)</span><br><span class="math inline">\(- \ldots + (-1)^{n-1} P \left(\bigcap\limits_{i=1}^n A_i\right ).\)</span></p></li>
</ol>
<p>El primer teorema particulariza el tercer axioma a un conjunto finito de sucesos disjuntos del espacio muestral. El segundo teorema es una de las propiedades que más aplicaremos en cálculo
de probabilidades, y nos indica cómo calcular la probabilidad de un suceso restándole a 1 la probabilidad de su complementario. El tercer teorema es una consecuencia del anterior y del primer axioma, por los cuales la probabilidad del suceso imposible es cero. El cuarto teorema es
de vital importancia cuando trabajemos con variables aleatorias y nos viene a decir que si un
suceso está contenido en otro, la probabilidad del primero no puede ser mayor que la del segundo.
Los teoremas quinto y sexto nos permiten calcular probabilidades de la unión de cualesquiera
conjuntos, sean o no disjuntos. Una consecuencia fundamental de las propiedades de la probabilidad es:</p>
<p><span class="math display">\[ \boxed{0 \leq P(A) \leq 1}.\]</span></p>
<p>La demostración de estos teoremas se puede encontrar, entre otros, en
<span class="citation">M. D. Ugarte, A. F. Militino, and A. T. Arnholt<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;&lt;em&gt;Probability and Statistics with r, Second Edition&lt;/em&gt; (CRC Press, 2015).&lt;/p&gt;"><sup>53</sup></a></span>. Asímismo, se puede comprobar fácilmente cómo las definiciones clásicas y frecuentistas cumplen todas estas
propiedades y por lo tanto son coherentes con la definición axiomática de la probabilidad.</p>

<div class="rmdejemplo">
<p><em>Lanzamiento de un dado de seis caras</em>. Sean los siguientes sucesos:</p>
<ul>
<li>
<span class="math inline">\(A_1:\)</span> “número impar”; <span class="math inline">\(A_1 = \{1, 3, 5\}\)</span>.</li>
<li>
<span class="math inline">\(A_2:\)</span> “número par”; <span class="math inline">\(A_2 = \{2, 4, 6\}\)</span>.</li>
<li>
<span class="math inline">\(A_3:\)</span> “número mayor que 4”; <span class="math inline">\(A_3 = \{5, 6\}\)</span>.</li>
<li>
<span class="math inline">\(A_4:\)</span> “número menor o igual que 4”; <span class="math inline">\(A_4 = \{1, 2, 3, 4\}\)</span>.</li>
</ul>
<p>Podemos calcular cualquiera de estas probabilidades por la definición de Laplace, ya
que los resultados elementales del experimento son equiprobables. Así:</p>
<p><span class="math display">\[P(A_1) = \frac{1}{2}=0.5=P(A_2); P(A_3) = \frac{2}{6}\simeq 0.3333; P(A_4)=\frac{4}{6}\simeq 0.6667.\]</span></p>
<p>Por simple enumeración de los casos posibles podemos calcular las probabilidades de los siguientes sucesos:</p>
<ul>
<li><p><span class="math inline">\(A_1 \cup A_3:\)</span> “número impar o mayor que cuatro”; <span class="math inline">\(A_1 \cup A_3=\{1,3,5,6\}\)</span>; <span class="math inline">\(P(A_1 \cup A_3)=\frac{4}{6} \simeq 0.6667\)</span>.</p></li>
<li><p><span class="math inline">\(A_1 \cap A_3:\)</span> “número impar y mayor que cuatro”; <span class="math inline">\(A_1 \cap A_3=\{5\}\)</span>;
<span class="math inline">\(P(A_1 \cap A_3)=\frac{1}{6} \simeq 0.1667\)</span>.</p></li>
<li><p>Y así sucesivemente para cada posible suceso <span class="math inline">\(A\)</span> subconjunto del espacio muestral <span class="math inline">\(\Omega=\{1,2,3,4,5,6\}\)</span>.</p></li>
</ul>
<p>Ahora bien, también podemos aplicar las propiedades de la probabilidad sin necesidad de enumerar
o contar todas las posibilidades. Por ejemplo, conocidos <span class="math inline">\(P(A_1), P(A_3)\)</span> Y <span class="math inline">\(P(A_1\cap A_3)\)</span>:</p>
<ul>
<li>
<span class="math inline">\(P(A_1 \cup A_3)=P(A_1) + P(A_3) - P(A_1 \cap A_3) = 0.5 + 0.3333 - 0.1667 \simeq 0.6667\)</span>,</li>
</ul>
<p>que conduce, obviamente, al mismo resultado. A medida que aumentan la complejidad de los experimentos, con espacios muestrales más grandes, o incluso infinitos, se hace dificultoso o imposible trabajar con enumeraciones, y es donde hay que aplicar la defición axiomática de la probabilidad.</p>
</div>

<div class="rmdejemplo">
<p>En nuestro ejemplo del estudio, podríamos estar
interesados en el suceso “ser mujer o joven”. Este suceso se
correspondería con el suceso <span class="math inline">\(M \cup J\)</span>. Para calcular esta probabilidad,
tendríamos en cuenta, según los datos del ejemplo, que <span class="math inline">\(P(M) = \frac{1}{2}=0.5\)</span>, <span class="math inline">\(P(J) = \frac{13}{52}=0.25\)</span>, y <span class="math inline">\(P(M \cap J)=\frac{5}{52}\simeq 0.0962\)</span>. Entonces:</p>
<p><span class="math display">\[P(M \cup J)=P(M)+P(J)-P(M\cap J)=0.5+0.25-0.0962 \simeq 0.6538.\]</span></p>
</div>
<p>En los anteriores ejemplos hemos utilizado solamente el teorema referido
a la probabilidad de la unión de sucesos. El teorema de la probabilidad
del suceso complementario va a ser la propiedad que más utilizaremos en
cálculo de probabilidades, dado que, en muchas ocasiones, es más sencillo
abordar el problema desde el punto de vista del suceso complementario.
Un ejemplo es la <em>paradoja de los cumpleaños</em>.</p>

<div class="rmdcafe">
<p>Si el día de nuestro cumpleaños asistimos a algún evento en el que haya
más de 30 personas, es muy probable que nos canten el cumpleaños feliz
a más de una persona.
Supongamos una clase de 30 alumnos.
¿Cuál es la probabilidad de que al menos dos alumnos
cumplan años el mismo, día?.
Abordar el problema directamente implicaría gran cantidad
de consideraciones y costosos cálculos hasta llegar a la solución, porque
habría que considerar todos los casos posibles y después calcular probabilidades
de uniones e intersecciones. Sin embargo,
se resuelve de forma casi inmediata sin consideramos la probabilidad del suceso
complementario. Es decir, si:</p>
<p><span class="math inline">\(A:\)</span> Al menos dos personas de un grupo de 30 cumplen años el mismo día,</p>
<p>entonces el suceso complementario es:</p>
<p><span class="math inline">\(A^c\)</span>: No hay dos personas en un grupo de 30 que cumplen años el mismo día.</p>
<p>Nótese cómo la probababilidad sería igual a 1 si el grupo de personas fuera
de 365 personas o
más<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Si no tenemos en cuenta los años bisiestos.&lt;/p&gt;"><sup>54</sup></a>,
ya que en ese caso el suceso sería un suceso seguro. En este caso, el espacio muestral
estará compuesto por el número de maneras que tendríamos de ordenar 30
fechas de nacimiento dentro de un año (día-mes), para un conjunto total de 365 días
diferentes que tiene el año. Obviamente se pueden repetir las fechas, y por
tanto el número total de casos posibles se corresponde con las variaciones con
repetición de 365 elementos tomados de 30 en 30:</p>
<p><span class="math display">\[\mathit{VR}_{m,n} = m^n = 365^{30} \simeq  7.392\cdot 10^{76}.\]</span></p>
<p>Para calcular el número de casos favorables a que nadie cumpla años el mismo día, fijamos el
cumpleaños de la primera persona. Entonces la siguiente persona pueden cumplir años cualquiera
de los 364 días restantes; fijados los dos primeros, la tercera persona puede cumplir años cualquiera de los 363 días restantes, y así sucesivamente. Por tanto, los casos favorables son las variaciones (sin repetición):</p>
<p><span class="math display">\[\mathit{V}_{m,n}=365\times 364 \times \ldots \times (365-30+1) \simeq 2.171\cdot 10^{76}\]</span></p>
<p>y entonces:</p>
<span class="math display">\[P(A) = 1-P(A^c) = 1- \frac{2.171\cdot 10^{76}}{7.392\cdot 10^{76}}\simeq 0.7063.\]</span>
Intuitivamente nos parecería una probabilidad demasiado alta para un grupo tan pequeño de personas,
por eso nos sorprendemos cuando escuchamos un <em>cumpleaños feliz</em> el día de nuestro cumpleaños en un lugar concurrido y no es para nosotros. Como vemos, no es tan difícil.
</div>

<div class="rmdpractica">
<p>Para obtener los casos favorables, si intentamos utilizar la fórmula de
las variaciones utilizando los factoriales (ver apéndice <a href="repaso.html#combinatoria">D.2</a>),
la calculadora y el software pueden devolver un error, por no poder calcular
el factorial de 365.</p>
<p><strong>HOJA DE CÁLCULO</strong></p>
<p>Disponemos en el rango <code>A1:A30</code> los números del 365 (m) al 336 (m - n + 1). Entonces
podemos obtener la probabilidad del ejemplo como:</p>
<p><code>=1-PRODUCTO(A1:A30)/(365^30)</code></p>
<p><strong>MAXIMA</strong></p>
<p>Maxima sí puede trabajar con números grandes, la siguiente expresión devuelve
la probabilidad pedida:</p>
<p><code>1 - (factorial(365)/factorial(365-30))/365^30;</code></p>
<p><strong>R</strong></p>
<p>El siguiente código realiza los cálculos paso a paso y devuelve la probabilidad pedida. Cambiando el valor <code>30</code> por otro número de personas cualquiera, se
puede ver cómo aumenta la probabilidad.</p>
</div>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ncumple</span> <span class="op">&lt;-</span> <span class="fl">30</span>
<span class="va">cposibles</span> <span class="op">&lt;-</span> <span class="fl">365</span><span class="op">^</span><span class="va">ncumple</span>
<span class="va">cfavorables</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/prod.html">prod</a></span><span class="op">(</span><span class="fl">365</span><span class="op">:</span><span class="op">(</span><span class="fl">365</span> <span class="op">-</span> <span class="va">ncumple</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="va">prob_ninguno</span> <span class="op">&lt;-</span> <span class="va">cfavorables</span><span class="op">/</span><span class="va">cposibles</span>
<span class="va">prob_alguno</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">cfavorables</span><span class="op">/</span><span class="va">cposibles</span>
<span class="va">prob_alguno</span>
<span class="co">#&gt; [1] 0.7063162</span></code></pre></div>
<p>Una vez definida la medida de probabilidad <span class="math inline">\(\wp\)</span> con los axiomas y propiedades
anteriores, llamamos <strong>espacio de probabilidad</strong> a la terna:</p>
<p><span class="math display">\[(\Omega, \aleph, \wp).\]</span></p>
<p>El estándar UNE-ISO 3534-1 recoge la definición axiomática de la probabilidad
de la siguiente forma:</p>
<blockquote>
<p><strong>sigma álgebra de sucesos; <span class="math inline">\(\sigma\)</span>-álgebra; sigma campo; <span class="math inline">\(\sigma\)</span>-campo; <span class="math inline">\(\aleph\)</span></strong></p>
<p>Conjunto de sucesos con las siguientes propiedades:</p>
<ol style="list-style-type: lower-alpha">
<li><p>Pertenecen a <span class="math inline">\(\aleph\)</span>;</p></li>
<li><p>Si un suceso pertenece a <span class="math inline">\(\aleph\)</span>, entonces su suceso complementario también pertenece a <span class="math inline">\(\aleph\)</span>;</p></li>
<li><p>Si <span class="math inline">\(\{A_i\}\)</span> es un conjunto de sucesos en <span class="math inline">\(\aleph\)</span>, entonces la unión <span class="math inline">\(\displaystyle\underset{i}\bigcup A_i\)</span> y
la intersección <span class="math inline">\(\displaystyle \underset{i}\bigcap A_i\)</span> de los sucesos pertenecen a <span class="math inline">\(\aleph\)</span>.</p></li>
</ol>
<p>— ISO 3534-1 2.69</p>
</blockquote>
<blockquote>
<p><strong>Medida de probabilidad <span class="math inline">\(\wp\)</span></strong></p>
<p>Función no negativa definida sobre la sigma álgebra de sucesos tal que</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\wp(\Omega) = 1\)</span></li>
</ol>
<p>donde <span class="math inline">\(\Omega\)</span> denota el espacio muestral</p>
<ol start="2" style="list-style-type: lower-alpha">
<li><span class="math inline">\(\wp \left (\bigcup\limits_{i=1}^{\infty} A_i \right ) = \sum\limits_{i=1}^{\infty} \wp(A_i)\)</span></li>
</ol>
<p>donde <span class="math inline">\(\{A_i\}\)</span> es una secuencia de pares de sucesos disjuntos</p>
<p>— ISO 3534-1 2.70</p>
</blockquote>
<blockquote>
<p><strong>Espacio de probabilidad (o espacio probabilístico); <span class="math inline">\((\Omega, \aleph, \wp)\)</span></strong></p>
<p>Espacio muestral, una sigma álgebra de sucesos asociada, y una medida de probabilidad.</p>
<p>— ISO 3534-1 2.68</p>
</blockquote>
</div>
</div>
<div id="probabilidad-condicionada-y-sus-consecuencias" class="section level2" number="4.4">
<h2>
<span class="header-section-number">4.4</span> Probabilidad condicionada y sus consecuencias<a class="anchor" aria-label="anchor" href="#probabilidad-condicionada-y-sus-consecuencias"><i class="fas fa-link"></i></a>
</h2>
<div id="probabilidad-condicionada" class="section level3" number="4.4.1">
<h3>
<span class="header-section-number">4.4.1</span> Probabilidad condicionada<a class="anchor" aria-label="anchor" href="#probabilidad-condicionada"><i class="fas fa-link"></i></a>
</h3>
<p>El concepto de <strong>probabilidad condicionada</strong> es uno de los más importantes
en teoría de la probabilidad. En ocasiones,
la ocurrencia o no de ciertos sucesos del espacio muestral puede estar afectada
por otros sucesos del espacio muestral. Por ejemplo, desde el punto de vista
de la definición de probabilidad de Laplace, en experimentos secuenciales
<span class="math inline">\(A_1, \ldots, A_n\)</span>,
es posible que los resultados de los sucesivos experimentos influyan
en los resultados de los siguientes, y entonces
hablaremos, por ejemplo, de la probabilidad del suceso <span class="math inline">\(A_2\)</span> condicionada
a que ha ocurrido el suceso <span class="math inline">\(A_1\)</span>, y la calcularemos enumerando
los casos favorables y los casos posibles bajo el supuesto de haber
sucedido <span class="math inline">\(A_1\)</span>. Esta situación aparece, por ejemplo, en los problemas de urnas.
Desde el
punto de vista de la definición frecuentista de la probabilidad, podemos
considerar un experimento en el que se observen un suceso <span class="math inline">\(A\)</span> en distintos
grupos o localizaciones, siendo <span class="math inline">\(B\)</span> el suceso que indica la pertenencia a
ese determinado grupo o característica.
Se pueden considerar las frecuencias relativas del suceso <span class="math inline">\(A\)</span> sólo
para aquellos experimentos en los que ha sucedido <span class="math inline">\(B\)</span>, y llamar a estas
frecuencias<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Nótese la analogía con las frecuencias marginales utilizadas en el capítulo 3.&lt;/p&gt;"><sup>55</sup></a>
<em>frecuencias</em> de <span class="math inline">\(A\)</span> <em>condicionadas</em> a <span class="math inline">\(B\)</span>, <span class="math inline">\(fr_{A|B}\)</span>.
Estas frecuencias relativas las podemos calcular dividiendo el número de veces que
ocurren tanto <span class="math inline">\(A\)</span> como <span class="math inline">\(B\)</span> <span class="math inline">\((n_{AB})\)</span> entre el número total de veces que ocurre <span class="math inline">\(B\)</span>, <span class="math inline">\((n_{B})\)</span>:</p>
<p><span class="math display">\[fr_{A | B}=\frac{n_{AB}}{n_B}.\]</span></p>
<p>Ahora bien, como <span class="math inline">\(fr_A= \frac{n_A}{n}\)</span>, <span class="math inline">\(fr_B= \frac{n_B}{n}\)</span> y <span class="math inline">\(fr_{AB}= \frac{n_{AB}}{n}\)</span>,
se tiene:</p>
<p><span class="math display">\[fr_{A | B}=\frac{n\cdot fr_{AB}}{n\cdot fr_B}=\frac{fr_{AB}}{fr_B}.\]</span></p>
<p>Es decir, la frecuencia condicionada es igual a la frecuencia conjunta dividido
por la frecuencia marginal del suceso condicionante. Así pues, dado que para un número grande de realizaciones del experimento, las
frecuencias relativas equivalen a la probabilidad, podemos definir la
probabilidad del suceso <span class="math inline">\(A\)</span> condicionada al suceso <span class="math inline">\(B\)</span> como:</p>
<p><span class="math display">\[\boxed{P(A | B)=\frac{P(A \cap B)}{P(B)}},\]</span></p>
<p>siempre y cuando <span class="math inline">\(P(B) &gt; 0\)</span>. Se demuestra
fácilmente<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Comprobando que se cumplen los tres axiomas de la definición axiomática.&lt;/p&gt;"><sup>56</sup></a>
que esta definición de probabilidad condicionada cumple
que dado un suceso <span class="math inline">\(A \in \aleph\)</span>, <span class="math inline">\((\Omega, \aleph, \wp(\cdot|A)\)</span> es un espacio de
probabilidad.</p>

<div class="rmdejemplo">
<p>La tabla <a href="introp.html#tab:fcond">4.1</a> contiene las frecuencias con las que se
han observado los sucesos <em>aprobar</em> y <em>suspender</em> dos elementos evaluables
de una asignatura: un examen y un trabajo.</p>
<p>Designemos <span class="math inline">\(AE\)</span> y <span class="math inline">\(SE\)</span> a los sucesos “aprobar el examen” y “suspender el examen”
respectivamente, y <span class="math inline">\(AT\)</span> y <span class="math inline">\(ST\)</span> a los sucesos “aprobar el trabajo” y “suspender”
el trabajo respectivamente. La probabilidad de aprobar el examen será:</p>
<p><span class="math display">\[P(AE)=\frac{40}{100} = 0.4.\]</span></p>
<p>Si incluimos más información a modo de condición, podemos calcular por ejemplo
la probabilidad de aprobar el examen condicionado a que se ha aprobado el trabajo:</p>
<p><span class="math display">\[P(AE | AT)=\frac{P(AE \cap AT)}{P(AT)}=\frac{30/100}{35/100} \simeq 0.8571 .\]</span></p>
</div>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:fcond">Tabla 4.1: </span>Datos ejemplo probabilidad condicionada</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">Trabajo aprobado</th>
<th align="right">Trabajo suspenso</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Examen aprobado</td>
<td align="right">30</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="left">Examen suspenso</td>
<td align="right">5</td>
<td align="right">55</td>
</tr>
</tbody>
</table></div>
<div class="rmdejemplo">
En nuestro ejemplo de sujetos en estudio aparece la probabilidad
condicionada de la siguiente forma. Se dice que uno de cada seis hombres responde al tratamiento.
Si definimos <span class="math inline">\(S\)</span> como el suceso “responder al tratamiento”,
entonces <span class="math inline">\(P(S|H)=\frac{1}{6}\simeq 0.1667\)</span>. Por otra parte, si quisiéramos calcular
la probabilidad de que un sujeto sea mujer, condicionado a que
es joven, entonces <span class="math inline">\(P(M | J)=\frac{P(M \cap J)}{P(J)} = \frac{5/52}{13/52}\simeq 0.3846\)</span>.
</div>
</div>
<div id="probabilidad-de-la-intersección-de-sucesos" class="section level3" number="4.4.2">
<h3>
<span class="header-section-number">4.4.2</span> Probabilidad de la intersección de sucesos<a class="anchor" aria-label="anchor" href="#probabilidad-de-la-intersecci%C3%B3n-de-sucesos"><i class="fas fa-link"></i></a>
</h3>
<p>La definición de probabilidad condicionada a la que hemos llegado, nos
permite calcular la probabilidad de la intersección de dos sucesos
cualesquiera sin más que despejar de la fórmula. Además, tendremos dos formas
de calcularla, según conozcamos <span class="math inline">\(P(A|B)\)</span> o <span class="math inline">\(P(B|A)\)</span>:</p>
<p><span class="math display">\[\boxed{P(A\cap B)=P(A|B)\cdot P(B)=P(B|A)\cdot P(A)}.\]</span></p>
<p>Recuerda que <span class="math inline">\(A \cap B\)</span> significa <em>A</em> <strong>y</strong> <em>B</em>, mientras que
<span class="math inline">\(A|B\)</span> significa <em>A</em> <strong>si</strong> ocurre <em>B</em>.</p>

<div class="rmdejemplo">
<p>La probabilidad condicionada aparece en los muestreos sin reemplazamiento. Se suele
asociar a los problemas <em>de urnas</em>, o también a la extracción de cartas de una
baraja. Por ejemplo, podemos calcular la probabilidad de sacar dos figuras
seguidas de una baraja de cartas francesa, con 52 cartas en total de las cuales
12 son figuras (J, Q, K de cada uno de los cuatro palos). Entonces, si definimos
<span class="math inline">\(A_1\)</span> como “sacar figura en la primera extracción” y <span class="math inline">\(A_2\)</span> como “sacar figura
en la segunda extracción”, entonces lo que buscamos es la probabilidad de que
ocurran los dos sucesos, <span class="math inline">\(P(A_1 \cap A_2)\)</span>:</p>
<span class="math display">\[P(A_1 \cap A_2)=P(A_1)\cdot P(A_2 | A_1)=\frac{12}{52}\cdot \frac{11}{51}=\frac{11}{221}\simeq 0.0498.\]</span>
</div>

<div class="rmdejemplo">
<p>En nuestro ejemplo de los sujetos en estudio, ¿cuál es la probabilidad de que un sujeto al azar sea mujer y además responda al tratamiento?</p>
<span class="math display">\[P(M \cap S) = P(S|M)\cdot P(M) = \frac{2}{6}\cdot \frac{1}{2} = \frac{1}{6}\simeq 0.1667.\]</span>
</div>
<p>A partir de la probabilidad condicionada se llega a la <strong>regla de la cadena</strong>
para calcular la probabilidad de la intersección de una serie de sucesos. La regla
consiste en ir multiplicando cada vez la probabilidad del suceso <span class="math inline">\(A_i\)</span> condicionada
a la intersección de todos los anteriores.</p>
<p><span class="math display">\[P\left( \bigcap\limits_{i=1}^{n} A_i \right) = P(A_1)\cdot P(A_2|A_1)\cdot P(A_3|A_1 \cap A_2)\cdot\ldots\cdot P\left(A_n | \bigcap\limits_{i=1}^{n-1} S_i \right). \]</span></p>

<div class="rmdejemplo">
<p>Por ejemplo, en una urna hay 5 bolas rojas y 3 bolas blancas. Hacemos 3
extracciones. Si en una extracción sale blanca, devolvemos la bola
a la urna y metemos 2 bolas blancas adicionales. ¿Qué probabilidad
hay de sacar 3 blancas seguidas?</p>
<p>Si definimos los sucesos <span class="math inline">\(A_1\)</span>, <span class="math inline">\(A_2\)</span> y <span class="math inline">\(A_3\)</span> como “sacar bola blanca en la primera,
segunda y tercera extracción respectivamente”, entonces estamos buscando:</p>
<p><span class="math display">\[P(A_1 \cap A_2 \cap A_3),\]</span>
que utilizando la regla de la cadena calcularemos como:</p>
<p><span class="math display">\[P(A_1)\cdot P(A_2|A_1) \cdot P(A_3|A_1 \cap A_2).\]</span></p>
<p>En la situación inicial hay 3 de ocho bolas blancas. En el segundo experimento,
si hemos sacado blanca, la devolvemos y añadimos dos más, es decir tenemos 5 de diez
bolas blancas. si la segunda vuelve a ser blanca, entonces en el tercer experimento
tenemos 7 de 12 bolas blancas. Por lo tanto:</p>
<span class="math display">\[P(A_1 \cap A_2 \cap A_3)= \frac{3}{8}\cdot \frac{5}{10} \cdot \frac{7}{12}=\frac{7}{64}\simeq 0.1094.\]</span>
</div>
</div>
<div id="independencia-de-sucesos" class="section level3" number="4.4.3">
<h3>
<span class="header-section-number">4.4.3</span> Independencia de sucesos<a class="anchor" aria-label="anchor" href="#independencia-de-sucesos"><i class="fas fa-link"></i></a>
</h3>
<p>Si bien en muchas ocasiones el conocimiento de ciertos eventos afectan a la
probabilidad de ocurrencia de otros, esto no siempre tiene por qué ser así.
En estos casos, diremos que dos sucesos son independientes si el conocimiento
de la ocurrencia de uno de ellos no modifica la probabilidad de aparición del otro.
Por tanto, en esos casos:</p>
<p><span class="math display">\[P(A|B) = P(A)\quad \text{y}\quad P(B|A) = P(B).\]</span></p>
<p>Entonces, por la propia definición de la probabilidad condicionada, se tiene que
si dos sucesos son independientes, entonces:</p>
<p><span class="math display">\[\boxed{P(A\cap B)=P(A)\cdot P(B)}.\]</span>
Esta fórmula, que es una definición en sí misma de independendencia de sucesos, nos
proporciona también un método para comprobar si dos sucesos son independientes o no
conocidas las probabilidades de los mismos y la de la
intersección<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Comprobar, por ejemplo, la independencia de los sucesos “aprobar el trabajo” y “aprobar el examen” en el ejemplo anterior.&lt;/p&gt;"><sup>57</sup></a>.</p>
<p>Para más de dos sucesos, la regla de la cadena explicada más arriba se
extiende inmediatamente de forma que la probabilidad de la intersección de <span class="math inline">\(n\)</span> sucesos independientes es el producto de sus probabilidades:</p>
<p><span class="math display">\[P(A_1\cap \ldots \cap A_n)=P(A_1) \cdot \ldots \cdot P(A_n).\]</span>
Y en el caso particular de que los <span class="math inline">\(n\)</span> sucesos sean equiprobables, tales que <span class="math inline">\(P(A_i) = p \;\forall i\)</span>, entonces:</p>
<p><span class="math display">\[P(A_1\cap \ldots \cap A_n)=p^n.\]</span></p>
<p>El lanzamiento sucesivo de una moneda o de un dado son claros ejemplos de sucesos independientes.</p>

<div class="rmdejemplo">
<p>En el lanzamiento de un dado dos veces seguidas (o lo que es lo mismo, en el lanzamiento
de dos dados), el resultado del primero no influye en el segundo. Por tanto, la
probabilidad de sacar dos seises en el lanzamiento de dos dados es:</p>
<span class="math display">\[P(A_1 \cap A_2)= \frac{1}{6}\cdot \frac{1}{6}=\frac{1}{36}\simeq 0.0278.\]</span>
Nótese que podemos llegar fácilmente al mismo resultado enumerando los posibles resultados,
pero con más esfuerzo. Además, en espacios muestrales más grandes se complica
enormemente la enumeración.
</div>
</div>
<div id="probabilidad-condicionada-e-independencia-en-iso-3534-1" class="section level3" number="4.4.4">
<h3>
<span class="header-section-number">4.4.4</span> Probabilidad condicionada e independencia en ISO 3534-1<a class="anchor" aria-label="anchor" href="#probabilidad-condicionada-e-independencia-en-iso-3534-1"><i class="fas fa-link"></i></a>
</h3>
<p>La norma UNE-ISO 3534-1 recoge las definiciones de probabilidad condicionada
e independencia de la siguiente forma:</p>
<blockquote>
<p><strong>Probabilidad condicionada; <span class="math inline">\(P(A|B)\)</span></strong></p>
<p>Probabilidad de la intersección de <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> dividida por la probabilidad de <span class="math inline">\(B\)</span>.</p>
<p>— ISO 3534-1 2.6</p>
</blockquote>
<blockquote>
<p><strong>Sucesos independientes</strong></p>
<p>Par de sucesos tal que la probabilidad de la intersección de los dos sucesos es el producto de las probabilidades individuales.</p>
<p>— ISO 3534-1 2.4</p>
</blockquote>
</div>
<div id="probabilidad-total-y-fórmula-de-bayes" class="section level3" number="4.4.5">
<h3>
<span class="header-section-number">4.4.5</span> Probabilidad total y fórmula de Bayes<a class="anchor" aria-label="anchor" href="#probabilidad-total-y-f%C3%B3rmula-de-bayes"><i class="fas fa-link"></i></a>
</h3>
<p>La probabilidad condicionada nos permite calcular probabilidades de sucesos
de los que tenemos información <em>parcial</em>, en el sentido de que conocemos
su probabilidad <em>condicionada</em> a algún otro suceso del espacio muestral,
pero queremos saber la probabilidad <em>total</em> del suceso, independientemente
de aquellos sucesos. Las condiciones para que podamos calcular la probabilidad
total de este suceso, llamémosle <span class="math inline">\(B\)</span>, son:</p>
<ul>
<li><p>Disponer de una <strong>partición</strong> de sucesos del espacio muestral <span class="math inline">\(A_1, A_2, \ldots, A_n\)</span>
tales que <span class="math inline">\(A_i \cap A_j = \emptyset \; \forall i \neq j\)</span> y <span class="math inline">\(\displaystyle \underset{i=1}{\overset{n}\bigcup A_i} = \Omega\)</span>.</p></li>
<li><p>Conocer las probabilidades de cada uno de esos sucesos que forman la partición, <span class="math inline">\(P(A_i)\)</span>.</p></li>
<li><p>Conocer las probabilidades del suceso de interés condicionadas a cada uno de los sucesos
que forman la partición del espacio muestral, es decir, <span class="math inline">\(P(B|A_i)\)</span>.</p></li>
</ul>
<p>Entonces, según el <strong>teorema de la probabilidad total</strong>, se verifica que:</p>
<p><span class="math display">\[\boxed{P(B)=\sum\limits_{i=1}^{n} P(B/A_i)\cdot P(A_i)}.\]</span>
En efecto, podemos ver gráficamente en la figura <a href="introp.html#fig:ptotal">4.7</a> que cada sumando de la
fórmula de la probabilidad total se corresponde con las intersecciones
del suceso de interés <span class="math inline">\(B\)</span> con cada uno de los sucesos de la partición <span class="math inline">\(A_i\)</span>. Como
estas intersecciones son sucesos disjuntos, la probabilidad de su unión es la
suma de sus probabilidades por las propiedades de la probabilidad.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ptotal"></span>
<img src="04-introp_files/figure-html/ptotal-1.png" alt="Representación del espacio muestral particionado más otro suceso" width="70%"><p class="caption">
Figura 4.7: Representación del espacio muestral particionado más otro suceso
</p>
</div>
<p>El desarrollo de la fórmula de la probabilidad condicionada a partir de la situación
descrita para calcular la probabilidad total, nos permite <em>darle la vuelta</em>
a la condición y encontrar probabilidades de los sucesos de la partición <span class="math inline">\(A_i\)</span> condicionados
a que se haya producido el suceso <span class="math inline">\(B\)</span>. Partimos de la propia definición de <span class="math inline">\(P(A_i|B)\)</span>:</p>
<p><span class="math display">\[P(A_i|B)=\frac{P(A_i\cap B)}{P(B)}.\]</span>
Pero a su vez, la probabilidad del numerador la podemos escribir como <span class="math inline">\(P(A_i \cap B)=P(B|A_i)\cdot P(A_i)\)</span>, y la probabilidad del denominador, aplicando la fórmula de la probabilidad total, es <span class="math inline">\(P(B)=\sum\limits_{i=1}^{n} P(B/A_i)\cdot P(A_i).\)</span> Lo que da lugar
a la fórmula de Bayes o <strong>Teorema de Bayes</strong>:</p>
<p><span class="math display">\[\boxed{P(A_i|B)=\frac{P(B|A_i)\cdot P(A_i)}{\sum\limits_{i=1}^{n} P(B/A_i)\cdot P(A_i)}},\]</span>
siempre que <span class="math inline">\(P(B&gt;0)\)</span>, que se puede expresar de forma simplificada como:</p>
<p><span class="math display">\[\boxed{P(A_i|B)=\frac{P(B|A_i)\cdot P(A_i)}{P(B)}}\]</span></p>

<div class="rmdejemplo">
<p>En una empresa que produce componentes electrónicos tomamos 5 lotes de producto,
cada uno compuesto de 50 componentes. Hay dos tipos de lotes. Los del
tipo 1 (<span class="math inline">\(A_1\)</span>) tienen 48 componentes correctos y 2 defectuosos. Los del tipo 2 (<span class="math inline">\(A_2\)</span>)
tienen 45 componentes correctos y 5 defectuosos. Tenemos 3 lotes tipo 1 y 2
lotes tipo 2. Si se toma uno de los 5 lotes al azar y se saca de éste
una pieza, ¿qué probabilidad hay de que ese componente sea defectuoso?</p>
<p>La figura <a href="introp.html#fig:ptotalej">4.8</a> representa la partición del espacio muestral de
este ejemplo.</p>
<p>En este ejemplo se dan todos los elementos que habíamos descrito para
calcular la probabilidad total del suceso <span class="math inline">\(B:\)</span> “el componente es defectuosos”.
Tenemos información parcial, en el sentido de que conocemos las probabilidades
de ser defectuoso para cada uno de los tipos de lote, es decir <span class="math inline">\(P(B|A_1)=\frac{2}{50}=0.04\)</span>
y <span class="math inline">\(P(B|A_2)=\frac{5}{50}=0.1\)</span>. También conocemos las probabilidades de los
dos sucesos que constituyen la partición, <span class="math inline">\(P(A_1) = \frac{3}{5}=0.6\)</span> y
<span class="math inline">\(P(A_2) = \frac{2}{5}=0.4\)</span>. Entonces, por el teorema de la probabilidad total:</p>
<p><span class="math display">\[P(B)=P(B|A_1)\cdot P(A_1) + P(B|A_2)\cdot P(A_2)= 0.04\cdot 0.6 + 0.1\cdot 0.4=0.064.\]</span>
Supongamos ahora que se extrae del conjunto de todos los lotes un componente al azar,
y resulta que es defectuoso. ¿Cuál es la probabilidad de que esa pieza provenga de un
lote del tipo 1?</p>
<p>Nótese que ahora lo que buscamos es <span class="math inline">\(P(A_1|B)\)</span>, como conocemos las <span class="math inline">\(P(B|A_i)\)</span> y
<span class="math inline">\(P(A_i)\)</span>, entonces podemos aplicar la fórmula de Bayes. Como ya hemos calculado
antes la probabilidad total de <span class="math inline">\(B\)</span>, podemos usar la fórmula <em>abreviada</em>:</p>
<span class="math display">\[P(A_1|B)=\frac{P(B|A_1)\cdot P(A_1)}{P(B)}=\frac{0.04\cdot 0.6}{0.064}=0.375.\]</span>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ptotalej"></span>
<img src="04-introp_files/figure-html/ptotalej-1.png" alt="Representación del espacio muestral del ejemplo de los componentes electrónicos" width="70%"><p class="caption">
Figura 4.8: Representación del espacio muestral del ejemplo de los componentes electrónicos
</p>
</div>

<div class="rmdejemplo">
<p>En nuestro ejemplo, conocíamos las probabilidades de que un sujeto responda al tratamiento
según si es hombre o mujer. También conocemos la probabilidad
de que el sujeto sea hombre o mujer. Entonces podemos calcular la probabilidad
de que un sujeto (independientemente de si es hombre o mujer) responda al tratamiento como:</p>
<p><span class="math display">\[P(S)=P(S|M)\cdot P(M) + P(S|H)\cdot P(H)= \frac{2}{6}\cdot \frac{1}{2} + \frac{1}{6}\cdot \frac{1}{2} = 0.25.\]</span></p>
<p>Si un sujeto responde al tratamiento, la probabilidad de que sea mujer es:</p>
<span class="math display">\[P(M|S)=\frac{P(S|M)\cdot P(M)}{P(S)}=\frac{\frac{2}{6}\cdot 0.5}{0.25} \simeq 0.6667.\]</span>
</div>

<div class="rmdcafe">
<p><strong>El problema de Monty Hall</strong></p>
<p><em>Monty Hall</em> es el nombre del presentador del concurso televisivo
estadounidense <em>Let’s make a deal</em>
que se emitió entre 1963 y 1990. En alguna de las fases del programa,
el concursante tiene que elegir una entre tres puertas, dos de las cuales
tienen detrás una cabra, mientras que la otra tiene un coche.
Una vez elegida la puerta, el presentador muestra el contenido de una
de las otras dos puertas, que contiene una cabra. Entonces el concursante
tiene la opción de cambiar su puerta por la otra que queda cerrada.
¿Es más ventajoso cambiar de puerta o quedarse con la elegida inicialmente?
¿O da lo mismo?</p>
<div class="inline-figure"><img src="images/door.jpg"></div>
<p>La solución puede parecer contraintuitiva, aunque tanto desde el razonamiento
a través de las frecuencias como con un desarrollo matemático se llega a
la misma conclusión. Y la clave está en la <strong>probabilidad condicionada</strong>.</p>
</div>
<p>El problema de <em>Monty Hall</em> dio lugar a historias curiosas que se pueden consultar en
<span class="citation">Corbalán and Sanz<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;&lt;em&gt;La Conquista Del Azar. La Teoría de Probabilidades&lt;/em&gt;.&lt;/p&gt;"><sup>58</sup></a></span>. Por ejemplo, el gran matemático Paul Erdös solo aceptó
como buena la solución real tras comprobarla en una simulación por ordenador.
Invito al lector a que concurse en la aplicación que
se muestra a continuación<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;accesible también en &lt;a href="https://elcano.shinyapps.io/monty_hall" class="uri"&gt;https://elcano.shinyapps.io/monty_hall&lt;/a&gt;&lt;/p&gt;'><sup>59</sup></a>
durante un buen número de jugadas y
compruebe a través de las frecuencias relativas qué estrategia ofrece mayor
probabilidad de ganar el coche.</p>

</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="aed-bi.html"><span class="header-section-number">3</span> Análisis exploratorio bivariante</a></div>
<div class="next"><a href="vauni.html"><span class="header-section-number">5</span> Variable aleatoria univariante</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="Índice capítulo"><h2>Índice capítulo</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#introp"><span class="header-section-number">4</span> Introducción a la Probabilidad</a></li>
<li>
<a class="nav-link" href="#sec-introprob"><span class="header-section-number">4.1</span> Introducción</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#est%C3%A1ndares-de-aplicaci%C3%B3n">Estándares de aplicación</a></li>
<li><a class="nav-link" href="#estad%C3%ADstica-y-c%C3%A1lculo-de-probabilidades">Estadística y Cálculo de Probabilidades</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#sucesos-aleatorios"><span class="header-section-number">4.2</span> Sucesos aleatorios</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#sucesos-notables"><span class="header-section-number">4.2.1</span> Sucesos notables</a></li>
<li><a class="nav-link" href="#operaciones-con-sucesos"><span class="header-section-number">4.2.2</span> Operaciones con sucesos</a></li>
<li><a class="nav-link" href="#clasificaci%C3%B3n-de-los-espacios-muestrales"><span class="header-section-number">4.2.3</span> Clasificación de los espacios muestrales</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#definiciones-de-probabilidad-y-sus-propiedades"><span class="header-section-number">4.3</span> Definiciones de probabilidad y sus propiedades</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#definici%C3%B3n-cl%C3%A1sica-o-de-laplace"><span class="header-section-number">4.3.1</span> Definición clásica o de Laplace</a></li>
<li><a class="nav-link" href="#ch07-defempirica"><span class="header-section-number">4.3.2</span> Definición frecuentista o empírica</a></li>
<li><a class="nav-link" href="#definici%C3%B3n-subjetivista"><span class="header-section-number">4.3.3</span> Definición subjetivista</a></li>
<li><a class="nav-link" href="#definici%C3%B3n-en-iso-3534-1"><span class="header-section-number">4.3.4</span> Definición en ISO 3534-1</a></li>
<li><a class="nav-link" href="#definici%C3%B3n-axiom%C3%A1tica"><span class="header-section-number">4.3.5</span> Definición axiomática</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#probabilidad-condicionada-y-sus-consecuencias"><span class="header-section-number">4.4</span> Probabilidad condicionada y sus consecuencias</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#probabilidad-condicionada"><span class="header-section-number">4.4.1</span> Probabilidad condicionada</a></li>
<li><a class="nav-link" href="#probabilidad-de-la-intersecci%C3%B3n-de-sucesos"><span class="header-section-number">4.4.2</span> Probabilidad de la intersección de sucesos</a></li>
<li><a class="nav-link" href="#independencia-de-sucesos"><span class="header-section-number">4.4.3</span> Independencia de sucesos</a></li>
<li><a class="nav-link" href="#probabilidad-condicionada-e-independencia-en-iso-3534-1"><span class="header-section-number">4.4.4</span> Probabilidad condicionada e independencia en ISO 3534-1</a></li>
<li><a class="nav-link" href="#probabilidad-total-y-f%C3%B3rmula-de-bayes"><span class="header-section-number">4.4.5</span> Probabilidad total y fórmula de Bayes</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/emilopezcano/estadistica-ciencias-ingenieria/blob/master/04-introp.Rmd">Ver fuente <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/emilopezcano/estadistica-ciencias-ingenieria/edit/master/04-introp.Rmd">Editar esta página <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Estadística Aplicada a las Ciencias y la Ingeniería</strong>" escrito por <a href="http://emilio.lcano.com" class="text-light">Emilio L. Cano</a>. Generado por última vez el día 2022-03-23.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Este libro ha sido generado con el paquete de R <a class="text-light" href="https://bookdown.org">bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
