[{"path":"index.html","id":"bienvenida","chapter":"Bienvenida","heading":"Bienvenida","text":"\nEste libro incluye los contenidos habitualmente presentes en el currículo\nde asignaturas de Estadística de los grados Ciencias e Ingenierías de universidades españolas. Aunque aparezca en el título, el manual incluye también los contenidos de Probabilidad necesarios.\nSi bien existe abundante material bibliográfico\nque cubre los contenidos de estas asignaturas, quería elaborar un material\npropio que fuera solamente para mis clases sino algo más\nglobal. En los últimos años ya lo hice para asignaturas de grado y Máster en ADE.1 Por otra parte, motiva cubrir el hueco de los materiales\nde acceso gratuito con la opción de comprar una edición\nimpresa2 y con el enfoque\nque se menciona en el siguiente apartado. Por otra parte, los libros publicados\noriginalmente en inglés y traducidos al español menudo resultan lejanos\nnuestro idioma (por muy buenas que sean las traducciones, los ejemplos en acres\nson muy intuitivos para un lector español). Espero que también sirva para\nlectores de otros países de habla hispana.","code":""},{"path":"index.html","id":"estándares-y-software","chapter":"Bienvenida","heading":"Estándares y software","text":"Los contenidos de este libro se basan en dos paradigmas que están presentes\nen los intereses de investigación y docencia del autor: los estándares y\nel software libre. En lo que se refiere estándares, la notación utilizada,\ndefiniciones y fórmulas se ajustarán el máximo posible la utilizada en normas\nnacionales e internacionales sobre metodología estadística. Estas normas se\ncitarán pertinentemente lo largo del texto. En cuanto al software libre,\nse proporcionarán instrucciones para resolver los ejemplos\nque ilustran la teoría utilizando software libre.\nobstante, el uso del software es\nauxiliar al texto y se puede seguir sin necesidad de utilizar\nlos programas. Según lo que proceda en cada caso, se utilizará\nsoftware de hoja de cálculo, el software estadístico y lenguaje de\nprogramación\nR,3\ny el software de álgebra computacional Máxima4.\nRespecto al software de hoja de cálculo, las fórmulas utilizadas se han probado\nen el software libre LibreOffice5, en Hojas de Cálculo de Google6 y\ntambién en Microsoft EXCEL7 que,\naunque es software libre, su uso\nestá más que generalizado y normalmente los estudiantes disponen de licencia de uso\ntravés de su universidad. En caso de que el nombre de la función sea distinta\nen EXCEL, se indicará en el propio ejemplo.Las normas son clave para el desarrollo económico de un país. Estudios en diversos países,\nincluido España, han demostrado que la aportación de la normalización su economía es del 1% del PIB8. La\nAsociación Española de Normalización (UNE) es el organismo legalmente\nresponsable del desarrollo y difusión de las normas técnicas en España.\nAdemás, representa España en los organismos internacionales de normalización como\nISO9 y CEN10.Las normas sobre estadística que surgen de ISO las elabora el Technical Committee\nISO TC 6911 Statistical Methods.\nPor su parte, el subcomité técnico de normalización\nCTN 66/SC 312, Métodos Estadísticos,\nparticipa como miembro nacional en ese comité ISO.\nLas normas que son de interés en España, se ratifican en inglés o se traducen\nal español como normas UNE. Para una descripción más completa de la elaboración\nde normas, véase Emilio L. Cano, Javier M. Moguerza, Mariano Prieto Corcoba.13","code":""},{"path":"index.html","id":"estructura-del-libro","chapter":"Bienvenida","heading":"Estructura del libro","text":"Este libro se ha elaborado utilizando el lenguaje Markdown con el propio\nsoftware R y el paquete bookdown.14\nSe incluyen una gran cantidad de ejemplos resueltos tanto de forma analítica\ncomo mediante software. En algunos casos se proporciona el uso de funciones\nen hojas de cálculo (y el resultado obtenido con un recuadro).\nEn otros, código de R, que aparecen en el texto\nsombreados y con la sintaxis coloreada, como el fragmento continuación\ndonde se puede comprobar la sesión de R en la que ha sido generado este material.\nObsérvese que los resultados se muestran precedidos de los símbolos\n#>.{r} sessionInfo()Normalmente, la descripción o enunciado de los ejemplos se incluyen en bloques\ncon el siguiente aspecto:Esto es un ejemplo. continuación puede mostrarse código o . Los ejemplos\npueden ir precedidos por un icono para identificar su campo de aplicación, por\nejemplo  Biología,  Ciencia y tecnología de Alimentos, o  Ciencia e Ingeniería Ambiental.Cuando el ejemplo incluya explicaciones sobre cómo resolverlo con software,\nestas explicaciones aparecerán en bloques con el siguiente aspecto:HOJA DE CÁLCULOLa función FACT obtiene el factorial de un número x (\\(x!\\)):=FACT(5)\n\\(\\boxed{\\mathsf{120}}\\)También se incluirán con el formato anterior indicaciones para usar la calculadora\ncientífica, cuando esto sea posible.El texto incluye otros bloques con información de distinto tipo, como los siguientes:Este contenido se considera avanzado. El lector principiante puede saltarse estos apartados\ny volver sobre ellos en una segunda lectura.Estos bloques están pensados para incluir información curiosa o complementaria\npara poner en contexto las explicaciones.Este volumen cubre los contenidos de asignaturas básicas de Estadística en un\namplio rango de grados. Puede servir también como repaso\npara alumnos de posgrado o incluso egresados que necesiten refrescar\nconocimientos o aprender aplicarlos con software moderno. Un segundo volumen cubrirá en el futuro métodos y modelos avanzados para\nentornos más exigentes.El libro está dividido en 4 partes. La primera parte está dedicada la Estadística\nDescriptiva, y consta de un capítulo introductorio seguido de sendos capítulos\npara el análisis exploratorio univariante y bivariante. La segunda parte\ntrata la Probabilidad en 4 capítulos, uno introductorio, dos dedicados las\nvariables\naleatorias univariantes y bivariantes respectivamente, y finalmente un capítulo\nque trata los modelos de distribución de probabilidad. En la tercera parte se\naborda la inferencia estadística, con una introducción al muestreo y la\nestimación puntual, seguida de capítulos dedicados los contrastes de\ncomparación de grupos, análisis de regresión y diseño de experimentos. La última\nparte está dedicada al control estadístico de la calidad, en la que,\ntras un capítulo introductorio, se tratan las dos herramientas más importantes\nen este campo: el control estadístico de procesos (SPC, Statistical Process\nControl, por sus siglas en inglés) y los muestreos de aceptación o, dicho de\notra forma, la inspección por muestreo. Finalmente, una serie de apéndices\ncon diverso material complementan el libro en su conjunto.","code":""},{"path":"index.html","id":"sobre-el-autor","chapter":"Bienvenida","heading":"Sobre el autor","text":"Actualmente soy Profesor Ayudante Doctor en la Escuela Técnica Superior de Ingeniería Informática e investigador en el Data Science Laboratory de la Universidad Rey Juan Carlos. Mis intereses de investigación incluyen Estadística Aplicada, Aprendizaje Estadístico y Metodologías para la Calidad. Previamente sido profesor e investigador en la Universidad de Castilla-La Mancha, donde sigo colaborando en docencia e investigación, y Estadístico en empresas del sector privado de diversos sectores.Presidente del subcomité técnico de normalización UNE (miembro de ISO) CTN 66/SC 3 (Métodos Estadísticos). Profesor en la Asociación Española para la Calidad (AEC). Presidente de la asociación Comunidad R Hispano.Más sobre mí, información actualizada y publicaciones: http://emilio.lcano.com.\nContacto: emilio@lcano.comEl material se proporciona bajo licencia CC--NC-ND.\nTodos los logotipos y marcas comerciales que puedan aparecer en este texto\nson propiedad de sus respectivos dueños y se incluyen en este texto únicamente\ncon fines formativos. Se ha puesto especial cuidado en la adecuada atribución\ndel material elaborado por el autor, véase el Apéndice F.\nAún así, si detecta algún uso\nindebido de material protegido póngase en contacto con el autor y será retirado.\nIgualmente, contacte con el autor si desea utilizar este material con fines\ncomerciales.Este obra está bajo una licencia de Creative Commons Reconocimiento-NoComercial-SinObraDerivada 4.0 Internacional.","code":""},{"path":"index.html","id":"agradecimientos","chapter":"Bienvenida","heading":"Agradecimientos","text":"Este libro es el resultado de años de trabajo en la docencia, investigación\ny transferencia de conocimiento en el campo de la Estadística. Está construido\npartir de las contribuciones lo largo de los años de compañeros y amigos\ncomo Javier M. Moguerza, Andrés Redchuk, David Ríos, Felipe Ortega, Mariano Prieto,\nMiguel Ángel Tarancón, Víctor M. Casero, Virgilio Gómez-Rubio, Matías Gámez, y\nmuchos otros (perdón\nl@s omitid@s por ser más exhaustivo).Especial agradecimiento toda la comunidad del software libre y\nlenguaje de programación R, y en particular al R Core Team y al equipo\nde RStudio.","code":""},{"path":"intro.html","id":"intro","chapter":"Capítulo 1 Introducción","heading":"Capítulo 1 Introducción","text":"","code":""},{"path":"intro.html","id":"estadística-y-análisis-de-datos","chapter":"Capítulo 1 Introducción","heading":"1.1 Estadística y análisis de datos","text":"","code":""},{"path":"intro.html","id":"qué-es-la-estadística","chapter":"Capítulo 1 Introducción","heading":"1.1.1 ¿Qué es la Estadística?","text":"Antes de introducirnos en el estudio de la Estadística y sus métodos, vamos \nintentar tener una visión de todo lo que abarca. Así pues, ¿qué es la Estadística?\nLa primera fuente que podemos consultar es la definición de la Real Academia Española,\ny encontramos estas acepciones:estadístico, caLa forma f., del al. Statistik, y este der. del . statista ‘hombre de Estado.’adj. Perteneciente o relativo la estadística.y f. Especialista en estadística.\ny f. Especialista en estadística.Estudio de los datos cuantitativos de la población, de los recursos naturales e industriales, del tráfico o de cualquier otra manifestación de las sociedades humanas.\nEstudio de los datos cuantitativos de la población, de los recursos naturales e industriales, del tráfico o de cualquier otra manifestación de las sociedades humanas.Conjunto de datos estadísticos.\nConjunto de datos estadísticos.Rama de la matemática que utiliza grandes conjuntos de datos numéricos para obtener inferencias basadas en el cálculo de probabilidades.\nRama de la matemática que utiliza grandes conjuntos de datos numéricos para obtener inferencias basadas en el cálculo de probabilidades.RAELas acepciones que nos interesan son sobre todo la tercera y la cuarta, en las\nque aparecen conceptos\nque veremos en este capítulo introductorio y en los que profundizaremos en el resto\ndel libro. La tercera acepción, “Conjunto de datos estadísticos,” es lo que muchas\npersonas entienden cuando oyen la palabra Estadística: La estadística del paro,\nla estadística de los precios, etc. Pero la Estadística es mucho más amplia.\nEn primer lugar, esos “datos estadísticos” han tenido que ser recopilados y\ntratados de alguna forma antes de llegar su publicación. Además, los datos\nestadísticos así entendidos son el resultado de un estudio pormenorizado\n(acepción 3) y normalmente de la aplicación de técnicas de inferencia\n(acepción 5). Algunas de estas técnicas forma parte de lo que vulgarmente\nse conoce como “la cocina” de las estadísticas.Podemos hablar entonces de la Estadística, de forma muy resumida,\ncomo la ciencia de analizar datos. Encontramos menudo15 una definición\nde la Estadística como “la ciencia que establece los métodos necesarios para la recolección, organización, presentación y análisis de datos relativos \nun conjunto de elementos o individuos.” Pero esta definición se centra solo\nen los métodos. Una definición más completa sería la siguiente:[…] la estadística es la parte de la matemática que estudia la variabilidad y el proceso aleatorio que la genera siguiendo leyes de probabilidad.Esta variabilidad puede ser debida al azar, o bien estar producida por causas ajenas él, correspondiendo al razonamiento estadístico diferenciar entre la variabilidad casual y la variabilidad causal.R Ocaña-Riola16Aquí vemos uno de los conceptos clave que guiará todo el estudio y aplicación de\nla Estadística: la variabilidad es la clave de todo. Entender el concepto de\nvariabilidad ayudará enormemente entender los métodos por complejos que sean.Variation reason statisticsEmilio L. Cano, Javier M. Moguerza, Andrés Redchuk17La Estadística ha sido siempre importante en los estudios de Ciencias e\nIngeniería. obstante, en los últimos tiempos la alta disponibilidad\ntanto de datos como de tecnología para tratarlos, hace imprescindible\nun dominio de las técnicas estadísticas y su aplicación en el dominio\nespecífico.","code":""},{"path":"intro.html","id":"los-dos-grandes-bloques-de-la-estadística","chapter":"Capítulo 1 Introducción","heading":"1.1.2 Los dos grandes bloques de la Estadística","text":"La Estadística se divide en dos grandes bloques de estudio, que son\nla Estadística Descriptiva y la Inferencia Estadística. la\nEstadística Descriptiva también se la conoce como Análisis Exploratorio de Datos\n(EDA, Exploratory Data Analysis, por sus siglas en inglés).\nEsta disciplina tuvo un gran desarrollo gracias al trabajo de Tukey,18\nque todavía hoy es una referencia. Pero en los últimos años ha cobrado si cabe\nmás importancia por la alta disponibilidad de datos y la necesidad de analizarlos.La Estadística Descriptiva se aplica sobre un conjunto de datos concretos,\ndel que obtenemos resúmenes numéricos y visualización de datos través de\nlos gráficos apropiados. Con la Estadística Descriptiva se identifican relaciones\ny patrones, guiando el trabajo posterior de la Inferencia Estadística.La Estadística Inferencial utiliza los datos y su análisis anterior para, través de las\nLeyes de la Probabilidad, obtener conclusiones de diverso tipo, como explicación de fenómenos,\nconfirmación de relaciones de causa-efecto, realizar predicciones o comparar grupos.\nEn definitiva, tomar decisiones por medio de modelos estadísticos y basadas en\nlos datos.","code":""},{"path":"intro.html","id":"la-esencia-de-la-estadística","chapter":"Capítulo 1 Introducción","heading":"1.1.3 La esencia de la Estadística","text":"La figura 1.1 representa\nla esencia de la Estadística y sus métodos. Estudiamos alguna característica\nobservable en una serie de elementos (sujetos, individuos, …)\nidentificables y únicos. Los datos que analizamos,\nprovienen de una determinada población que es objeto de estudio.\nPero estos datos, son más que\nuna muestra, es decir, un subconjunto representativo de la población. Incluso\ncuando “creemos” que tenemos todos los datos, debemos tener presente que trabajamos\ncon muestras, ya que generalmente tomaremos decisiones o llegaremos conclusiones\nsobre el futuro, y esos datos seguro que los tenemos. Por eso es importante\nconsiderar siempre este paradigma población-muestra, donde la\npoblación es desconocida y sus propiedades teóricas. La Estadística Descriptiva\nse ocupa del análisis exploratorio de datos en sentido amplio, que aplicaremos\nsobre los datos concretos de la muestra en este unidad y la siguiente. La\nInferencia Estadística hace referencia los métodos mediante los cuales,\ntravés de los datos de la muestra, tomaremos decisiones, explicaremos relaciones,\no haremos predicciones sobre la población. Para ello, haremos uso de la\nProbabilidad, que veremos más adelante, aplicando\nel método más adecuado.\nEn estos métodos será muy importante considerar el método de obtención de la muestra\nque, en términos generales, debe ser representativa de la población para que las\nconclusiones sean válidas.\nFigura 1.1: La esencia de los métodos estadísticos\n En un ensayo clínico, se eligen una serie de participantes en el estudio los\nque se le suministran distintos tratamientos según el diseño del ensayo.\nLos participantes en el estudio son sujetos que constituyen la muestra.\ntravés de los resultados de esta muestra, obtendremos conclusiones\npara toda la población, que estará definida en el propio ensayo clínico.\nPor ejemplo, en el estudio del efecto de un determinado tratamiento para la\ndiabetes, la población serían todos los enfermos de diabetes.Otro concepto clave inherente la Estadística, es que casi siempre estaremos\ninvestigando sobre esta fórmula:\\[Y=f(X)\\]Es decir, buscamos encontrar la relación entre una variable respuesta \\(Y\\) y una o varias\nvariables explicativas \\(X\\). Casi toda la Ciencia de Datos consiste en encontrar esa \\(f\\).\nEs fundamental interiorizar este concepto para después aplicar el método adecuado,\nya que según sean la/s \\(Y\\), la/s \\(X\\) y el objetivo de nuestro estudio, los caminos\npueden ser muy diferentes.El origen del término Data Science se suele atribuir Bill Cleveland tras la publicación de su artículo “Data Science: Action Plan Expanding Technical Areas Field Statistics” en 2001,1920, aunque lo anticipó Tukey 40 años antes en “Future Data Analysis”21 . obstante, es partir del año 2010, con la irrupción del Big Data y la necesidad de analizar grandes cantidades de datos, cuando se empieza popularizar el término intentando dar una definición gráfica de la profesión (Data Scientist). Así, es muy común presentar la ciencia de datos como la intersección de los conocimientos informáticos, los conocimientos estadístico-matemáticos, y el conocimiento de la materia en estudio (negocio, campo científico, etc.). Así, la persona de ciencias o ingeniería, con evidentes conocimientos en su campo, que adquiera conocimientos de Estadística y sea capaz de utilizar software avanzado como R, es uno de los perfiles más demandados.Paralelamente la Ciencia de Datos, aparecen términos más recientes como Big Data, Internet Things o Industria 4.0. Detrás de todos ellos, está el análisis estadístico. Y la mayoría de las veces es suficiente aplicar los métodos más básicos para solucionar los problemas o demostrar las hipótesis.","code":""},{"path":"intro.html","id":"los-datos-y-su-organización","chapter":"Capítulo 1 Introducción","heading":"1.2 Los datos y su organización","text":"","code":""},{"path":"intro.html","id":"características-y-variables","chapter":"Capítulo 1 Introducción","heading":"1.2.1 Características y variables","text":"Las características que observamos en los elementos de la muestra\n(o que estudiamos en una población) pueden ser distintos tipos. Nos referiremos\ngenéricamente estas características como variables, aunque en en algunos\námbitos como el Control Estadístico de Procesos (SPC, Statistical Process Control\npor sus siglas en inglés) este término se refiere solo las variables continuas\nque ahora definiremos.Denotaremos las variables con letras mayúsculas del alfabeto latino (\\(X\\), \\(Y\\), \\(\\), …).\nCuando observamos la característica, la variable toma un valor. Estos valores\npueden ser agrupados en clases, de forma que cada posible valor\npertenezca una y solo una clase. En ocasiones los datos con los que trabajamos\nestán ya clasificados en clases. Las variables pueden tomar cualquier valor en su dominio, es decir, el conjunto de posibles valores que puede tomar la variable. Veremos más adelante cómo cuantificar esas posibilidades través de la Probabilidad.Cuando se recogen datos utilizando cuestionarios, menudo en las preguntas\npara recoger características cuantitativas se ofrece elegir un intervalo en vez\nde peguntar el valor exacto. Por ejemplo, al preguntar la edad de una\npersona, se pueden dar las opciones: 1) menos de 20 años; 2) entre 20 y 40 años;\n3) entre 40 y 60 años; 4) Más de 60 años. Así, si una persona tiene 30 años, el valor\nde la variable es 30 (en el caso de la encuesta lo conoceremos exactamente)\nque pertenece la clase “entre 20 y 40 años.”","code":""},{"path":"intro.html","id":"parámetros-y-estadísticos","chapter":"Capítulo 1 Introducción","heading":"1.2.2 Parámetros y estadísticos","text":"Distinguiremos la caracterización de las variables que estudiamos en la población de las observadas en la muestra denotándolas por parámetros y estadísticos respectivamente. Los parámetros son valores teóricos, casi siempre desconocidos, sobre los que haremos inferencia. Los denotaremos por letras griegas minúsculas, como por ejemplo \\(\\mu\\) para la media poblacional.\nUn estadístico es una función definida sobre los datos de una muestra. Pueden ser valores de más de una variable, y los resumiremos en un único valor, resultado de aplicar esa función. Los estadísticos tomarán valores distintos dependiendo de la muestra concreta. Esto hace que sean su vez variables, y\nque tengan una distribución en el muestreo que nos permitirá hacer inferencia sobre la población. Los denotaremos con letras latinas, como por ejemplo \\(\\bar x\\) para la media muestra.La figura 1.2 representa la esencia de la estadística relacionando parámetros y estadísticos. Además de la equivalencia entre parámetros y estadísticos, la distribución de frecuencias de los datos de la muestra representada en el histograma se corresponde con la distribución de probabilidad teórica de la población.\nFigura 1.2: La esencia de los métodos estadísticos\n","code":""},{"path":"intro.html","id":"la-inferencia-y-sus-métodos","chapter":"Capítulo 1 Introducción","heading":"1.2.3 La inferencia y sus métodos","text":"Existen dos grandes grupos de métodos para hacer la inferencia sobre la población. La estadística paramétrica asume que la característica sigue una\ndeterminada distribución de probabilidad. Esta distribución de probabilidad depende de unos parámetros (por ejemplo, la media\ny la desviación típica). La inferencia se hace en base esos parámetros, y se asumen ciertas hipótesis de partida que se deben comprobar.\nLa estadística paramétrica asume ninguna distribución de probabilidad para la\ncaracterística. Los métodos se basan en estadísticos de orden (cuantiles) y hace falta cumplir ninguna hipótesis.Por otra parte, se pueden seguir dos enfoques bien diferenciados la hora de hacer inferencia. Por una parte, el enfoque frecuentista asume que los parámetros son valores fijos desconocidos, de los que estimamos\nsu valor. Esta estimación está ligada una incertidumbre (error) derivada\ndel muestreo. Por otra parte, en el enfoque bayesiano los parámetros son valores fijos desconocidos, sino variables aleatorias de las que se estima su distribución de probabilidad. Y partir de esa distribución de probabilidad, se hace la inferencia. En este libro se tratarán los métodos bayesianos.","code":""},{"path":"intro.html","id":"organización-de-los-datos","chapter":"Capítulo 1 Introducción","heading":"1.2.4 Organización de los datos","text":"Hemos hablado de características de forma aislada. Pero normalmente estudiamos una sola característica de la población, sino que observamos varias características, teniendo así en la muestra\nun conjunto de variables relativas una serie de elementos. Cuando analizamos una única variable, aislada del resto, estaremos\nhaciendo análisis univariante. Cuando analizamos más de una variable, estaremos haciendo análisis multivariante. Casi siempre un estudio estadístico incluye análisis univariante y\nmultivariante.Para poder analizar los datos de forma eficiente, debemos organizarlos siguiendo los principios Tidy data. Así, dispondremos los datos en forma de tablas (datos rectangualares), donde tengamos una columna para cada variable (mismo tipo de datos) y una fila para cada observación (elemento, individuo).\nEl analista y software deben entender lo mismo, lo que podríamos decir que es preparar los datos para las máquinas y para los humanos. Esta sería la “capa de datos,” después puede haber una “capa de presentación,” independiente de la anterior. Aquí puede jugar un papel importante los metadatos: diccionarios de datos para consultar sobre las variables (unidades, descripciones, etc.)La tabla 1.1 muestra las primeras filas de una tabla de datos bien organizada. Cada fila representa un solo elemento, cada columna una sola variable, sin mezclar datos. Los nombres de las variables son cortos pero informativos.Tabla 1.1: Tabla rectangular bien organizada","code":""},{"path":"intro.html","id":"tipos-de-datos-y-escalas","chapter":"Capítulo 1 Introducción","heading":"1.2.5 Tipos de datos y escalas","text":"Las características que observamos pueden ser de distintos tipos. La correcta identificación del tipo de variable es crucial para hacer un correcto análisis, ya que los métodos pueden ser muy distintos.La primera diferenciación que haremos será entre variables cuantitativas y cualitativas. Las variables cuantitativas o numéricas se pueden expresar con un número que además tiene una escala métrica (se pueden medir diferencias entre individuos). su vez, pueden ser continuas o discretas. Las variables continuas pueden tomar cualquier valor en un intervalo (teóricamente infinitos valores). Las variables discretas pueden tomar un número de valores finito o infinito numerable, pero toma valores entre un valor y otro.Las variables cualitativas o categóricas son etiquetas sin sentido numérico en las que podemos clasificar los elementos. Si el número de posibles etiquetas son dos, estaremos ante variables dicotómicas, que en algunos casos podremos codificar como ceros y unos si presenta o presenta la característica principal. Las variables multinivel presentan más de dos posibles etiquetas. En ambos casos se trata de una escala nominal. Las variables ordinales son aquellas en las que las etiquetas se pueden ordenar, de forma que tenemos una escala ordinal.Además de las variables propiamente dichas, nuestro conjunto de datos puede tener otras características como marcas de tiempo e identificadores, que serán útiles para aplicar los métodos, pero serán objeto de análisis.En ocasiones es útil transformar las variables de un tipo otro. Por ejemplo:Fechas categóricas (etiqueta de mes, día de la semana, …)Cuantitativas cualitativas (clases, intervalos)Ordinales como numéricas: con precaución, sobre todo si hay pocos datos (<100). Se pueden combinar en índices.Variables calculadas con otras (por ejemplo, IMC)En los siguientes capítulos abordaremos el análisis de todos estos datos.","code":""},{"path":"intro.html","id":"la-estadística-y-el-método-científico","chapter":"Capítulo 1 Introducción","heading":"1.3 La Estadística y el método científico","text":"La estadística es un pilar fundamental del método científico. El método científico se aplica también en el desarrollo tecnológico. Por tanto, la correcta aplicación de los métodos estadísticos es imprescindible para el avance de la ciencia y la técnica.","code":""},{"path":"intro.html","id":"el-método-científico","chapter":"Capítulo 1 Introducción","heading":"1.3.1 El método científico","text":"El método científico se puede resumir en los siguientes pasos:Hacerse una preguntaHacerse una preguntaRealizar investigación de baseRealizar investigación de basePlantear una hipótesisPlantear una hipótesisComprobar la hipótesis con experimentosComprobar la hipótesis con experimentosAnalizar resultados y extraer conclusionesAnalizar resultados y extraer conclusionesComunicar resultadosComunicar resultadosLa pregunta que nos hacemos (1) depende del campo de aplicación, y aquí todavía aparece la Estadística (menos que sea una investigación sobre los propios métodos estadísticos). Durante la investigación de base (2), realizamos análisis exploratorio de datos e identificamos relaciones. Posiblemente, esta primera investigación nos hace cambiar la pregunta del primer paso. Plantear una hipótesis (3) significa formalizarla en términos de Hipóteis nula, \\(H_0\\), e hipótesis alternativa, \\(H_1\\), que se comprobarán con los datos empíricamente. El planteamiento de la hipótesis determina\nel método estadístico utilizar, y el diseño\ndel experimento (en sentido amplio). Para comprobar la hipótesis con experimentos (4) es fundamental un diseño adecuado para que los\nresultados sean válidos, así como la\ncorrecta organización de los datos recogidos según los\nprotocolos establecidos. Estos protocolos incluyen conceptos estadísticos como aleatorización y bloqueo, entre otros. Analizar resultados (5a) se puede hacer sino con técnicas estadísticas, y estos resultados deben contarle al experto la historia con suficiente evidencia para extraer conclusiones (5b). Intervienen aquí el análisis exploratorio, los contrastes de hipótesis y la validación de los modelos. Por último, podemos aprovechar las herramientas estadísticas modernas para comunicar resultados (6), por ejemplo mediante Informes reproducibles RMarkdown, Gráficos efectivos y resultados clave. Los resultados negativos (cuando conseguimos demostrar lo que buscábamos en la hipótesis) es un aspecto considerar también, para utilizar como lecciones aprendidas y conocimiento general.","code":""},{"path":"intro.html","id":"investigación-reproducible","chapter":"Capítulo 1 Introducción","heading":"1.3.2 Investigación reproducible","text":"Los informes reproducibles mencionados en el párrafo anterior hacen referencia al enfoque de Investigación reproducible en el cual se puedan reproducir los resultados, bien los mismos investigadores en otro momento, o terceras partes interesadas para verificar la validez de los resultados. Para esto es necesario utilizar software estadístico basado en scripts en los que se pueda consultar toda la lógica del análisis (frente software de “ventanas” donde se pierde la trazabilidad). Este código se puede mezclar con la propia narrativa del informe (antecedentes, interpretación, conclusiones, etc.) de forma que, dados los mismos datos, se obtenga el mismo informe. Incluso, dados otros datos, se podría replicar el estudio de forma instantánea. El enfoque “copy-paste” alternativo, en el que vamos añadiendo un informe los resultados en un momento dado, son fuente de inconsistencias, errores, desactualización y falta de reproducibilidad, y en los que cualquier cambio requiere mucho esfuerzo.","code":""},{"path":"intro.html","id":"estadística-calidad-y-sostenibilidad","chapter":"Capítulo 1 Introducción","heading":"1.4 Estadística, Calidad y Sostenibilidad","text":"La es una herramienta fundamental en muchos procedimientos\nrelacionados con la Calidad, y es por eso que se habla de\nControl Estadístico de la Calidad.","code":""},{"path":"intro.html","id":"calidad-y-variabilidad","chapter":"Capítulo 1 Introducción","heading":"1.4.1 Calidad y variabilidad","text":"Todos tenemos nuestra percepción de la calidad. Pero veamos primero la definición estandarizad de calidad que tenemos en la norma ISO 9001.Calidad: Grado en el que un conjunto de .red[características] inherentes de un objeto\ncumple con los .red[requisitos]ISO 9001:2015 3.6.2Los requisitos son especificaciones de la característica, que pueden ser bilaterales o unilaterales.En la figura 1.3 vemos dos distribuciones de datos del tipo que vamos \nver en el libro22. Los dos conjuntos de datos correspondientes la medición\nde la variable peso tienen la misma media: 10 g.\nSin embargo, la de la izquierda tiene una desviación típica (medida de la variabilidad) igual \n0.6 g, menor que la de la derecha que es 1 g. Si las líneas rojas son nuestros\nlímites de especificación, podemos ver cómo en el proceso de la derecha algunos de los\nelementos de nuestro proceso satisfacen los requisitos. En este ejemplo se ve\nclaramente cómo reducir la variabilidad mejora la calidad ¡sin hacer nada\nmás! (ni nada menos).\nFigura 1.3: Procesos con la misma media y distinta variabilidad\nEn general,\nlas CTQs (Critical Quality características críticas para la calidad) tendrán un valor objetivo (target, \\(T\\)), o valor nominal, que es el ideal.\nAnte la imposibilidad de tener procesos exactos, se fijan unos límites de especificación\no límites de tolerancia dentro de los cuales el producto o servicio es conforme,\nmientras que es conforme cuando el valor de la CTQ está fuera de dichos límites.\nSe utilizan los símbolos \\(L\\) y \\(U\\) para designar los límites de control\ninferior y superior respectivamente.La Calidad se mide como la pérdida total que un producto causa la sociedadGenichi TaguchiDebemos considerar que la falta de calidad \nproduce pérdidas sólo cuando el producto cumple con las especificaciones, sino que,\nmedida que nos alejamos del valor objetivo, esa pérdida aumenta, y además lo\nhace de manera lineal, es decir, proporcional, sino que es mayor cuanto más nos\nalejamos del objetivo. Es lo que se conoce como la función de pérdida de Taguchi\n(Taguchi’s Loss Function).\nTaguchi consideraba la calidad como la consecución de un objetivo de\ncalidad, como una tolerancia, y la falta de calidad como una pérdida\npara la sociedad. El producto perfecto produce pérdidas (loss), mientras que\ncualquier desviación del objetivo produce una pérdida para la sociedad, que aumenta\nmedida que esa desviación es mayor.23 La figura 1.4\nrepresenta este coste para la sociedad (línea azul discontinua), que se produce\nsiempre que se consigue el objetivo, frente al coste contable (línea punteada gris),\nque solo se produce con las conformidades. El análisis de la función de\npérdida es una herramienta muy útil en proyectos de mejora, véase Cano, Moguerza, Redchuk.24\nFigura 1.4: Función de pérdida de Taguchi\n","code":""},{"path":"intro.html","id":"métodos-estadísticos-para-la-calidad","chapter":"Capítulo 1 Introducción","heading":"1.4.2 Métodos estadísticos para la calidad","text":"Existen métodos estadísticos específicos para el control y\nmejora de la calidad. Las dos principales herramientas del\nControl Estadístico de Procesos (SPC, Statistical Process Control)\nson los gráficos de control y el análisis de la capacidad del proceso.\nLa figura 1.5 muestra un ejemplo de ambas. El gráfico de control de la parte superior sirve para monitorizar las muestras (subgrupos de los que se calcula un estadístico) con el objetivo de detectar el cambio con respecto su situación de control estadístico. Así, los límites son “la voz del proceso.” La parte inferior representa “la voz de cliente,” comparando las especificaciones con la variabilidad del proceso, y calculando los índices de capacidad que son la medida real de calidad largo plazo (frente la mera contabilización de las unidades defectuosas y su cuantificación monetaria). Estas técnicas se combinan con otras tanto exploratorias como de inferencia para controlar y mejorar la calidad.\nFigura 1.5: Gráficos de control y capacidad del proceso\nOtra técnica de calidad en la que la Estadística juega un papel fundamental es la inspección por muestreo, también conocida como muestreos de aceptación. La aceptación de unidades o lotes de producto, se puede hacer con inspección completa, comprobando si los productos están dentro de los límites de especificación. Esto veces es muy caro o directamente imposible, por lo que se recurre al muestreo. El análisis se puede hacer por atributos (variables cualitativas y por variables (variables cuantitativas). La base de esto métodos reside en la probabilidad de aceptar/rechazar un lote defectuoso/correcto, desde el punto de vista del consumidor/productor. Existen una gran variedad de planes de muestreo específicos, como planes simples, planes dobles y múltiples o planes secuenciales. Muchos están descritos en las normas clásicas MIL-STD, que evolucionaron las series de normas ISO 2859 e ISO 3951.En los llamados ensayos inter-laboratorios también se aplican técnicas estadísticas como el análisis del sistema de medición (MSA, Measurement Systems Analysis), estudios de precisión y exactitud, estudios R&R (Reproducibility & Repeatibility), o validación de laboratorios. En la mayoría de los casos lo que se utiliza es Diseño y Análisis de Experimentos.","code":""},{"path":"intro.html","id":"metodologías-y-estándares","chapter":"Capítulo 1 Introducción","heading":"1.4.3 Metodologías y estándares","text":"Las normas sobre métodos estadísticos que elabora ISO emanan del comité ISO TC69, del que hay un subcomité “espejo” en UNE (entidad acreditada de normalización en España), el subcomité UNE CT66/SC3. La propia ISO 9000\nhace mención los métodos estadísticos, y existe un informe técnico, UNE-ISO TR 1017 sobre “Orientación sobre las técnicas estadísticas para la Norma ISO 9001:2020.” Algunas universidades disponen del catálogo de normas UNE en sus bases de datos para el acceso de docentes y estudiantes.La metodología Seis Sigma y el ciclo DMAIC aplican el método científico la mejora de la calidad, utilizando el lenguaje de las empresas. Lean Six Sigma es una evolución en la que se añade Seis Sigma los principios de Lean Manufacturing.","code":""},{"path":"intro.html","id":"objetivos-de-desarrollo-sostenible-ods","chapter":"Capítulo 1 Introducción","heading":"1.5 Objetivos de Desarrollo Sostenible (ODS)","text":"El 25 de septiembre de 2015, los líderes mundiales adoptaron un conjunto de .red[objetivos globales] para erradicar la pobreza, proteger el planeta y asegurar la prosperidad para todos como parte de una nueva agenda de desarrollo sostenible. Cada objetivo tiene .red[metas específicas] que deben alcanzarse en los próximos 15 años.Naciones Unidas","code":""},{"path":"intro.html","id":"los-17-ods","chapter":"Capítulo 1 Introducción","heading":"1.5.1 Los 17 ODS","text":"Esta iniciativa de la ONU (Sustainable Development Goals, SDG) plantea 17 objetivos generales, que se detallan en 169 metas concretas. Estos objetivos van más allá del medio ambiente, que probablemente es lo primero que nos viene la cabeza25. Los 17 objetivos son los siguientes, y se esquematizan en la figura 1.6.Fin de la pobreza - Poner fin la pobreza en todas sus formas en todo el mundoHambre cero- Poner fin al hambre, lograr la seguridad alimentaria y la mejora de la nutrición y promover la agricultura sostenibleSalud y bienestar- Garantizar una vida sana y promover el bienestar para todos en todas las edadesEducación de calidad- Garantizar una educación inclusiva, equitativa y de calidad y promover oportunidades de aprendizaje durante toda la vida para todosIgualdad de género- Lograr la igualdad entre los géneros y empoderar todas las mujeres y las niñas*Agua limpia y saneamiento**- Garantizar la disponibilidad de agua y su gestión sostenible y el saneamiento para todosEnergía asequible y contaminante- Garantizar el acceso una energía asequible, segura, sostenible y moderna para todosTrabajo decente y crecimiento económico- Promover el crecimiento económico sostenido, inclusivo y sostenible, el empleo pleno y productivo y el trabajo decente para todosIndustria, innovación e infraestructura- Construir infraestructuras resilientes, promover la industrialización inclusiva y sostenible y fomentar la innovaciónReducción de las desigualdades- Reducir la desigualdad en y entre los paísesCiudades y comunidades sostenibles- Lograr que las ciudades y los asentamientos humanos sean inclusivos, seguros, resilientes y sosteniblesProducción y consumo responsables- Garantizar modalidades de consumo y producción sosteniblesAcción por el clima- Adoptar medidas urgentes para combatir el cambio climático y sus efectosVida submarina- Conservar y utilizar en forma sostenible los océanos, los mares y los recursos marinos para el desarrollo sostenibleVida de ecosistemas terrestres- Proteger, restablecer y promover el uso sostenible de los ecosistemas terrestres, gestionar sosteniblemente los bosques, luchar contra la desertificación, detener e invertir la degradación de las tierras y detener la pérdida de biodiversidadPaz, justicia e instituciones sólidas- Promover sociedades, justas, pacíficas e inclusivas para el desarrollo sostenible, proporcionar todas las personas acceso la justicia y desarrollar instituciones eficaces, responsables e inclusivas en todos los nivelesAlianzas para lograr objetivos- Fortalecer los medios de ejecución y revitalizar la Alianza Mundial para el Desarrollo Sostenible\nFigura 1.6: Objetivos de Desarrollo Sostenible. Fuente: un.org\n","code":""},{"path":"intro.html","id":"estadística-y-sostenibilidad","chapter":"Capítulo 1 Introducción","heading":"1.5.2 Estadística y sostenibilidad","text":"La Estadística, y su aplicación en la Ciencia y la Ingeniería, puede hacerse presente en los ODS. Algunos ejemplos serían los siguientes:Al realizar investigación sobre algún aspecto de los ODS, irremediablemente utilizaremos la Estadística. Nos podemos proponer nuestras propias líneas de investigación y desarrollo tecnológico desde el punto de vista de uno o varios ODSAl realizar investigación sobre algún aspecto de los ODS, irremediablemente utilizaremos la Estadística. Nos podemos proponer nuestras propias líneas de investigación y desarrollo tecnológico desde el punto de vista de uno o varios ODSTener presentes los ODS para ser sostenible en los propios análisis. Por ejemplo reduciendo el uso de papel o energía, pero también utilizando lenguaje inclusivo o teniendo en cuenta minorías.Tener presentes los ODS para ser sostenible en los propios análisis. Por ejemplo reduciendo el uso de papel o energía, pero también utilizando lenguaje inclusivo o teniendo en cuenta minorías.Relacionar con ODS e intentar contribuir sea cual sea el objetivo de la\ninvestigaciónRelacionar con ODS e intentar contribuir sea cual sea el objetivo de la\ninvestigaciónSiempre podemos hacernos la pregunta: ¿Cómo puede contribuir este trabajo/estudio/investigación/…\nconseguir los Objetivos de Desarrollo Sostenible?Siempre podemos hacernos la pregunta: ¿Cómo puede contribuir este trabajo/estudio/investigación/…\nconseguir los Objetivos de Desarrollo Sostenible?","code":""},{"path":"aed-uni.html","id":"aed-uni","chapter":"Capítulo 2 Análisis exploratorio univariante","heading":"Capítulo 2 Análisis exploratorio univariante","text":"Resúmenes numéricosResúmenes gráficosValores atípicosValores perdidosEn preparación.","code":""},{"path":"aed-bi.html","id":"aed-bi","chapter":"Capítulo 3 Análisis exploratorio bivariante","heading":"Capítulo 3 Análisis exploratorio bivariante","text":"Representación gráficaCorrelaciónRegresiónIntro multivarianteEn preparación.","code":""},{"path":"introp.html","id":"introp","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"Capítulo 4 Introducción a la Probabilidad","text":"","code":""},{"path":"introp.html","id":"sec-introprob","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.1 Introducción","text":"En los capítulos anteriores, hemos visto cómo mediante la Estadística Descriptiva\nestudiamos variables estadísticas describiéndolas y representándolas. Mediante la\nEstadística Inferencial lo que tratamos es de inferir (estimar, predecir)\nlas propiedades de una población basándonos en una muestra de\ndatos26. La Teoría de\nProbabilidades y el Cálculo de Probabilidades son las bases en las que\nse sustentan estos métodos, partiendo de la estimación del modelo de\ndatos, es decir, la distribución de probabilidad de una determinada\ncaracterística en la población.\nEn este capítulo estudiaremos los conceptos fundamentales del\nCálculo de Probabilidades.","code":""},{"path":"introp.html","id":"estándares-de-aplicación","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"Estándares de aplicación","text":"En este capítulo se han aplicado los siguientes estándares:UNE-ISO 3534-1: Estadística. Vocabulario y símbolos. Parte 1, Términos estadísticos generales y términos empleados en el cálculo de probabilidades","code":""},{"path":"introp.html","id":"estadística-y-cálculo-de-probabilidades","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"Estadística y Cálculo de Probabilidades","text":"La figura 4.1 representa una especie de dogma de la Estadística, esto es,\nsu relación con la probabilidad y la inferencia, través de la población y la muestra.\nFigura 4.1: Relación entre la Estadística Descriptiva, el Cálculo de Probabilidades y la Estadística Inferencial\nEs decir, partiendo de los datos de la muestra, estimaremos el modelo de\ndistribución de probabilidad que sigue la variable en estudio en toda la\npoblación. partir de ahí, podremos estimar sus parámetros,\ncalcular probabilidades y realizar contrastes de hipótesis usando técnicas\nde inferencia estadística. La Estadística Descriptiva sobre los datos de la\nmuestra es una tarea permanente.\nNecesitamos en primer lugar una\ndefinición de la Probabilidad y sus propiedades.","code":""},{"path":"introp.html","id":"sucesos-aleatorios","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.2 Sucesos aleatorios","text":"Definamos un experimento como cualquier actividad\nque deriva en un resultado observable e identificable, al que llamaremos suceso. Estos\nresultados pueden ser deterministas o aleatorios.\nSucesos deterministas son los resultados de aquellos experimentos que,\nbajo las mismas condiciones,\nproducen el mismo resultado. Por ejemplo, si observamos el número de eclipses de sol\nque se producen en los próximos 12 meses, el resultado es determinista.\nPor contra, Sucesos aleatorios son aquellos que están sujetos incertidumbre. La\nmayoría de los experimentos son deterministas sino aleatorios. Por ejemplo,\nel resultado al lanzar un dado, observar si un cliente compra o al entrar \nuna tienda, etc.Llamamos sucesos elementales\ncada uno de los resultados posibles de un experimento. Al ser aleatorios,\nconocemos cuál de ellos va ser el resultado final del experimento, pero sí\npodemos conocer la probabilidad de que se produzca cada uno de los\nresultados27.\nPor ejemplo: en una clase de 50 alumnos, si observamos\nel número de alumnos que obtiene sobresaliente en un curso, sabemos cuántos\nvan ser. Pero sí podemos saber cuál es la probabilidad de cada uno de los\nresultados posibles, en este caso entre 0 (ninguno) y 50 (todos) en base \nlo que ha sucedido en años anteriores.Así, la Probabilidad es una medida del grado de incertidumbre\nsobre el resultado de un experimento aleatorio. Los posibles resultados de un experimento\naleatorio forman un conjunto, y la teoría de probabilidades se sustenta en la\nteoría de conjuntos.\ncontinuación vamos definir\nformalmente los sucesos en términos de conjuntos.Espacio muestral, \\(\\Omega\\)Conjunto de todos los resultados posibles— ISO 3534-1 2.1\\(\\Omega\\) estará formado por los posibles resultados del experimento o\nsucesos elementales \\(\\omega_i\\).Suceso, \\(\\)Subconjunto del espacio muestral— ISO 3534-1 2.2Suceso complementario, \\(^c\\)Espacio muestral excluyendo el suceso dado— ISO 3534-1 2.3Así, un suceso cualquiera estará formado por uno o varios sucesos elementales \\(\\omega_i\\)\ndel espacio muestral. Un suceso \\(\\) ocurre si ocurre alguno de los sucesos\nelementales que lo componen.","code":""},{"path":"introp.html","id":"sucesos-notables","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.2.1 Sucesos notables","text":"Los siguientes sucesos tienen especial importancia en el cálculo de probabilidades:Suceso \\(\\subseteq \\Omega\\).Suceso complementario28 \\(^c\\).Suceso seguro \\(\\Omega\\).Suceso imposible \\(\\emptyset\\).La figura 4.2 representa el espacio muestral, un suceso cualquiera \\(\\) y su\ncomplementario \\(^c\\). El suceso imposible aparece representado, pero en\nrealidad sería:\\[\\emptyset = \\Omega^c\\]\nFigura 4.2: Representación del espacio muestral, un suceso cualquiera y su complementario\nHabitualmente se utilizan ejemplos de juegos de azar para introducir el\ncálculo de probabilidades, como lanzamiento de monedas y dados, o\ncombinaciones de cartas en barajas de naipes. Los ejemplos con juegos de azar\ntienen la ventaja de que son fáciles de comprender.La aplicación de la probabilidad en casos distintos\nlos juegos de azar, sigue las mismas leyes, y los ejemplos se pueden asimilar\nsituaciones reales de la empresa o cualquier otro ámbito. continuación\nse describe un ejemplo ilustrativo que,\naunque totalmente inventado, se puede encontrar el lector\nen el futuro con ligeras variaciones según su ámbito de actuación.\nUtilizaremos en lo posible las cifras usadas en los problemas de azar\npara ver la utilidad de aquéllos ejemplos en casos más prácticos.En un estudio se cuenta con un conjunto de 52 sujetos,\nlos cuales están clasificados\nsegún alguna característica.\nVamos considerar el experimento de observar un sujeto\n(por ejemplo cuando entra en la página web del estudio) y clasificarlo\nsegún un criterio determinado. Tendremos los siguientes sucesos:52 posibles sujetos en estudio, \\((\\Omega)\\)La mitad son mujeres \\((M)\\)4 investigadores \\(()\\) , 12 técnicos \\((T)\\), resto pacientes \\((P)\\)13 jóvenes \\((J)\\), 26 adultos \\(()\\), 13 mayores \\((R)\\); 5, 18 y 3 mujeres en cada\ngrupo respectivamente1 de cada seis hombres \\((H)\\) responderá al tratamiento \\((S)\\), el doble si es mujer````¿Con qué juegos de azar relacionarías cada uno de los sucesos anteriores?\nPiensa algunos ejemplos de sucesos en el entorno empresarial con datos similares.\nEl siguiente puede ser un ejemplo más real.CALCULADORA5 \\(\\boxed{\\mathsf{nCr}}\\) 2 \\(\\rightarrow\\) 10HOJA DE CÁLCULO=COMBIN(5;2) \\(\\boxed{\\mathsf{10}}\\)\n[EXCEL] =COMBINAT(5;2) \\(\\boxed{\\mathsf{10}}\\)R","code":"\nchoose(5, 2)\n#> [1] 10"},{"path":"introp.html","id":"operaciones-con-sucesos","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.2.2 Operaciones con sucesos","text":"Como se ha comentado anteriormente, los sucesos son conjuntos. Y como\ntales, aplican las operaciones y propiedades de la teoría de conjuntos.Unión de sucesos. Dados dos sucesos \\(\\) y \\(B\\), definimos\n\\(\\cup B\\)29\ncomo\nel suceso que se cumple si:Ocurre \\(\\), oOcurre \\(B\\), oOcurren \\(\\) y \\(B\\) la vezEl suceso unión contiene los sucesos elementales comunes y los comunes,\nvéase la figura 4.3.\nFigura 4.3: Representación de la unión de dos sucesos\nIntersección de sucesos. Dados dos sucesos \\(\\) y \\(B\\), definimos\n\\(\\cap B\\)30\ncomo el suceso que se cumple si ocurren \\(\\) y \\(B\\) simultáneamente. El suceso\nintersección contiene únicamente los sucesos elementales comunes ambos sucesos,\nvéase la figura 4.4Las operaciones de unión e intersección entre dos ducesos se extienden\ninmediatamente más de dos sucesos.\nFigura 4.4: Representación de la intersección de dos sucesos\nSucesos disjuntos. Dos sucesos \\(\\) y \\(B\\) son disjuntos o mutuamente excluyentes si:\\[\\cap B = \\emptyset.\\]Un suceso \\(\\) está contenido en otro suceso \\(B\\), \\(\\subset B\\) si siempre que se\nproduce \\(\\), se produce también \\(B\\).Diferencia de sucesos. El suceso diferencia \\(-B\\) es el suceso que se produce cuando\nocurre \\(\\) y ocurre \\(B\\). Se verifica:\\[-B = \\cap B^c.\\]La figura 4.5 muestra una representación de sucesos disjuntos, sucesos incluidos en otros sucesos y diferencia de sucesos.\nFigura 4.5: Representación de sucesos disjuntos (izquierda), suceso contenido en otro suceso (centro) y diferencia de sucesos (derecha)\nPartición del espacio muestral. Dada una colección de sucesos \\(A_1, A_2, \\ldots\\),\ndecimos que es una partición del espacio muestral \\(\\Omega\\) si:\\(A_1, A_2, \\ldots: \\quad A_i \\subset \\Omega \\; \\forall \\)\\(A_i \\cap A_j = \\emptyset \\; \\forall \\neq j\\),\\(\\displaystyle \\underset{}\\bigcup A_i = \\Omega\\).La figura 4.6 representa gráficamente una partición del\nespacio muestral \\(\\Omega\\) en cinco sucesos \\(A_1, \\ldots, A_5\\).Nótese que los sucesos elementales de un experimento \\(\\omega_i\\) constituyen una\npartición del espacio muestral.\nFigura 4.6: Representación de una partición del espacio muestral\nDe la teoría de conjuntos se deducen fácilmente las siguientes propiedades\nde las operaciones con sucesos:Conmutativa:\n\\(\\cup B= B\\cup \\).\n\\(\\cap B= B\\cap \\).\n\\(\\cup B= B\\cup \\).\\(\\cap B= B\\cap \\).Asociativa:\n\\(\\cup (B \\cup C) = (\\cup B) \\cup C\\).\n\\(\\cap (B \\cap C) = (\\cap B) \\cap C\\).\n\\(\\cup (B \\cup C) = (\\cup B) \\cup C\\).\\(\\cap (B \\cap C) = (\\cap B) \\cap C\\).Distributiva:\n\\(\\cup (B \\cap C) = (\\cup B) \\cap (\\cup C)\\).\n\\(\\cap (B \\cup C) = (\\cap B) \\cup (\\cap C)\\).\n\\(\\cup (B \\cap C) = (\\cup B) \\cap (\\cup C)\\).\\(\\cap (B \\cup C) = (\\cap B) \\cup (\\cap C)\\).Leyes de De Morgan:\n\\((\\cup B)^c = ^c \\cap B^c\\).\n\\((\\cap B)^c = ^c \\cup B^c\\).\n\\((\\cup B)^c = ^c \\cap B^c\\).\\((\\cap B)^c = ^c \\cup B^c\\).\\(\\cup = \\cap = \\cup \\emptyset = \\cap \\Omega = \\).\\(\\cup \\Omega = \\Omega\\).\\(\\cap \\emptyset = \\emptyset\\).","code":""},{"path":"introp.html","id":"clasificación-de-los-espacios-muestrales","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.2.3 Clasificación de los espacios muestrales","text":"La primera clasificación que haremos de un espacio muestral es en función\nde su tamaño:Finito: consta de un número finito de sucesos elementales. Por ejemplo\nel lanzamiento de un dado: \\(\\Omega = \\{1, 2, 3, 4, 5, 6 \\}\\).Finito: consta de un número finito de sucesos elementales. Por ejemplo\nel lanzamiento de un dado: \\(\\Omega = \\{1, 2, 3, 4, 5, 6 \\}\\).Infinito numerable: el resultado del experimento tiene (al menos teóricamente)\ninfinitos posibles resultados, pero se pueden numerar. Por ejemplo el número\nde piezas correctas hasta que se\nproduce un fallo: \\(\\Omega = \\{ 0, 1, 2, 3, \\ldots \\}\\).Infinito numerable: el resultado del experimento tiene (al menos teóricamente)\ninfinitos posibles resultados, pero se pueden numerar. Por ejemplo el número\nde piezas correctas hasta que se\nproduce un fallo: \\(\\Omega = \\{ 0, 1, 2, 3, \\ldots \\}\\).Infinito numerable: el resultado del experimento tiene\ninfinitos posibles resultados, que se pueden numerar.\nPor ejemplo el tiempo hasta el fallo en el\nejemplo\nanterior31:\n\\(\\Omega = [0, \\infty)\\).Infinito numerable: el resultado del experimento tiene\ninfinitos posibles resultados, que se pueden numerar.\nPor ejemplo el tiempo hasta el fallo en el\nejemplo\nanterior31:\n\\(\\Omega = [0, \\infty)\\).Definimos una sigma álgebra de sucesos \\(\\sigma\\)-álgebra o \\(\\aleph\\) (aleph) como un\nconjunto de sucesos que verifican las siguientes propiedades:Pertenecen \\(\\aleph\\),Si un suceso pertenece \\(\\aleph\\), entonces su suceso complementario también pertenece \\(\\aleph\\),Si \\(\\{A_i\\}\\) es un conjunto de sucesos en \\(\\aleph\\), entonces la unión \\(\\displaystyle \\underset{}\\bigcup A_i\\) y\nla intersección \\(\\displaystyle \\underset{}\\bigcap A_i\\) pertenecen \\(\\aleph\\).Nótese la diferencia entre \\(\\Omega\\) y \\(\\aleph\\). Mientras el espacio muestral \\(\\Omega\\) es el\nconjunto de todos los sucesos elementales del experimento, la \\(\\sigma\\)-álgebra de\nsucesos \\(\\aleph\\) es el conjunto de todos los sucesos que podemos crear partir\ndel espacio muestral \\(\\Omega\\) y las operaciones de unión, intersección y\ncomplementariedad con esos sucesos. El par \\((\\Omega, \\aleph)\\) se dice que es un espacio probabilizable.Observamos al azar el tipo de participante en el estudio de uno tomado al azar.\nEntonces los posibles resultados del experimento o\nsucesos elementales es:\\[\\Omega = \\{, T, P\\}\\]Haciendo todas las operaciones posibles de unión, intersección y complementariedad,\npodemos llegar fácilmente la siguiente \\(\\sigma\\)-álgebra de\nsucesos:","code":""},{"path":"introp.html","id":"definiciones-de-probabilidad-y-sus-propiedades","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.3 Definiciones de probabilidad y sus propiedades","text":"Ya hemos dicho anteriormente que la probabilidad es una medida del grado de\nincertidumbre sobre el resultado de un experimento. Ahora necesitamos formalizar\nla definición de probabilidad con el fin de trabajar matemáticamente\ncon ella.","code":""},{"path":"introp.html","id":"definición-clásica-o-de-laplace","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.3.1 Definición clásica o de Laplace","text":"La definición clásica de la probabilidad, también conocida\ncomo definición de\nLaplace32,\nrequiere disponer de un espacio muestral finito\nreferido un experimento en el que todos los resultados posibles son igualmente probables.\nBajo estas condiciones, la probabilidad de un suceso cualquiera \\(\\) se obtiene\ncomo el cociente entre el número de casos favorables al suceso, dividido\npor el número total de casos posibles del experimento. Así:\\[P() = \\frac{\\text{casos favorables } }{\\text{casos posibles}}.\\]Utilizaremos la definición de Laplace para asignar probabilidades sucesos\ncuando tengamos una enumeración completa del espacio muestral como en los\nejemplos anteriores.En el lanzamiento de un dado equilibrado de seis caras, la probabilidad de sacar\nun seis es igual al cociente entre los casos favorables sacar un 6 (1) y los\ncasos posibles del experimento (6):\\[:\\text{ Sacar un 6 en el lanzamiento de un dado}\\]En el ejemplo de los sujetos en estudio, la probabilidad de que\nun sujeto al azar sea investigador es el cociente entre los casos favorables\nser investigador (4) y los casos posibles (52):","code":""},{"path":"introp.html","id":"ch07-defempirica","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.3.2 Definición frecuentista o empírica","text":"La definición clásica de probabilidad se encuentra con dificultades para\nasignar probabilidades medida que los experimentos alcanzan cierta complejidad.\nPor una parte, siempre tenemos una descripción completa del espacio muestral,\no, simplemente, es infinito, con lo cual podemos aplicar la fórmula de Laplace.\notras veces tenemos la información disponible necesaria. Pensemos en la\nsituación habitual descrita en la figura 4.1 al principio de este\ncapítulo. Queremos asignar\nuna probabilidad un suceso referido nuestra población objeto de estudio.\nSin embargo, tenemos información de los casos posibles y favorables la\nocurrencia del suceso. lo sumo, tenemos acceso una muestra de datos\nde la población, la que podemos aplicar el experimento y obtener las\nfrecuencias de ocurrencia de los sucesos en cuestión. Pues bien, la\ndefinición frecuentista nos dice que si observamos la frecuencia\nde ocurrencia del suceso \\(\\), llamémosle \\(n()\\), en un número grande\nde experimentos \\(n\\), la frecuencia relativa de ocurrencia del suceso \\(\\) tiende\nla probabilidad del suceso \\(\\). Matemáticamente:\\[P() = \\lim\\limits_{n \\\\infty} \\frac{n()}{n}.\\]En experimentos fáciles de realizar, se puede comprobar empíricamente. Por\nejemplo, podemos lanzar una moneda e ir anotando la frecuencia\nde caras con cada repetición. Este tipo de experimentos son también\nfáciles de realizar mediante simulación. En la siguiente aplicación\nse puede simular la elección de elementos de un conjunto34.En la práctica, utilizaremos esta definición para asignar probabilidades\nsucesos en base datos históricos, experiencia previa, etc. En muchas\nocasiones, estos datos están disponibles en forma de porcentajes, y bastará\ncon dividir por 100 para transformarlos en una frecuencia relativa, que\nse tomará como probabilidad.","code":""},{"path":"introp.html","id":"definición-subjetivista","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.3.3 Definición subjetivista","text":"En las dos definiciones anteriores de probabilidad, hemos asignado probabilidades\nsucesos en base unos determinados datos, bien de recuento de posibilidades,\nbien de frecuencias relativas. En ocasiones, se dispone de absolutamente\nningún dato de este tipo. Entonces las probabilidades se han de asignar de\nforma subjetiva, fijadas por un individuo en particular como su\ngrado de creencia acerca de la ocurrencia de un suceso. El individuo fija\nun valor entre cero y uno en base la evidencia de que dispone, que puede\nincluir juicios personales, y también interpretaciones priori sobre las dos\nconcepciones anteriores de la probabilidad, clásica y frecuentista. Por ejemplo,\npuede considerar la frecuencia relativa de fenómenos similares, y combinar esta\ninformación con sus conocimientos y percepciones sobre la materia de estudio.El enfoque subjetivista tiene especial interés en fenómenos que se prestan\nrepetición, así como en métodos de estadística Bayesiana, donde se fija\nuna probabilidad priori de los parámetros de la\npoblación35.\nExisten métodos\nespecíficos para asignar probabilidades subjetivas\nde forma racional, que quedan fuera de los objetivos de este libro, véase, por\nejemplo,.36","code":""},{"path":"introp.html","id":"definición-en-iso-3534-1","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.3.4 Definición en ISO 3534-1","text":"La definición estandarizada que proporciona la norma UNE-ISO 3534-1 es la\nsiguiente para la probabilidad de un suceso \\(\\):Probabilidad de un suceso \\(\\); \\(P()\\)Número real del intervalo cerrado \\([0, 1]\\) asignado un suceso— ISO 3534-1 2.5Nótese que en el estándar se entra en detalles matemáticos por el bien\nde la aplicabilidad en los procesos empresariales. obstante, esta\ndefinición es en esencia compatible y congruente con el resto de definiciones\nde probabilidad.","code":""},{"path":"introp.html","id":"definición-axiomática","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.3.5 Definición axiomática","text":"Si bien todas las definiciones anteriores son válidas y útiles en determinados\ncontextos, todas presentaban problemas para desarrollar una teoría de\nprobabilidades que se pudiera aplicar cualquier espacio probabilizable. La\nsiguiente definición\naxiomática37\nresolvió estos problemas.Una probabilidad \\(\\wp\\) es una función:\\[\n\\begin{split}\n\\wp: & \\; \\aleph \\longrightarrow [0, 1]\\\\\n& \\longrightarrow P()\n\\end{split}\n\\]que cumple:Primer axioma: \\(\\forall \\\\aleph \\; \\exists \\; P() \\geq 0\\).Primer axioma: \\(\\forall \\\\aleph \\; \\exists \\; P() \\geq 0\\).Segundo axioma: \\(P(\\Omega) = 1\\).Segundo axioma: \\(P(\\Omega) = 1\\).Tercer axioma: Dada la sucesión \\(A_1, \\ldots, A_i, \\ldots: A_i \\\\aleph \\; \\forall\\, , A_i \\cap A_j = \\emptyset \\; \\forall \\neq j\\), se cumple:Tercer axioma: Dada la sucesión \\(A_1, \\ldots, A_i, \\ldots: A_i \\\\aleph \\; \\forall\\, , A_i \\cap A_j = \\emptyset \\; \\forall \\neq j\\), se cumple:\\[P \\left (\\bigcup\\limits_{=1}^{\\infty} A_i \\right ) = \\sum\\limits_{=1}^{\\infty} P(A_i).\\]En lenguaje natural, el primer axioma indica que cada suceso le podemos asignar un número negativo llamado “probabilidad del suceso \\(\\)”; el segundo axioma asigna al suceso seguro una\nprobabilidad igual 1; el tercer axioma establece la forma de calcular probabilidades la\nunión de sucesos disjuntos o mutuamente excluyentes, mediante la suma de sus\nrespectivas probabilidades. Nótese que la formulación del axioma es válida para espacios\nmuestrales infinitos (numerables y numerables).partir de estos tres axiomas, se deducen los siguientes teoremas:Dados \\(n\\) sucesos disjuntos dos dos \\(A_1, \\ldots, A_n: A_i \\cap A_j = \\emptyset \\; \\forall \\neq j\\):\\[P \\left (\\bigcup\\limits_{=1}^{n} A_i \\right ) = \\sum\\limits_{=1}^{n} P(A_i).\\]\\(P(^c)=1-P()\\).\\(P(^c)=1-P()\\).\\(P(\\emptyset) = 0\\).\\(P(\\emptyset) = 0\\).Dados \\(A_1, A_2: A_1 \\subset A_2 \\implies P(A_1) \\leq P(A_2)\\).Dados \\(A_1, A_2: A_1 \\subset A_2 \\implies P(A_1) \\leq P(A_2)\\).\\(P(\\cup B) = P() + P(B) - P(\\cap B)\\).\\(P(\\cup B) = P() + P(B) - P(\\cap B)\\).\\(P(\\bigcup\\limits_{=1}^n A_i) = \\sum\\limits_{=1}^n P(A_i) - \\sum\\limits_{<j} P(A_i \\cap A_j) + \\sum\\limits_{<j<k} P(A_i \\cap A_j \\cap A_k) - \\ldots + (-1)^{n-1} P \\left(\\bigcap\\limits_{=1}^n A_i\\right )\\).\\(P(\\bigcup\\limits_{=1}^n A_i) = \\sum\\limits_{=1}^n P(A_i) - \\sum\\limits_{<j} P(A_i \\cap A_j) + \\sum\\limits_{<j<k} P(A_i \\cap A_j \\cap A_k) - \\ldots + (-1)^{n-1} P \\left(\\bigcap\\limits_{=1}^n A_i\\right )\\).El primer teorema particulariza el tercer axioma un conjunto finito de sucesos disjuntos del espacio muestral. El segundo teorema es una de las propiedades que más aplicaremos en cálculo\nde probabilidades, y nos indica cómo calcular la probabilidad de un suceso restándole 1 la probabilidad de su complementario. El tercer teorema es una consecuencia del anterior y del primer axioma, por los cuales la probabilidad del suceso imposible es cero. El cuarto teorema es\nde vital importancia cuando trabajemos con variables aleatorias y nos viene decir que si un\nsuceso está contenido en otro, la probabilidad del primero puede ser mayor que la del segundo.\nLos teoremas quinto y sexto nos permiten calcular probabilidades de la unión de cualesquiera\nconjuntos, sean o disjuntos. Una consecuencia fundamental de las propiedades de la probabilidad es:\\[ \\boxed{0 \\leq P() \\leq 1}.\\]La demostración de estos teoremas se puede encontrar, entre otros, en\nM. D. Ugarte, . F. Militino, . T. Arnholt.38 Asímismo, se puede comprobar fácilmente cómo las definiciones clásicas y frecuentistas cumplen todas estas\npropiedades y por lo tanto son coherentes con la definición axiomática de la probabilidad.Lanzamiento de un dado de seis caras. Sean los siguientes sucesos:\\(A_1:\\) “número impar”; \\(A_1 = \\{1, 3, 5\\}\\).\\(A_2:\\) “número par”; \\(A_2 = \\{2, 4, 6\\}\\).\\(A_3:\\) “número mayor que 4”; \\(A_3 = \\{5, 6\\}\\).\\(A_4:\\) “número menor o igual que 4”; \\(A_4 = \\{1, 2, 3, 4\\}\\).Podemos calcular cualquiera de estas probabilidades por la definición de Laplace, ya\nque los resultados elementales del experimento son equiprobables. Así:\\[P(A_1) = \\frac{1}{2}=0.5=P(A_2); P(A_3) = \\frac{2}{6}\\simeq 0.3333; P(A_4)=\\frac{4}{6}\\simeq 0.6667.\\]Por simple enumeración de los casos posibles podemos calcular las probabilidades de los siguientes sucesos:\\(A_1 \\cup A_3:\\) “número impar o mayor que cuatro”; \\(A_1 \\cup A_3=\\{1,3,5,6\\}\\); \\(P(A_1 \\cup A_3)=\\frac{4}{6} \\simeq 0.6667\\).\\(A_1 \\cup A_3:\\) “número impar o mayor que cuatro”; \\(A_1 \\cup A_3=\\{1,3,5,6\\}\\); \\(P(A_1 \\cup A_3)=\\frac{4}{6} \\simeq 0.6667\\).\\(A_1 \\cap A_3:\\) “número impar y mayor que cuatro”; \\(A_1 \\cap A_3=\\{5\\}\\);\n\\(P(A_1 \\cap A_3)=\\frac{1}{6} \\simeq 0.1667\\).\\(A_1 \\cap A_3:\\) “número impar y mayor que cuatro”; \\(A_1 \\cap A_3=\\{5\\}\\);\n\\(P(A_1 \\cap A_3)=\\frac{1}{6} \\simeq 0.1667\\).Y así sucesivemente para cada posible suceso \\(\\) subconjunto del espacio muestral \\(\\Omega=\\{1,2,3,4,5,6\\}\\).Y así sucesivemente para cada posible suceso \\(\\) subconjunto del espacio muestral \\(\\Omega=\\{1,2,3,4,5,6\\}\\).Ahora bien, también podemos aplicar las propiedades de la probabilidad sin necesidad de enumerar\no contar todas las posibilidades. Por ejemplo, conocidos \\(P(A_1), P(A_3)\\) Y \\(P(A_1\\cap A_3)\\):\\(P(A_1 \\cup A_3)=P(A_1) + P(A_3) - P(A_1 \\cap A_3) = 0.5 + 0.3333 - 0.1667 \\simeq 0.6667\\),que conduce, obviamente, al mismo resultado. medida que aumentan la complejidad de los experimentos, con espacios muestrales más grandes, o incluso infinitos, se hace dificultoso o imposible trabajar con enumeraciones, y es donde hay que aplicar la defición axiomática de la probabilidad.En nuestro ejemplo del estudio, podríamos estar\ninteresados en el suceso “ser mujer o joven.” Este suceso se\ncorrespondería con el suceso \\(M \\cup J\\). Para calcular esta probabilidad,\ntendríamos en cuenta, según los datos del ejemplo, que \\(P(M) = \\frac{1}{2}=0.5\\), \\(P(J) = \\frac{13}{52}=0.25\\), y \\(P(M \\cap J)=\\frac{5}{52}\\simeq 0.0962\\). Entonces:\\[P(M \\cup J)=P(M)+P(J)-P(M\\cap J)=0.5+0.25-0.0962 \\simeq 0.6538.\\]En los anteriores ejemplos hemos utilizado solamente el teorema referido\nla probabilidad de la unión de sucesos. El teorema de la probabilidad\ndel suceso complementario va ser la propiedad que más utilizaremos en\ncálculo de probabilidades, dado que, en muchas ocasiones, es más sencillo\nabordar el problema desde el punto de vista del suceso complementario.\nUn ejemplo es la paradoja de los cumpleaños.Si el día de nuestro cumpleaños asistimos algún evento en el que haya\nmás de 30 personas, es muy probable que nos canten el cumpleaños feliz\nmás de una persona.\nSupongamos una clase de 30 alumnos.\n¿Cuál es la probabilidad de que al menos dos alumnos\ncumplan años el mismo, día?.\nAbordar el problema directamente implicaría gran cantidad\nde consideraciones y costosos cálculos hasta llegar la solución, porque\nhabría que considerar todos los casos posibles y después calcular probabilidades\nde uniones e intersecciones. Sin embargo,\nse resuelve de forma casi inmediata sin consideramos la probabilidad del suceso\ncomplementario. Es decir, si:\\[: \\text{Al menos dos personas de un grupo de 30 cumplen años el mismo día,}\\]entonces el suceso complementario es:\\[^c: \\text{hay dos personas en un grupo de 30 que cumplen años el mismo día.}\\]Nótese cómo la probababilidad sería igual 1 si el grupo de personas fuera\nde 365 personas o\nmás39,\nya que en ese caso el suceso sería un suceso seguro. En este caso, el espacio muestral\nestará compuesto por el número de maneras que tendríamos de ordenar 30\nfechas de nacimiento dentro de un año (día-mes), para un conjunto total de 365 días\ndiferentes que tiene el año. Obviamente se pueden repetir las fechas, y por\ntanto el número total de casos posibles se corresponde con las variaciones con\nrepetición de 365 elementos tomados de 30 en 30:\\[\\mathit{VR}_{m,n} = m^n = 365^{30} \\simeq  7.392\\cdot 10^{76}.\\]Para calcular el número de casos favorables que nadie cumpla años el mismo día, fijamos el\ncumpleaños de la primera persona. Entonces la siguiente persona pueden cumplir años cualquiera\nde los 364 días restantes; fijados los dos primeros, la tercera persona puede cumplir años cualquiera de los 363 días restantes, y así sucesivamente. Por tanto, los casos favorables son las variaciones (sin repetición):\\[\\mathit{V}_{m,n}=365\\times 364 \\times \\ldots \\times (365-30+1) \\simeq 2.171\\cdot 10^{76}\\]y entonces:Para obtener los casos favorables, si intentamos utilizar la fórmula de\nlas variaciones utilizando los factoriales (ver apéndice ??),\nla calculadora y el software pueden devolver un error, por poder calcular\nel factorial de 365.HOJA DE CÁLCULODisponemos en el rango A1:A30 los números del 365 (m) al 336 (m - n + 1). Entonces\npodemos obtener la probabilidad del ejemplo como:=1-PRODUCTO(A1:A30)/(365^30)MAXIMAMaxima sí puede trabajar con números grandes, la siguiente expresión devuelve\nla probabilidad pedida:1 - (factorial(365)/factorial(365-30))/365^30;REl siguiente código realiza los cálculos paso paso y devuelve la probabilidad pedida. Cambiando el valor 30 por otro número de personas cualquiera, se\npuede ver cómo aumenta la probabilidad.Una vez definida la medida de probabilidad \\(\\wp\\) con los axiomas y propiedades\nanteriores, llamamos espacio de probabilidad la terna:\\[(\\Omega, \\aleph, \\wp).\\]El estándar UNE-ISO 3534-1 recoge la definición axiomática de la probabilidad\nde la siguiente forma:sigma álgebra de sucesos; \\(\\sigma\\)-álgebra; sigma campo; \\(\\sigma\\)-campo; \\(\\aleph\\)Conjunto de sucesos con las siguientes propiedades:Pertenecen \\(\\aleph\\);Pertenecen \\(\\aleph\\);Si un suceso pertenece \\(\\aleph\\), entonces su suceso complementario también pertenece \\(\\aleph\\);Si un suceso pertenece \\(\\aleph\\), entonces su suceso complementario también pertenece \\(\\aleph\\);Si \\(\\{A_i\\}\\) es un conjunto de sucesos en \\(\\aleph\\), entonces la unión \\(\\displaystyle\\underset{}\\bigcup A_i\\) y\nla intersección \\(\\displaystyle \\underset{}\\bigcap A_i\\) de los sucesos pertenecen \\(\\aleph\\).Si \\(\\{A_i\\}\\) es un conjunto de sucesos en \\(\\aleph\\), entonces la unión \\(\\displaystyle\\underset{}\\bigcup A_i\\) y\nla intersección \\(\\displaystyle \\underset{}\\bigcap A_i\\) de los sucesos pertenecen \\(\\aleph\\).— ISO 3534-1 2.69Medida de probabilidad \\(\\wp\\)Función negativa definida sobre la sigma álgebra de sucesos tal que\\(\\wp(\\Omega) = 1\\)donde \\(\\Omega\\) denota el espacio muestral\\(\\wp \\left (\\bigcup\\limits_{=1}^{\\infty} A_i \\right ) = \\sum\\limits_{=1}^{\\infty} \\wp(A_i)\\)donde \\(\\{A_i\\}\\) es una secuencia de pares de sucesos disjuntos— ISO 3534-1 2.70Espacio de probabilidad (o espacio probabilístico); \\((\\Omega, \\aleph, \\wp)\\)Espacio muestral, una sigma álgebra de sucesos asociada, y una medida de probabilidad.— ISO 3534-1 2.68","code":"\nncumple <- 30\ncposibles <- 365^ncumple\ncfavorables <- prod(365:(365 - ncumple + 1))\nprob_ninguno <- cfavorables/cposibles\nprob_alguno <- 1 - cfavorables/cposibles\nprob_alguno\n#> [1] 0.7063162"},{"path":"introp.html","id":"probabilidad-condicionada-y-sus-consecuencias","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.4 Probabilidad condicionada y sus consecuencias","text":"","code":""},{"path":"introp.html","id":"probabilidad-condicionada","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.4.1 Probabilidad condicionada","text":"El concepto de probabilidad condicionada es uno de los más importantes\nen teoría de la probabilidad. En ocasiones,\nla ocurrencia o de ciertos sucesos del espacio muestral puede estar afectada\npor otros sucesos del espacio muestral. Por ejemplo, desde el punto de vista\nde la definición de probabilidad de Laplace, en experimentos secuenciales\n\\(A_1, \\ldots, A_n\\),\nes posible que los resultados de los sucesivos experimentos influyan\nen los resultados de los siguientes, y entonces\nhablaremos, por ejemplo, de la probabilidad del suceso \\(A_2\\) condicionada\nque ha ocurrido el suceso \\(A_1\\), y la calcularemos enumerando\nlos casos favorables y los casos posibles bajo el supuesto de haber\nsucedido \\(A_1\\). Esta situación aparece, por ejemplo, en los problemas de urnas.\nDesde el\npunto de vista de la definición frecuentista de la probabilidad, podemos\nconsiderar un experimento en el que se observen un suceso \\(\\) en distintos\ngrupos o localizaciones, siendo \\(B\\) el suceso que indica la pertenencia \nese determinado grupo o característica.\nSe pueden considerar las frecuencias relativas del suceso \\(\\) sólo\npara aquellos experimentos en los que ha sucedido \\(B\\), y llamar estas\nfrecuencias40\nfrecuencias de \\(\\) condicionadas \\(B\\), \\(fr_{|B}\\).\nEstas frecuencias relativas las podemos calcular dividiendo el número de veces que\nocurren tanto \\(\\) como \\(B\\) \\((n_{AB})\\) entre el número total de veces que ocurre \\(B\\), \\((n_{B})\\):\\[fr_{| B}=\\frac{n_{AB}}{n_B}.\\]Ahora bien, como \\(fr_A= \\frac{n_A}{n}\\), \\(fr_B= \\frac{n_B}{n}\\) y \\(fr_{AB}= \\frac{n_{AB}}{n}\\),\nse tiene:\\[fr_{| B}=\\frac{n\\cdot fr_{AB}}{n\\cdot fr_B}=\\frac{fr_{AB}}{fr_B}.\\]Es decir, la frecuencia condicionada es igual la frecuencia conjunta dividido\npor la frecuencia marginal del suceso condicionante. Así pues, dado que para un número grande de realizaciones del experimento, las\nfrecuencias relativas equivalen la probabilidad, podemos definir la\nprobabilidad del suceso \\(\\) condicionada al suceso \\(B\\) como:\\[\\boxed{P(| B)=\\frac{P(\\cap B)}{P(B)}},\\]siempre y cuando \\(P(B) > 0\\). Se demuestra\nfácilmente41\nque esta definición de probabilidad condicionada cumple\nque dado un suceso \\(\\\\aleph\\), \\((\\Omega, \\aleph, \\wp(\\cdot|)\\) es un espacio de\nprobabilidad.La tabla 4.1 contiene las frecuencias con las que se\nhan observado los sucesos aprobar y suspender dos elementos evaluables\nde una asignatura: un examen y un trabajo.Designemos \\(AE\\) y \\(SE\\) los sucesos “aprobar el examen” y “suspender el examen”\nrespectivamente, y \\(\\) y \\(ST\\) los sucesos “aprobar el trabajo” y “suspender”\nel trabajo respectivamente. La probabilidad de aprobar el examen será:\\[P(AE)=\\frac{40}{100} = 0.4.\\]Si incluimos más información modo de condición, podemos calcular por ejemplo\nla probabilidad de aprobar el examen condicionado que se ha aprobado el trabajo:\\[P(AE | )=\\frac{P(AE \\cap )}{P()}=\\frac{30/100}{35/100} \\simeq 0.8571 .\\]Tabla 4.1: Datos ejemplo probabilidad condicionada","code":""},{"path":"introp.html","id":"probabilidad-de-la-intersección-de-sucesos","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.4.2 Probabilidad de la intersección de sucesos","text":"La definición de probabilidad condicionada la que hemos llegado, nos\npermite calcular la probabilidad de la intersección de dos sucesos\ncualesquiera sin más que despejar de la fórmula. Además, tendremos dos formas\nde calcularla, según conozcamos \\(P(|B)\\) o \\(P(B|)\\):\\[\\boxed{P(\\cap B)=P(|B)\\cdot P(B)=P(B|)\\cdot P()}.\\]Recuerda que \\(\\cap B\\) significa y B, mientras que\n\\(|B\\) significa si ocurre B.La probabilidad condicionada aparece en los muestreos sin reemplazamiento. Se suele\nasociar los problemas de urnas, o también la extracción de cartas de una\nbaraja. Por ejemplo, podemos calcular la probabilidad de sacar dos figuras\nseguidas de una baraja de cartas francesa, con 52 cartas en total de las cuales\n12 son figuras (J, Q, K de cada uno de los cuatro palos). Entonces, si definimos\n\\(A_1\\) como “sacar figura en la primera extracción” y \\(A_2\\) como “sacar figura\nen la segunda extracción,” entonces lo que buscamos es la probabilidad de que\nocurran los dos sucesos, \\(P(A_1 \\cap A_2)\\):En nuestro ejemplo de los sujetos en estudio, ¿cuál es la probabilidad de que un cliente al azar sea mujer y además responda al tratamiento?partir de la probabilidad condicionada se llega la regla de la cadena\npara calcular la probabilidad de la intersección de una serie de sucesos. La regla\nconsiste en ir multiplicando cada vez la probabilidad del suceso \\(A_i\\) condicionada\nla intersección de todos los anteriores.\\[P\\left( \\bigcap\\limits_{=1}^{n} A_i \\right) = P(A_1)\\cdot P(A_2|A_1)\\cdot P(A_3|A_1 \\cap A_2)\\cdot\\ldots\\cdot P\\left(A_n | \\bigcap\\limits_{=1}^{n-1} S_i \\right). \\]Por ejemplo, en una urna hay 5 bolas rojas y 3 bolas blancas. Hacemos 3\nextracciones. Si en una extracción sale blanca, devolvemos la bola\nla urna y metemos 2 bolas blancas adicionales. ¿Qué probabilidad\nhay de sacar 3 blancas seguidas?Si definimos los sucesos \\(A_1\\), \\(A_2\\) y \\(A_3\\) como “sacar bola blanca en la primera,\nsegunda y tercera extracción respectivamente,” entonces estamos buscando:\\[P(A_1 \\cap A_2 \\cap A_3),\\]\nque utilizando la regla de la cadena calcularemos como:\\[P(A_1)\\cdot P(A_2|A_1) \\cdot P(A_3|A_1 \\cap A_2).\\]En la situación inicial hay 3 de ocho bolas blancas. En el segundo experimento,\nsi hemos sacado blanca, la devolvemos y añadimos dos más, es decir tenemos 5 de diez\nbolas blancas. si la segunda vuelve ser blanca, entonces en el tercer experimento\ntenemos 7 de 12 bolas blancas. Por lo tanto:","code":""},{"path":"introp.html","id":"independencia-de-sucesos","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.4.3 Independencia de sucesos","text":"Si bien en muchas ocasiones el conocimiento de ciertos eventos afectan la\nprobabilidad de ocurrencia de otros, esto siempre tiene por qué ser así.\nEn estos casos, diremos que dos sucesos son independientes si el conocimiento\nde la ocurrencia de uno de ellos modifica la probabilidad de aparición del otro.\nPor tanto, en esos casos:\\[P(|B) = P()\\quad \\text{y}\\quad P(B|) = P(B).\\]Entonces, por la propia definición de la probabilidad condicionada, se tiene que\nsi dos sucesos son independientes, entonces:\\[\\boxed{P(\\cap B)=P()\\cdot P(B)}.\\]\nEsta fórmula, que es una definición en sí misma de independendencia de sucesos, nos\nproporciona también un método para comprobar si dos sucesos son independientes o \nconocidas las probabilidades de los mismos y la de la\nintersección42.Para más de dos sucesos, la regla de la cadena explicada más arriba se\nextiende inmediatamente de forma que la probabilidad de la intersección de \\(n\\) sucesos independientes es el producto de sus probabilidades:\\[P(A_1\\cap \\ldots \\cap A_n)=P(A_1) \\cdot \\ldots \\cdot P(A_n).\\]\nY en el caso particular de que los \\(n\\) sucesos sean equiprobables, tales que \\(P(A_i) = p \\;\\forall \\), entonces:\\[P(A_1\\cap \\ldots \\cap A_n)=p^n.\\]El lanzamiento sucesivo de una moneda o de un dado son claros ejemplos de sucesos independientes.En el lanzamiento de un dado dos veces seguidas (o lo que es lo mismo, en el lanzamiento\nde dos dados), el resultado del primero influye en el segundo. Por tanto, la\nprobabilidad de sacar dos seises en el lanzamiento de dos dados es:","code":""},{"path":"introp.html","id":"probabilidad-condicionada-e-independencia-en-iso-3534-1","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.4.4 Probabilidad condicionada e independencia en ISO 3534-1","text":"La norma UNE-ISO 3534-1 recoge las definiciones de probabilidad condicionada\ne independencia de la siguiente forma:Probabilidad condicionada; \\(P(|B)\\)Probabilidad de la intersección de \\(\\) y \\(B\\) dividida por la probabilidad de \\(B\\).— ISO 3534-1 2.6Sucesos independientesPar de sucesos tal que la probabilidad de la intersección de los dos sucesos es el producto de las probabilidades individuales.— ISO 3534-1 2.4","code":""},{"path":"introp.html","id":"probabilidad-total-y-fórmula-de-bayes","chapter":"Capítulo 4 Introducción a la Probabilidad","heading":"4.4.5 Probabilidad total y fórmula de Bayes","text":"La probabilidad condicionada nos permite calcular probabilidades de sucesos\nde los que tenemos información parcial, en el sentido de que conocemos\nsu probabilidad condicionada algún otro suceso del espacio muestral,\npero queremos saber la probabilidad total del suceso, independientemente\nde aquellos sucesos. Las condiciones para que podamos calcular la probabilidad\ntotal de este suceso, llamémosle \\(B\\), son:Disponer de una partición de sucesos del espacio muestral \\(A_1, A_2, \\ldots, A_n\\)\ntales que \\(A_i \\cap A_j = \\emptyset \\; \\forall \\neq j\\) y \\(\\displaystyle \\underset{=1}{\\overset{n}\\bigcup A_i} = \\Omega\\).Disponer de una partición de sucesos del espacio muestral \\(A_1, A_2, \\ldots, A_n\\)\ntales que \\(A_i \\cap A_j = \\emptyset \\; \\forall \\neq j\\) y \\(\\displaystyle \\underset{=1}{\\overset{n}\\bigcup A_i} = \\Omega\\).Conocer las probabilidades de cada uno de esos sucesos que forman la partición, \\(P(A_i)\\).Conocer las probabilidades de cada uno de esos sucesos que forman la partición, \\(P(A_i)\\).Conocer las probabilidades del suceso de interés condicionadas cada uno de los sucesos\nque forman la partición del espacio muestral, es decir, \\(P(B|A_i)\\).Conocer las probabilidades del suceso de interés condicionadas cada uno de los sucesos\nque forman la partición del espacio muestral, es decir, \\(P(B|A_i)\\).Entonces, según el teorema de la probabilidad total, se verifica que:\\[\\boxed{P(B)=\\sum\\limits_{=1}^{n} P(B/A_i)\\cdot P(A_i)}.\\]\nEn efecto, podemos ver gráficamente en la figura 4.7 que cada sumando de la\nfórmula de la probabilidad total se corresponde con las intersecciones\ndel suceso de interés \\(B\\) con cada uno de los sucesos de la partición \\(A_i\\). Como\nestas intersecciones son sucesos disjuntos, la probabilidad de su unión es la\nsuma de sus probabilidades por las propiedades de la probabilidad.\nFigura 4.7: Representación del espacio muestral particionado más otro suceso\nEl desarrollo de la fórmula de la probabilidad condicionada partir de la situación\ndescrita para calcular la probabilidad total, nos permite darle la vuelta\nla condición y encontrar probabilidades de los sucesos de la partición \\(A_i\\) condicionados\nque se haya producido el suceso \\(B\\). Partimos de la propia definición de \\(P(A_i|B)\\):\\[P(A_i|B)=\\frac{P(A_i\\cap B)}{P(B)}.\\]\nPero su vez, la probabilidad del numerador la podemos escribir como \\(P(A_i \\cap B)=P(B|A_i)\\cdot P(A_i)\\), y la probabilidad del denominador, aplicando la fórmula de la probabilidad total, es \\(P(B)=\\sum\\limits_{=1}^{n} P(B/A_i)\\cdot P(A_i).\\) Lo que da lugar\nla fórmula de Bayes o Teorema de Bayes:\\[\\boxed{P(A_i|B)=\\frac{P(B|A_i)\\cdot P(A_i)}{\\sum\\limits_{=1}^{n} P(B/A_i)\\cdot P(A_i)}},\\]\nsiempre que \\(P(B>0)\\), que se puede expresar de forma simplificada como:\\[\\boxed{P(A_i|B)=\\frac{P(B|A_i)\\cdot P(A_i)}{P(B)}}\\]En una empresa que produce componentes electrónicos tomamos 5 lotes de producto,\ncada uno compuesto de 50 componentes. Hay dos tipos de lotes. Los del\ntipo 1 (\\(A_1\\)) tienen 48 componentes correctos y 2 defectuosos. Los del tipo 2 (\\(A_2\\))\ntienen 45 componentes correctos y 5 defectuosos. Tenemos 3 lotes tipo 1 y 2\nlotes tipo 2. Si se toma uno de los 5 lotes al azar y se saca de éste\nuna pieza, ¿qué probabilidad hay de que ese componente sea defectuoso?La figura 4.8 representa la partición del espacio muestral de\neste ejemplo.En este ejemplo se dan todos los elementos que habíamos descrito para\ncalcular la probabilidad total del suceso \\(B:\\) “el componente es defectuosos.”\nTenemos información parcial, en el sentido de que conocemos las probabilidades\nde ser defectuoso para cada uno de los tipos de lote, es decir \\(P(B|A_1)=\\frac{2}{50}=0.04\\)\ny \\(P(B|A_2)=\\frac{5}{50}=0.1\\). También conocemos las probabilidades de los\ndos sucesos que constituyen la partición, \\(P(A_1) = \\frac{3}{5}=0.6\\) y\n\\(P(A_2) = \\frac{2}{5}=0.4\\). Entonces, por el teorema de la probabilidad total:\\[P(B)=P(B|A_1)\\cdot P(A_1) + P(B|A_2)\\cdot P(A_2)= 0.04\\cdot 0.6 + 0.1\\cdot 0.4=0.064.\\]\nSupongamos ahora que se extrae del conjunto de todos los lotes un componente al azar,\ny resulta que es defectuoso. ¿Cuál es la probabilidad de que esa pieza provenga de un\nlote del tipo 1?Nótese que ahora lo que buscamos es \\(P(A_1|B)\\), como conocemos las \\(P(B|A_i)\\) y\n\\(P(A_i)\\), entonces podemos aplicar la fórmula de Bayes. Como ya hemos calculado\nantes la probabilidad total de \\(B\\), podemos usar la fórmula abreviada:\nFigura 4.8: Representación del espacio muestral del ejemplo de los componentes electrónicos\nEn nuestro ejemplo, conocíamos las probabilidades de que un sujeto responda al tratamiento\nsegún si es hombre o mujer. También conocemos la probabilidad\nde que el sujeto sea hombre o mujer. Entonces podemos calcular la probabilidad\nde que un sujeto (independientemente de si es hombre o mujer) responda al tratamiento como:\\[P(S)=P(S|M)\\cdot P(M) + P(S|H)\\cdot P(H)= \\frac{2}{6}\\cdot \\frac{1}{2} + \\frac{1}{6}\\cdot \\frac{1}{2} = 0.25.\\]Si un sujeto responde al tratamiento, la probabilidad de que sea mujer es:El problema de Monty HallMonty Hall es el nombre del presentador del concurso televisivo\nestadounidense Let’s make deal\nque se emitió entre 1963 y 1990. En alguna de las fases del programa,\nel concursante tiene que elegir una entre tres puertas, dos de las cuales\ntienen detrás una cabra, mientras que la otra tiene un coche.\nUna vez elegida la puerta, el presentador muestra el contenido de una\nde las otras dos puertas, que contiene una cabra. Entonces el concursante\ntiene la opción de cambiar su puerta por la otra que queda cerrada.\n¿Es más ventajoso cambiar de puerta o quedarse con la elegida inicialmente?\n¿O da lo mismo?La solución puede parecer contraintuitiva, aunque tanto desde el razonamiento\ntravés de las frecuencias como con un desarrollo matemático se llega \nla misma conclusión. Y la clave está en la probabilidad condicionada.El problema de Monty Hall dio lugar historias curiosas que se pueden consultar en.43 Por ejemplo, el gran matemático Paul Erdös solo aceptó\ncomo buena la solución real tras comprobarla en una simulación por ordenador.\nInvito al lector que concurse en la aplicación que\nse muestra continuación44\ndurante un buen número de jugadas y\ncompruebe través de las frecuencias relativas qué estrategia ofrece mayor\nprobabilidad de ganar el coche.","code":""},{"path":"vauni.html","id":"vauni","chapter":"Capítulo 5 Variable aleatoria univariante","heading":"Capítulo 5 Variable aleatoria univariante","text":"En preparación.DefiniciónFunción de distribuciónVA discretaVA continua","code":""},{"path":"vabi.html","id":"vabi","chapter":"Capítulo 6 Variable aleatoria bivariante","heading":"Capítulo 6 Variable aleatoria bivariante","text":"En preparación.Distribución conjuntaCorrelación y regresión","code":""},{"path":"modelos.html","id":"modelos","chapter":"Capítulo 7 Modelos de distribución de probabilidad","heading":"Capítulo 7 Modelos de distribución de probabilidad","text":"En preparación.IntroducciónModelos discretosModelos continuosModelos multivariantes*","code":""},{"path":"muestreo.html","id":"muestreo","chapter":"Capítulo 8 Muestreo y estimación","heading":"Capítulo 8 Muestreo y estimación","text":"En preparación.Muestreo estadísticoEstimación y contrastesEstadísticosEstimadores puntuales (medias, proporciones, varianzas)Estimación por intervalosEstimación paramétricaInferencia Bayesiana*","code":""},{"path":"comparacion.html","id":"comparacion","chapter":"Capítulo 9 Comparación de grupos","heading":"Capítulo 9 Comparación de grupos","text":"En preparación.Comparación de atributosComparación de dos gruposComparación de más de dos grupos","code":""},{"path":"regresion.html","id":"regresion","chapter":"Capítulo 10 Modelos de regresión","heading":"Capítulo 10 Modelos de regresión","text":"En preparación.Regresión lineal simpleRegresión linealRegresión lineal múltipleOtros modelos*\n(GLM, GAM, …)","code":""},{"path":"doe.html","id":"doe","chapter":"Capítulo 11 Diseño de experimentos","heading":"Capítulo 11 Diseño de experimentos","text":"En preparación.IntroDiseños factorialesDiseños \\(2^k\\)Diseños fraccionales","code":""},{"path":"introc.html","id":"introc","chapter":"Capítulo 12 Introducción","heading":"Capítulo 12 Introducción","text":"En preparación.Historia de la calidadEstadística y calidadGestión de la calidadMejora de procesos vs control de calidadMetodologíasIntro Six Sigma*","code":""},{"path":"spc.html","id":"spc","chapter":"Capítulo 13 Control Estadístico de Procesos","heading":"Capítulo 13 Control Estadístico de Procesos","text":"En preparación.Intro SPCGráficos de controlCapacidad y rendimiento","code":""},{"path":"aceptacion.html","id":"aceptacion","chapter":"Capítulo 14 Inspección por muestreo","heading":"Capítulo 14 Inspección por muestreo","text":"En preparación.IntroPlanes para atributosPlanes para variables","code":""},{"path":"símbolos-abreviaturas-y-acrónimos.html","id":"símbolos-abreviaturas-y-acrónimos","chapter":"Apéndice A Símbolos, abreviaturas y acrónimos","heading":"Apéndice A Símbolos, abreviaturas y acrónimos","text":"","code":""},{"path":"símbolos-abreviaturas-y-acrónimos.html","id":"acrónimos","chapter":"Apéndice A Símbolos, abreviaturas y acrónimos","heading":"A.1 Acrónimos","text":"","code":""},{"path":"símbolos-abreviaturas-y-acrónimos.html","id":"letras-griegas","chapter":"Apéndice A Símbolos, abreviaturas y acrónimos","heading":"A.2 Letras griegas","text":"\\(^*\\) Mayúsculas","code":""},{"path":"símbolos-abreviaturas-y-acrónimos.html","id":"símbolos","chapter":"Apéndice A Símbolos, abreviaturas y acrónimos","heading":"A.3 Símbolos","text":"","code":""},{"path":"tablas.html","id":"tablas","chapter":"Apéndice B Tablas estadísticas","heading":"Apéndice B Tablas estadísticas","text":"","code":""},{"path":"tablas.html","id":"distribución-normal","chapter":"Apéndice B Tablas estadísticas","heading":"B.1 Distribución normal","text":"La siguiente tabla contiene la probabilidad de la cola superior de la distribución normal estándar \\(Z\\sim N(0;1)\\),\nes decir \\(1-F(z)=P[Z>z].\\).","code":""},{"path":"tablas.html","id":"resumen-modelos-de-distribución-de-probabilidad","chapter":"Apéndice B Tablas estadísticas","heading":"B.2 Resumen modelos de distribución de probabilidad","text":"","code":""},{"path":"repaso.html","id":"repaso","chapter":"Apéndice C Repaso","heading":"Apéndice C Repaso","text":"Este apéndice cubre algunas cuestiones matemáticas básicas que el lector\nde este libro con seguridad habrá aprendido con anterioridad. Se incluyen\ncomo referencia para facilitar el repaso aquellos que lo necesiten.","code":""},{"path":"repaso.html","id":"logaritmos-y-exponenciales","chapter":"Apéndice C Repaso","heading":"C.1 Logaritmos y exponenciales","text":"","code":""},{"path":"repaso.html","id":"combinatoria","chapter":"Apéndice C Repaso","heading":"C.2 Combinatoria","text":"Una de las definiciones de probabilidad implica contar\nel número de veces que puede ocurrir un suceso determinado. Por tanto,\nen muchas ocasiones el cálculo de probabilidades empieza contando las\nposibilidades de que ocurra un suceso. La Combinatoria es la parte de la\nMatemática discreta que nos ayuda en esta tarea. Incluimos un breve\nresumen con ejemplos de las fórmulas más habituales y su cálculo con R.","code":""},{"path":"repaso.html","id":"ejemplo-ilustrativo","chapter":"Apéndice C Repaso","heading":"C.2.1 Ejemplo ilustrativo","text":"Habitualmente se utilizan ejemplos de juegos de azar para introducir el\ncálculo de probabilidades, como lanzamiendo de monedas y dados, o\ncombinaciones de cartas en barajas de naipes. Para darle un enfoque\npráctico, utilizaremos lo largo del módulo un ejemplo ilustrativo que,\naunque totalmente inventado, se puede encontrar el lector\nen el futuro con ligeras variaciones según su ámbito de actuación.\nUtilizaremos en lo posible las cifras usadas en los problemas de azar\npara ver la utilidad de aquéllos ejemplos en casos más prácticos.Datos básicos:52 posibles usuarios de un servicio52 posibles usuarios de un servicioLa mitad son mujeresLa mitad son mujeres4 directivos, 12 mandos, resto operarios4 directivos, 12 mandos, resto operarios13 jóvenes, 26 adultos, 13 mayores (5, 18 y 3 mujeres en cada\ngrupo respectivamente)13 jóvenes, 26 adultos, 13 mayores (5, 18 y 3 mujeres en cada\ngrupo respectivamente)1 de cada seis hombres contratará el servicio (el doble si es mujer)1 de cada seis hombres contratará el servicio (el doble si es mujer)Nótese cómo podemos traducir el concepto de\nservicio cualquier ámbito: usuarios de salud o educación, enfermos de\nuna determinada patología, equipos de una infraestructura, etc. Asimismo\nlas categorías pueden ser cualesquiera aplicables los elementos de los\nconjuntos.","code":""},{"path":"repaso.html","id":"principio-básico-de-conteo","chapter":"Apéndice C Repaso","heading":"C.2.2 Principio básico de conteo","text":"Definición: Realizamos \\(k\\) experimentos sucesivamente, cada\nuno de ellos con \\(n_i\\) posibles resultados (\\(=1, \\ldots, k\\)). Entonces\nel número total de resultados posibles es:\\[n_1\\cdot n_2, \\cdot \\ldots \\cdot n_k\\]Ejemplo: Resultados posibles si tomamos al azar un individuo\ny observamos su grupo de edad y si contratará o el servicio.Código","code":"\n3*2\n#> [1] 6"},{"path":"repaso.html","id":"permutaciones","chapter":"Apéndice C Repaso","heading":"C.2.3 Permutaciones","text":"Definición: De cuántas formas posibles podemos ordenar un\nconjunto de \\(n\\) elementos sin repetirlos.\\[P_n = n! = n\\cdot(n-1)\\cdot(n-2)\\cdot\\ldots\\cdot 2\\cdot 1\\]Ejemplo: De cuántas formas podemos ordenar un conjunto de\ntres individuos, uno de cada categoría laboral.Código","code":"\nfactorial(3)\n#> [1] 6"},{"path":"repaso.html","id":"variaciones-muestreo-sin-reemplazamiento","chapter":"Apéndice C Repaso","heading":"C.2.4 Variaciones (muestreo sin reemplazamiento)","text":"Definición: De cuántas formas posibles podemos seleccionar\nuna muestra de \\(n\\) elementos de un conjunto total de \\(m\\), sin que se\nrepitan. Una ordenación distinta, es una posibilidad distinta.\\[V_{m,n} = m\\cdot(m-1)\\cdot(m-2)\\cdot\\ldots\\cdot (m-n+1) = \\frac{m!}{(m-n)!}\\]Ejemplo: De cuántas formas podemos seleccionar una muestra\nde 5 individuos en nuestro conjunto de 52 sin que se repitan (por\nejemplo para asignar un ranking)Código","code":"\nfactorial(52)/factorial(52-5)\n#> [1] 311875200"},{"path":"repaso.html","id":"variaciones-con-repetición-muestreo-con-reemplazamiento","chapter":"Apéndice C Repaso","heading":"C.2.5 Variaciones con repetición (muestreo con reemplazamiento)","text":"Definición: De cuántas formas posibles podemos seleccionar\nuna muestra de \\(n\\) elementos de un conjunto total de \\(m\\), pudiéndose\nrepetir. Una ordenación distinta, es una posibilidad distinta.\n\\[\\mathit{VR}_{m,n} = m^n\\]Ejemplo: De cuántas formas podemos seleccionar una muestra\nde 5 individuos en nuestro conjunto de 52 pudiéndose repetir (por\nejemplo para asignar premios consecutivamente)Código","code":"\n52^5\n#> [1] 380204032"},{"path":"repaso.html","id":"combinaciones-muestras-equivalentes","chapter":"Apéndice C Repaso","heading":"C.2.6 Combinaciones (muestras equivalentes)","text":"Definición: De cuántas formas posibles podemos seleccionar\nuna muestra de \\(n\\) elementos de un conjunto total de \\(m\\), sin importar\nel orden.\\[\\mathit{C}_{m,n} = \\binom{m}{n} = \\frac{m!}{n!(m-n)!}\\]\\(\\binom{m}{n}\\) se lee m sobre n, y se le conoce como número combinatorio.\nAlgunas propiedades importantes de los números combinatorios:\\[\\binom{m}{m} = \\binom{m}{0} = 1.\\]\n\\[\\binom{m}{1} = \\binom{m}{m-1} = m.\\]\n\\[\\binom{m}{n} + \\binom{m}{n+1} = \\binom{m+1}{n+1}\\]\nPor otra parte, por convenio se tiene que:\\[0!=1,\\]\\[\\text{si } <b \\implies \\binom{}{b} = 0.\\]Ejemplo: De cuántas formas podemos seleccionar una muestra\nde 5 individuos en nuestro conjunto de 52 sin importar el orden (por\nejemplo para asignar premios de una sola vez)Código","code":"\nchoose(52, 5)\n#> [1] 2598960"},{"path":"repaso.html","id":"combinaciones-y-permutaciones-con-repetición","chapter":"Apéndice C Repaso","heading":"C.2.7 Combinaciones y permutaciones con repetición","text":"Las combinaciones y\npermutaciones también se pueden dar con repetición, siendo las fórmulas\npara calcularlas las siguientes:\\[\\mathit{CR}_{m,n}= \\mathit{C}_{m+n-1,n}= \\frac{(m+n-1)!}{n!\\cdot(m-1)!}\\]\n\\[\\mathit{PR} = \\frac{n!}{!\\cdot b!\\cdot \\ldots\\cdot z!}\\]La primera situación es aquella en la que los\nelementos se pueden repetir, pero nos importa el orden en que lo\nhagan. La segunda aparece cuando el elemento del conjunto total de\nelementos aparece \\(\\) veces, y así sucesivamente.","code":""},{"path":"ampliación.html","id":"ampliación","chapter":"Apéndice D Ampliación","heading":"Apéndice D Ampliación","text":"En este apéndice se incluyen temas avanzados que pueden ser útiles al lector\nmás allá de un curso básico de estadística para ciencias o ingeniería, y\nque se han incluido en el cuerpo de los capítulos para mantener el nivel\nde una asignatura de grado.","code":""},{"path":"ampliación.html","id":"función-característica","chapter":"Apéndice D Ampliación","heading":"D.1 Función característica","text":"","code":""},{"path":"ampliación.html","id":"cambio-de-variable","chapter":"Apéndice D Ampliación","heading":"D.2 Cambio de variable","text":"","code":""},{"path":"ampliación.html","id":"variables-aleatorias-unidimensionales-mixtas","chapter":"Apéndice D Ampliación","heading":"D.3 Variables aleatorias unidimensionales mixtas","text":"","code":""},{"path":"ampliación.html","id":"variables-aleatorias-bidimensionales-mixtas","chapter":"Apéndice D Ampliación","heading":"D.4 Variables aleatorias bidimensionales mixtas","text":"","code":""},{"path":"ampliación.html","id":"algunos-modelos-de-distribución-continuos-más","chapter":"Apéndice D Ampliación","heading":"D.5 Algunos modelos de distribución continuos más","text":"","code":""},{"path":"ampliación.html","id":"distribución-beta","chapter":"Apéndice D Ampliación","heading":"D.5.1 Distribución Beta","text":"La distribución Beta se utiliza en problemas de inferencia relativos proporciones, especialmente en inferencia bayesiana.\\[X \\sim \\mathit{}(\\alpha, \\beta)\\]Función de densidad\\[f(x) = \n\\begin{cases}\n\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha-1}(1-x)^{\\beta -1} & \\text{si } 0 < x < 1\\\\\n0 & \\text{resto } \n\\end{cases}\\]En matemáticas, la función Gamma (\\(\\Gamma\\)) es una integral indefinida que tiene entre otras las siguientes propiedades:$() = _0x{} e^{-x} dx, > 0 $\\(\\Gamma(\\alpha + 1) = \\alpha \\Gamma(\\alpha)\\)\\(n \\\\mathbb{N}-\\{0\\} \\implies \\Gamma(n) = (n-1)!\\)\\(\\Gamma(\\frac{1}{2}) = \\sqrt{\\pi}\\)** Características**Esperanza: \\(E[X] = \\frac{\\alpha}{\\alpha + \\beta}\\)Varianza: \\(\\mathit{Var}[X] = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta+1)}\\)Caso particular: \\(\\mathit{}(1,1) = U(0,1)\\).Ejemplo\\(X\\): Proporción de clientes que contratarán el servicio\\(X\\sim \\mathit{}(1, 5)\\)Código","code":"\nmibeta <- function(x) dbeta(x, 1, 5)\ncurve(mibeta, lwd = 2)"},{"path":"ampliación.html","id":"distribución-gamma","chapter":"Apéndice D Ampliación","heading":"D.5.2 Distribución Gamma","text":"La distribución Gamma se utiliza, entre otros, para modelizar tiempos de espera hasta que suceden \\(\\alpha\\) eventos en un proceso de Poisson. De hecho, en inferencia bayesiana gamma es la distribución priori de la distribución de Poisson.\\[X \\sim \\mathit{Ga}(, b)\\]Función de densidad\\[f(x) =\n\\begin{cases}\n\\frac{b^}{\\Gamma()}x^{-1}{e}^{-bx} & \\text{si } 0 < x < \\infty\\\\\n0 & \\text{resto }\n\\end{cases}\\]CaracterísticasEsperanza: \\(E[X] = \\frac{}{b}\\)Varianza: \\(\\mathit{Var}[X] = \\frac{}{b^2}\\)$() = _0x{} e^{-x} dx $La exponencial es un caso particularCódigo","code":"\n\n\nmigamma <- function(x, a) dgamma(x, a, 2)\ncurve(migamma(x, 1), lwd = 2, xlim = c(0,10), \n      main = \"Distribución Gamma b = 2\")\ncurve(migamma(x, 2), lwd = 2, add = TRUE, lty = 2)\ncurve(migamma(x, 4), lwd = 2, add = TRUE, lty = 3)\nlegend(x = 6, y = 2, c(\"a = 1\", \"a = 2\", \"a = 4\"), lty = 1:3)"},{"path":"ampliación.html","id":"distribución-de-weibull","chapter":"Apéndice D Ampliación","heading":"D.5.3 Distribución de Weibull","text":"La distribución Gamma presenta algunos inconventientes al modelizar tiempos de vida, y por eso algunas veces se prefiere la distribución de Weibull, que básicamente sirve para lo mismo. Véase  para los detalles.\\[X \\sim \\mathit{}(, b) \\]Función de densidad\n\\[f(x) =\n\\begin{cases}\n\\frac{}{b}\\left (\\frac{x}{b} \\right)^{-1}e^{-(x/b)^} & \\text{si } x > 0\\\\\n0 & \\text{resto }\n\\end{cases}\\]CaracterísticasEsperanza: \\(E[X] =b \\Gamma\\left (1 + \\frac{1}{} \\right )\\)Varianza: \\(\\mathit{Var}[X] = b^2 \\left ( \\Gamma \\left (  1 + \\frac{2}{} \\right  )  - \\left ( \\Gamma \\left (1 + \\frac{2}{} \\right ) \\right )^2 \\right )\\)Código","code":"\nmiweibull <- function(x, a) dweibull(x, a, 2)\ncurve(miweibull(x, 1), lwd = 2, xlim = c(0,5), \n      ylim = c(0, 1),\n      main = \"Distribución Weibull b = 2\")\ncurve(miweibull(x, 2), lwd = 2, add = TRUE, lty = 2)\ncurve(miweibull(x, 5), lwd = 2, add = TRUE, lty = 3)\nlegend(x = 4, y = 1, c(\"a = 1\", \"a = 2\", \"a = 5\"), lty = 1:3)"},{"path":"ampliación.html","id":"modelos-de-distribución-de-probabilidad-multivariantes","chapter":"Apéndice D Ampliación","heading":"D.6 Modelos de distribución de probabilidad multivariantes","text":"","code":""},{"path":"ampliación.html","id":"modelos-de-distribución-de-probabilidad-relacionadas-con-la-normal","chapter":"Apéndice D Ampliación","heading":"D.7 Modelos de distribución de probabilidad relacionadas con la normal","text":"","code":""},{"path":"ampliación.html","id":"simulación-de-variables-aleatorias","chapter":"Apéndice D Ampliación","heading":"D.8 Simulación de variables aleatorias","text":"\\(U(0;\\; 1)\\): Generador de probabilidades aleatorias. Dada cualquier función de distribución \\(F\\), se pueden generar valores de esa VA obteniendo \\(F^{-1}(U(0;\\; 1))\\)","code":""},{"path":"demostraciones.html","id":"demostraciones","chapter":"Apéndice E Demostraciones","heading":"Apéndice E Demostraciones","text":"Em este apéndice se incluyen aquellas demostraciones de teoremas y propiedades\nincluidas en los capítulos para mantener el carácter práctico del mismo.","code":""},{"path":"demostraciones.html","id":"variable-aleatoria-discreta","chapter":"Apéndice E Demostraciones","heading":"E.1 Variable aleatoria discreta","text":"","code":""},{"path":"demostraciones.html","id":"función-de-probabilidad","chapter":"Apéndice E Demostraciones","heading":"E.1.1 Función de probabilidad","text":"","code":""},{"path":"demostraciones.html","id":"esperanza","chapter":"Apéndice E Demostraciones","heading":"E.1.2 Esperanza","text":"","code":""},{"path":"demostraciones.html","id":"varianza","chapter":"Apéndice E Demostraciones","heading":"E.1.3 Varianza","text":"","code":""},{"path":"creditos.html","id":"creditos","chapter":"Apéndice F Créditos","heading":"Apéndice F Créditos","text":"Los gráficos y diagramas generados son creación y propiedad del autor, salvo que se\nindique lo contrario. Su licencia de uso es la misma que la del resto de la\nobra, véase el Prefacio.La imagen de la portada es de dominio público, obtenida en pixabay.com, gracias al\nusuario Manuchi.Las imágenes de tipo clipart usadas en esta obra y las fotografías atribuidas\npertenecen al dominio público gracias openclipart.org, unplash.com o pixabay.com.R logo (c) 2016 R Foundation.","code":""},{"path":"referencias.html","id":"referencias","chapter":"Referencias","heading":"Referencias","text":"","code":""}]
