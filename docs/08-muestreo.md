# (PART) Inferencia estad칤stica {-}



# Muestreo y estimaci칩n {#muestreo}


## Muestreo Estad칤stico

El muestreo estad칤stico es el mecanismo por el que se selecciona la muestra a partir de una poblaci칩n. A grandes rasgos, hay que determinar c칩mo se seleccionan los elementos de la muestra y cu치ntos se seleccionan. Este tama침o muestral lo representamos por $n$, y a menudo se habla de "la $n$" del experimento (o del estudio, en general). El tama침o de la muestra lo determina la caracter칤stica que queremos estudiar, que se representada por una **variable aleatoria**. En funci칩n del modelo de distribuci칩n de probabilidad que sigue la variable aleatoria, se determina el tama침o de la muestra.


:::{.rmdcafe data-latex=""}
Es importante diferenciar las muestras estad칤sticas de las muestras "biol칩gicas" o de materiales. A veces estar치n relacionadas, pero otras veces ser치n cosas totalmente distintas y no relacionadas.
:::


El muestreo es muy importante en cualquier estudio estad칤stico para poder extraer
conclusiones v치lidas y tomar decisiones sobre la poblaci칩nrespaldadas por los datos. El aspecto
m치s importante es que tienen que ser muestras representativas de la la poblaci칩n.
Para asegurar esta representatividad, utilizamos m칠todos probabil칤sticos, de forma
que los sesgos (falta de representatividad) que se produzcan sean achacables 
칰nicamente al azar, y no a otro tipo de cuestiones.

No siempre realizamos estudios estad칤sticos basados en una muestra extra칤da ad-hoc, sino
que analizamos datos disponibles que se han recogido o est치n disponibles sin
realizar un muestreo. Con estos datos podemos hacer estudios observacionales
(frente a los experimentos dise침ados) siempre teniendo en cuenta que puede
haber sesgos y la muestra no represente a la poblaci칩n. Por otra parte, 
muchas veces no es posible hacer un muestreo completamente aleatorizado,
y entonces podemos recurrir a muestreos cuasi-probabil칤sticos. En cualquier
caso, hay que intentar evitar a toda costa las muestras "de conveniencia",
y plantearnos en todo momento si podemos considerar que es representativa
de la poblaci칩n.


:::{.rmdinfo data-latex=""}

La muestra debe **representar** a la poblaci칩n.

:::

## Muestreo probabil칤stico

Entre los muestreos probabil칤sticos, podemos elegir entre muestreo aleatorio simple (MAS), muestreo estratificado, muestreo por conglomerados y muestreo sistem치tico. Salvo en este 칰ltimo, en los dem치s necesitamos una enumeraci칩n e identificaci칩n de los individuos de la poblaci칩n. En el muestreo sistem치tico, necesitamos solamente un orden.

El **muestreo aleatorio simple** es el m치s sencillo. Todos los elementos de la poblaci칩n tienen la misma probabilidad de pertenecer a la muestra. Requiere tener identificados de alguna manera a los individuos de la poblaci칩n, y es adecuado en poblaciones peque침as, homog칠neas, en las que no hay patrones conocidos. 


:::{.rmdejemplo data-latex=""}

Se dispone del listado de depuradoras de agua de una regi칩n y se quiere estudiar alguna
caracter칤stica espec칤fica de instalaciones sin hacer an치lisis a todas las depuradoras. Se seleccionan
al azar un n칰mero de depuradoras determinado.

:::

El **muestreo estratificado** es m치s adecuado en poblaciones no homog칠neas. 
Se conocen grupos dentro de la poblaci칩n, que son diferentes entre ellos, 
pero las subpoblaciones dentro de los grupos son homog칠neas. Adem치s, se 
conoce algo sobre la distribuci칩n de la caracter칤stica en cada grupo.
Entonces se obtiene una muestra aleatoria de cada uno de los grupos (estratos).
Este tipo de muestreo no es apropiado en poblaciones peque침as.


:::{.rmdejemplo data-latex=""}

Si estamos estudiando una poblaci칩n en la que se sabe que la variable de inter칠s se comporta de forma diferente en distintas CCAA, se consideran estos  estratos y se obtiene una submuestra de cada uno (por ejemplo en el caso anterior de las depuradoras).
:::


El **muestreo por conglomerados** tambi칠n asume que se dispone de grupos en la poblaci칩n, 
pero son homog칠neos entre s칤 (se parecen). 
Pero dentro de cada grupo la variable se comporta de forma heterog칠nea.
Puede existir una jerarqu칤a (conglomerados dentro de los conglomerados).
Entonces se obtiene una muestra de grupos (no de individuos). 
Despu칠s se pueden estudiar TODOS los individuos de los grupos de la muestra, o aplicar otro muestreo dentro (por ejemplo, estratificado). Es adecuado cuando es m치s f치cil llegar a todos los elementos de un grupo.


:::{.rmdejemplo data-latex=""}

Se estudian h치bitos de higiene en las familias en una ciudad. Se divide en barrios y se elige muestra de barrios. Dentro de cada barrio, se eligen aleatoriamente edificios, y se estudian todas las familias del edificio

:::

No siempre tenemos la lista de elementos, como en los casos anteriores. Pero s칤 podemos "ordenarlos" de alguna manera,
por ejemplo, conforme llegan muestras (en el sentido biol칩gico) a un laboratorio. Entonces podemos
realizar un **muestreo sistem치tico**. Para poder usarlo es importante estar 
seguro de que la caracter칤stica no depende del orden.
Entonces, se elige un punto de partida (idealmente, aleatorio) y se toman elementos separados a distancia $k$ (coeficiente de elevaci칩n). Se puede aplicar en vez de MAS en cualquiera de las situaciones anteriores.


:::{.rmdejemplo data-latex=""}

En la producci칩n de un fertilizante en bolas, se tomar치n muestras de 10 bolas cada hora. Se elige aleatoriamente un instante la primera hora, y a partir de ah칤 cada 60 minutos se elegir치n las siguientes 10 bolas.
:::


Cuando no es posible hacer un muestreo probabil칤stico, algunas veces pueden ser v치lidos 
muestreos no probabil칤sticos. Entonces podremos hacer estudios observacionales,
e incluso aplicar t칠cnicas de inferencia estad칤stica, pero con ciertas precauciones.
Las conclusiones pueden no ser v치lidas para toda la poblaci칩n, y hay que tenerlo en cuenta.
Hay que procurar que, al menos cualitativamente, podamos presumir que la muestra representa a la poblaci칩n,
o al menos no tener evidencias de que no es as칤. Los estudios observacionales (sobre datos que est치n ah칤) son tambi칠n muy valiosos. Si estos estudios nos dan luz sobre algo suficientemente importante, puede merecer la pena dise침ar un experimento para confirmar las conclusiones.


## Par치metros y estimadores

Recordemos que los par치metros se definen sobre una Variable Aleatoria $X$ de la **poblaci칩n**. Son **Desconocidos**, pero siguen un modelo de distribuci칩n de probabilidad te칩rica de la variable aleatoria subyacente. En general, los queremos **estimar** mediante inferencia param칠trica. Los estad칤sticos son valores que se calculan con los datos de la **muestra**. En cada muestra ser치n distintos, es decir, habr치 variabilidad, y por tanto son variables aleatorias, que siguen tambi칠n una **distribuci칩n** de probabilidad. Esa distribuci칩n de probabilidad del estad칤stico es lo que llamamos distribuci칩n en el muestreo.



:::{.rmdejemplo data-latex=""}

$\mu, \sigma^2 \text{ y }  \pi$ representan los par치metros media, varianza y proporci칩n de una determinada caracter칤stica en la poblaci칩n. Son desconocidos, y dependen de la distribuci칩n de la caracter칤stica en estudio. 
$\bar x, s^2 \text{ y } p$ son estad칤sticos calculados con los $n$ datos de una muestra.
:::

Un estimador es un estad칤stico mediante el cual estimamos el valor de un 
par치metro. Esa estimaci칩n estar치 sujeta a un error, que se puede cuantificar si se ha seguido un muestreo probabil칤stico. El error va a depender de las propiedades del estimador y del tama침o de la muestra.
Representamos con $\hat \mu = \bar x$ que la media muestral $\bar x$ es un estimador de la media poblacional $\mu$


:::{.rmdejemplo data-latex=""}
* Proporci칩n: $\hat \pi = p$
* Media: $\hat \mu = \bar x$ 
* Varianza: $\hat \sigma^2 = s^2 = \frac{1}{n-1}\left( \sum x_i^2 - n \bar x^2 \right )$
:::


Para determinar qu칠 estimador utilizar para un par치metro, se estudia su 
distribuci칩n en el muestreo. Las siguientes son propiedades deseables de los estimadores:

* **Insesgado**: Que la esperanza del estimador sea igual al verdadero valor del par치metro.

* **Eficiente**: Que tenga la m칤nima varianza posible.

* **Consistente**: Que tenga menor variabilidad a mayor tama침o de muestra.


## Distribuci칩n en el muestreo de los principales estad칤sticos

### Media muestral

Sea la variable aleatoria $X$ con $E[X] = \mu$ y $V[X] = \sigma^2$. Obtenemos muestras de tama침o $n$: $x_1, \ldots, x_i, \ldots, x_n$. Usamos la media muestral como estimador de la media poblacional:

$$\hat  \mu = \bar x = \frac 1 n \sum\limits_1^n x_i.$$

Entonces $\overline X_{\{n\}}$ es la variable aleatoria "media de la caracter칤stica $X$ en muestras de tama침o $n$", y por
las propieadades de la esperanza y la varianza:

* $E[\overline X_{\{n\}}]$ = $\mu$,

* $V[\overline X_{\{n\}}] = \frac{\sigma^2}{n}$.


### Teorema Central del L칤mite


Sean $X_1, \ldots, X_n$ variables aleatorias independientes e id칠nticamente distribuidas, con
media $\mu$ y varianza $\sigma^2$. Y sea $\overline X$ el promedio de esas variables aleatorias:

$$\overline X = \frac 1 n \sum\limits_{i=1}^n X_i$$

Entonces, para $n$ suficientemente grande, la variable aleatoria $\overline X_{\{n\}}$ sigue una distribuci칩n normal de media $\mu$ y varianza $\frac{\sigma^2}{n}$:

$$\overline X_{\{n\}} \sim N\left(\mu; \frac{\sigma}{\sqrt{n}} \right)$$

El Teorema Central del L칤mite nos va a permitir hacer inferencia de cualquier variable aleatoria $X$ utilizando las propiedades de la distribuci칩n normal.


### Varianza muestral

La varianza poblacional, calculada con $n$ en el denominador, es un estimador **sesgado**:

$$E\left[\frac 1 n \sum (x_i-\bar x)^2 \right] = \frac{n}{n-1}\sigma^2.$$

Por eso usamos la "cuasivarianza" o varianza muestral:

$$\hat \sigma^2 = s^2 = \frac{ 1}{ n-1} \sum (x_i-\bar x)^2$$
Se cumple que:

* $E[s^2] = \sigma^2$
* $V[s^2] = \frac{2\sigma^4}{n-1}$

Para determinar la distribuci칩n en el muestreo de la varianza muestral, primero tenemos
que definir la distribuci칩n $\chi^2$, que tiene un 칰nico par치metro, los grados de libertad $n$.
Se define como la suma de $n$ variables aleatorias normales independientes estandarizadas al cuadrado:

$$\chi^2_n = Z_1^2 + \ldots + Z_n^2;\quad E[\chi^2_{n}]=n; \quad V[\chi^2_{n}]=2n$$

Se cumple, independientemente de la distribuci칩n de $X$, que:

$$\frac{(n-1)s^2}{\sigma^2}\sim \chi^2_{n-1},$$
que es la distribuci칩n que usaremos para hacer inferencia sobre la varianza de la poblaci칩n.

### Proporci칩n muestral

Sea la variable aleatoria $X:$ N칰mero de elementos de la muestra de tama침o $n$ que presentan la caracter칤stica en estudio.
Entonces al extraer la muestra, se obtienen valores $x \in \{1, \ldots, n\}$, y el estad칤stico proporci칩n muestral ser치 $p = \frac x n$. Entonces, la probabilidad de que el par치metro $\pi$ tome un valor determinado $p=\frac x n$, es equivalente a la probabilidad de que la variable $X$ tome el valor $x$:

$$P[\pi = p] = P\left [\pi = \frac x n\right] = P[X = x]$$

Por tanto, la distribuci칩n exacta en el muestreo de $\hat \pi = p$ es una Binomial de par치metros $n$ y $\pi$.

Como la binomial es una suma de distribuciones de Bernoulli, entonces $p$ es una media: $p=\frac X n = \frac{\sum X_i}{n}$, y por el Teorema Central del L칤mite: 

$$P = \frac{X}{n}\approx N\left(\pi, \sqrt{\frac{\pi(1-\pi)}{n}}\right).$$
Tambi칠n se puede definir la distribuci칩n en el muestreo del n칰mero de elementos de la muestra con la caracter칤stica, $X$:

$$X=np \sim N(n\pi, \sqrt{n\pi(1-\pi))}.$$

## Tama침o muestral para estimar la media

Recordemos que no conocemos los par치metros de la poblaci칩n, por tanto necesitamos una forma de estimar el error que estamos cometiendo. Definimos entonces el error est치ndar de la media (_Standard Error_, SE) como: 

$$SE=\frac{s}{\sqrt{n}}$$

como medida de dispersi칩n del promedio muestral. A veces se usa error t칤pico como sin칩nimo. 


:::{.rmdinfo data-latex=""}

A mayor tama침o muestral, menor variabilidad, y menor error en las estimaciones.

:::



El error depende del tama침o muestral, y tambi칠n podemos determinar cu치l debe ser 
el tama침o de la muestra $n$ para cometer, como m치ximo, un determinado error $e$.
Y esto lo haremos con una cierta **confianza**. 
En los m칠todos param칠tricos, este nivel de confianza tiene que ver con el **muestreo**.
Indica la proporci칩n de veces que cometo un error inferior a $e$ si repito el muestreo 
un n칰mero grande de veces. Se suele expresar como porcentaje, por ejemplo 95%, 99%, etc.


Definimos el **nivel de significaci칩n** $\alpha$ como el complementario del nivel de confianza. Por ejemplo, 
para un nivel de confianza del 95% tendr칤amos un nivel de significaci칩n de 0,05. Entonces, para la media de una variable aleatoria $X$ que sigue una distribuci칩n normal, si tipificamos:

$$\frac{\overline X- \mu}{\frac{\sigma}{\sqrt{n}}}\sim N(0; 1).$$

Entonces para cumplir la confianza indicada anteriormente, se debe dar la siguiente condici칩n:

\begin{equation} 
  P\left[-z_{\frac{\alpha}{2}}<\frac{\overline x- \mu}{\frac{\sigma}{\sqrt{n}}}<z_{\frac{\alpha}{2}}\right] = 1-\alpha,
  (\#eq:n1)
\end{equation} 

donde $z_{\frac{\alpha}{2}}$ es el cuantil de la distribuci칩n normal estandarizada para una probabilidad de $1-\frac{\alpha}{2}$.


:::{.rmdinfo data-latex=""}
Normalmente se omite en $z_{\frac{\alpha}{2}}$ el s칤mbolo "$1-$" por comodidad al ser sim칠tricos: $z_\frac \alpha 2= - z_{1-\frac \alpha 2}$.

:::

<img src="08-muestreo_files/figure-html/unnamed-chunk-1-1.png" width="60%" style="display: block; margin: auto;" />


:::{.rmdejemplo data-latex=""}

Para un nivel de significaci칩n $\alpha = 0{,}05$, $z_{\frac{\alpha}{2}} \simeq 1{,}96$. Podemos encontrar este valor en las tablas o con m치s precisi칩n usando la siguiente expresi칩n de R:

````
qnorm(0.95)
````

:::

Despejando $\mu$ en la ecuaci칩n \@ref(eq:n1):

$$P\left[\overline x-z_{\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}< \mu < \overline x+z_{\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}\right] = 1-\alpha.$$

De aqu칤, el error que estoy cometiendo un $100 \times (1-\alpha)$% de las veces al estimar la media $\mu$ con la media muestral $\bar x$ y muestras de tama침o $n$ es:

$$e=z_{\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}},$$

de donde despejando $n$, tenemos una expresi칩n general para calcular el tama침o de muestra:

$$n = \frac{z_{\frac{\alpha}{2}}^2 \sigma^2}{e^2}.$$

Esta expresi칩n nos sirve tal cual para calcular el tama침o de muestra para estimar la
media poblacional de una variable aleatoria normal con **varianza conocida** $\sigma^2$,
y tama침o poblacional grande. Si el tama침o de la poblaci칩n es peque침o y conocido, $N$, entonces
el tama침o de la muestra se calcula con esta otra f칩rmula:

$$n = \frac{N\cdot z_{\frac{\alpha}{2}}^2 \cdot \sigma^2}{e^2\cdot (N-1)+ z_{\frac{\alpha}{2}}^2 \cdot \sigma^2},$$

Si la varianza es desconocida, sustituimos $\sigma$ por $s$. Si no tenemos $s$, se estima el caso m치s desfavorable.


:::{.rmdejemplo data-latex=""}
Queremos estimar la valoraci칩n que hacen los clientes de un determinado servicio energ칠tico en una puntuaci칩n de 0 a 10. El caso m치s desfavorable (para el tama침o de la varianza) ser칤a que la mitad de los clientes contestaran un 0 y la otra mitad un 10. O, equivalentemente, que contestara un cliente con un cero y otro con un 10. Entonces, la varianza $s^2$ ser칤a 50. Y el tama침o de muestra m칤nimo para estimar la puntuaci칩n media en una poblaci칩n grande y no equivocarnos en m치s de $e = 1$ punto ser칤a de $n =136$ clientes.
:::


```r
var(c(0,10))
#> [1] 50
(qnorm(0.95)^2*50)/(1^2)
#> [1] 135.2772
```

## Tama침o muestral para estimar la proporci칩n

Asumimos que ser치n muestras grandes, y aplicando la aproximaci칩n de la distribuci칩n binomial por la normal, tenemos que para poblaciones grandes:

$$n = \frac{z_{\frac{\alpha}{2}}^2 \cdot \pi\cdot(1-\pi)}{e^2},$$
y para poblaciones peque침as de tama침o $N$:

$$n = \frac{N\cdot z_{\frac{\alpha}{2}}^2\cdot \pi\cdot(1-\pi)}{e^2\cdot (N-1)+ z_{\frac{\alpha}{2}}^2 \cdot \pi\cdot(1-\pi)}.$$

Si no hay informaci칩n sobre el par치metro $\pi$, se toma el caso m치s desfavorable, que siempre es: $\pi = (1-\pi) = 0{,}5.$


## Estimaci칩n puntual

Uno de los objetivos de la inferencia estad칤stica es la estimaci칩n de los par치metros de la
poblaci칩n, a partir de los datos de la muestra. Mediante la estimaci칩n puntual daremos
un valor 칰nico como estimaci칩n del par치metro, mediante un estimador (funci칩n aplicada a los datos de
la muestra). As칤, para los par치metros m치s importantes tenemos los siguientes estimadores:

* Proporci칩n: $\hat \pi = p = \frac x n$.
* Media: $\hat \mu = \bar x = \frac{\sum x_i}{n}$. 
* Varianza: $\hat \sigma^2 = s^2 = \frac{1}{n-1}\left( \sum x_i^2 - n \bar x^2 \right )$.

Se pueden determinar los mejores estimadores para cualquier par치metro de cualquier
distribuci칩n de probabilidad, que cumplan las caracter칤sticas de insesgadez, eficiencia y consistencia. 
Para ello se pueden utilizar diversos m칠todos, como el m칠todo de los momentos o el de m치xima verosimilitud,
que no se tratan en este texto aplicado.


:::{.rmdejemplo data-latex=""}
`<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:green;overflow:visible;position:relative;"><path d="M210.6 5.9L62 169.4c-3.9 4.2-6 9.8-6 15.5C56 197.7 66.3 208 79.1 208H104L30.6 281.4c-4.2 4.2-6.6 10-6.6 16C24 309.9 34.1 320 46.6 320H80L5.4 409.5C1.9 413.7 0 419 0 424.5c0 13 10.5 23.5 23.5 23.5H192v32c0 17.7 14.3 32 32 32s32-14.3 32-32V448H424.5c13 0 23.5-10.5 23.5-23.5c0-5.5-1.9-10.8-5.4-15L368 320h33.4c12.5 0 22.6-10.1 22.6-22.6c0-6-2.4-11.8-6.6-16L344 208h24.9c12.7 0 23.1-10.3 23.1-23.1c0-5.7-2.1-11.3-6-15.5L237.4 5.9C234 2.1 229.1 0 224 0s-10 2.1-13.4 5.9z"/></svg>`{=html} La normativa de calidad del agua^[https://www.boe.es/buscar/act.php?id=BOE-A-2003-3596] determina que el par치metro pH debe estar 
entre 6.5 y 9.5 unidades de pH. Se obtienen 30 muestras aleatorias en hogares y se mide el pH, registrando tambi칠n si el edificio tiene dep칩sito de agua y la cantidad de antimonio en $\mu$g/l. Los datos se
muestran en la tabla \@ref(tab:ph1). Podr칤amos estimar con estos datos la media de pH en la poblaci칩n, la varianza, y la proporci칩n de edificios con dep칩sito de agua, utilizando los estimadores indicados anteriormente. 
:::







:::{.rmdpractica data-latex=""}
`<svg aria-hidden="true" role="img" viewBox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:steelblue;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"/></svg>`{=html} El siguiente c칩digo calcula la media muestral del pH, la varianza muestral del pH, y la
proporci칩n muestral de edificios con dep칩sito de agua (y por tanto tambi칠n si dep칩sito de agua). Los datos se importan directamente
de una url.
:::


```r
ph1 <- readr::read_rds("https://lcano.com/data/eaci/ph1.rds")
mean(ph1$pH)
#> [1] 8.041267
var(ph1$pH)
#> [1] 0.2134909
prop.table(table(ph1$deposito))
#> 
#>        No        S칤 
#> 0.6333333 0.3666667
```


## Estimaci칩n por intervalos

Al hacer la estimaci칩n puntual de cualquier par치metro, digamos gen칠ricamente $\theta$, estamos cometiendo un error $e$. Este error se puede cuantificar gracias a la distribuci칩n en el muestreo del estad칤stico que estemos usando como estimador. Y entonces podemos construir **intervalos de confianza** (IC) para el par치metro que estamos estimando.

El intervalo puede ser bilateral, con dos l칤mites inferior y superior, $\theta \in[\mathit{LI}, \mathit{LS}]$
de manera que:

$$P[\mathit{LI} < \theta < \mathit{LS}]=1-\alpha.$$
Esta expresi칩n indica que la probabilidad de que el verdadero valor del par치metro $\theta$ est칠 dentro del intervalo es $1-\alpha$. Dicho de otro modo, si repiti칠ramos el proceso de muestreo indefinidamente, el 95% de las veces el valor estimado del par치metro $\theta$ estar칤a dentro del intervalo de confianza. 
N칩tese que la probabilidad de que el par치metro sea mayor que el l칤mite
superior o menor que el l칤mite inferior ser치 $\frac \alpha 2$. Aqu칤, $1-\alpha$ es el nivel de confianza (se expresa a menudo como porcentaje), y $\alpha$ es el nivel de significaci칩n. 

Los intervalos de confianza tambi칠n pueden ser unilaterales, cuando solamente nos interesa saber un umbral m칤nimo o m치ximo del verdadero valor del par치metro. Estos intervalos tienen un 칰nico l칤mite inferior o superior, y se pueden expresar como:

* $[LI, \infty)$: $P[\theta > LI] = 1-\alpha$.
* $(-\infty, LS]$: $P\theta < LS] = 1-\alpha$.

La diferencia principal es que, con la misma confianza, queremos asegurarnos de que el verdadero valor del par치metro no es mayor que el l칤mite superior o no es menor que el l칤mite inferior (pero el lado opuesto nos da igual).

:::{.rmdejemplo data-latex=""}
`<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:green;overflow:visible;position:relative;"><path d="M210.6 5.9L62 169.4c-3.9 4.2-6 9.8-6 15.5C56 197.7 66.3 208 79.1 208H104L30.6 281.4c-4.2 4.2-6.6 10-6.6 16C24 309.9 34.1 320 46.6 320H80L5.4 409.5C1.9 413.7 0 419 0 424.5c0 13 10.5 23.5 23.5 23.5H192v32c0 17.7 14.3 32 32 32s32-14.3 32-32V448H424.5c13 0 23.5-10.5 23.5-23.5c0-5.5-1.9-10.8-5.4-15L368 320h33.4c12.5 0 22.6-10.1 22.6-22.6c0-6-2.4-11.8-6.6-16L344 208h24.9c12.7 0 23.1-10.3 23.1-23.1c0-5.7-2.1-11.3-6-15.5L237.4 5.9C234 2.1 229.1 0 224 0s-10 2.1-13.4 5.9z"/></svg>`{=html} La normativa de calidad del agua mencionada en el 
ejemplo del pH, determina un valor param칠trico de 5 $\mu$g/l de antimonio como
l칤mite m치ximo. En este caso, el intervalo de confianza que nos interesar치 es
un intervalo unilateral con un 칰nico l칤mite superior, ya que la caracter칤stica en 
estudio es "cuanto menor, mejor".
:::


Para determinar los intervalos de confianza, nos basamos en la distribuci칩n
en el muestreo de cada estimador $\hat \theta$. A continuaci칩n deduciremos
las f칩rmulas para los intervalos de confianza de la media, la varianza y
la proporci칩n.

### Intervalo de confianza para $\mu$: $\sigma^2$ conocida


La media muestral de tama침o $n$ sigue una distribuci칩n Normal con media $\mu$ y
varianza $\frac{\sigma^2}{n}$. Por tanto, tipificando, tenemos la siguiente distribuci칩n en
el muestreo:

\begin{equation}
\frac{\overline X- \mu}{\frac{\sigma}{\sqrt{n}}}\sim N(0; 1).
  (\#eq:dmz)
\end{equation} 

Par un nivel de confianza $1-\alpha$ determinado, si buscamos un **intervalo bilateral** tenemos que:

$$P\left[-z_{\frac{\alpha}{2}}<\frac{\overline x- \mu}{\frac{\sigma}{\sqrt{n}}}<z_{\frac{\alpha}{2}}\right] = 1-\alpha.$$

Y despejando $\mu$ tendremos que, con una confianza de $1-\alpha$, el verdadero valor del par치metro $\mu$ estar치 en el 
intervalo: 

$$\mu \in \left [\bar x - z_{\frac{\alpha}{2}}\cdot \frac{\sigma}{\sqrt{n}};\; \bar x + z_{\frac{\alpha}{2}}\cdot \frac{\sigma}{\sqrt{n}}\right].$$


O, de forma m치s compacta:

\begin{equation}
\boxed{\bar x \pm z_{\frac{\alpha}{2}}\cdot \frac{\sigma}{\sqrt{n}}}
  (\#eq:icz)
\end{equation} 

:::{.rmdpractica data-latex=""}
`<svg aria-hidden="true" role="img" viewBox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:steelblue;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"/></svg>`{=html} La estimaci칩n puntual de la media del pH en las
30 viviendas muestreadas en el ejemplo anterior, est치 sujeta a un cierto error. Vamos a 
dar la estimaci칩n como un intervalo de confianza al 95%. Supongamos que la varianza
es conocida e igual a $\sigma^2 = 0{,}25$. Para varianza conocida
no hay una funci칩n espec칤fica que nos d칠 el intervalo de confianza, pero es
muy f치cil obtenerlo con la siguiente expresi칩n, donde `c(-1,1)*` nos permite
obtener dos n칰meros, uno sumando y otro restando aquello a lo que multiplica,
y `qnorm(0.975)` nos da el valor de $z_{\frac \alpha 2}$, dado que si 
$1-\alpha=0{,}95 \implies \frac \alpha 2 = \frac{ 0{,}05}{ 2} = 0{,}025$. 
:::


```r
mean(ph1$pH) + c(-1, 1)*qnorm(0.975)*sqrt(0.25)/sqrt(30)
#> [1] 7.862347 8.220186
```


:::{.rmdinfo data-latex=""}
Recordemos que por simplicidad escribimos $z_{\frac{\alpha}{2}}$ pero tomamos
el cuantil de la distribuci칩n normal en $1-\frac \alpha 2$, es decir, 0,975.
En la pr치ctica, en este caso dar칤a igual, porque $z_{\frac \alpha 2} = - z_{1- \frac \alpha 2}$
y al aplicar la f칩rmula con $\pm$ el resultado ser칤an los mismos l칤mites. 
Sin embargo, en los intervalos bilaterales tenemos que poner cuidado con los c치lculos.
:::

Los **intervalos unilaterales** se deducen an치logamente, pero acotando el valor
de la distribuci칩n normal
solo en una de las colas. Por ejemplo, para un intervalo unilateral por la derecha:

$$P\left[\frac{\overline x- \mu}{\frac{\sigma}{\sqrt{n}}}<z_{\alpha}\right] = 1-\alpha.$$
Y el intervalo de confianza ahora ser치:

$$\boxed{\mu < \bar x + z_{\alpha}\cdot \frac{\sigma}{\sqrt{n}}}.$$
An치logamente, para un intervalo por la izquierda, el intervalo de
confianza ser치:

$$\boxed{\mu > \bar x - z_{\alpha}\cdot \frac{\sigma}{\sqrt{n}}}.$$

N칩tese que en los intervalos unilaterales utilizamos $z_\alpha$ en vez de $z_{\frac \alpha 2}$.
Esto es porque concentramos toda la probabilidad de error en una de las colas,
lo que adem치s reduce el error en la estimaci칩n. Por eso, cuando solo estemos interesados
en uno de los l칤mites, el superior o el inferior, siempre es preferible obtener
intervalos unilaterales. La figura \@ref(fig:zalpha) muestra una representaci칩n
de las tres situaciones.

<div class="figure">
<img src="08-muestreo_files/figure-html/zalpha-1.png" alt="$z_{\frac \alpha 2}$ o $z_\alpha$, esa es la cuesti칩n" width="672" />
<p class="caption">(\#fig:zalpha)$z_{\frac \alpha 2}$ o $z_\alpha$, esa es la cuesti칩n</p>
</div>


:::{.rmdpractica data-latex=""}
`<svg aria-hidden="true" role="img" viewBox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:steelblue;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"/></svg>`{=html} En el ejemplo del antimonio, queremos obtener 
un intervalo de confianza al 99%
para dar cuenta de la incertidumbre en la estimaci칩n puntual, pero
con mucha confianza. Adem치s, para
aumentar la precisi칩n de nuestra estimaci칩n por intervalos, solo
nos interesa el l칤mite superior, que es donde podemos tener el riesgo
para la salud. Supongamos que la varianza es conocida, $\sigma^2 = 0{,}0064$.
Entonces el l칤mite superior ser칤a el calculado con la siguiente
expresi칩n. Esto quiere decir que, con una confianza del 99%, la media del
antimonio en el agua potable es menor de 1,05 $\mu$g/l, muy lejos del l칤mite
marcado por la legislaci칩n (t칠ngase en cuenta que hacemos estimaciones sobre la media, no
sobre posibles valores individuales).
:::


```r
mean(ph1$antimonio) + qnorm(0.99)*sqrt(0.0064)/sqrt(30)
#> [1] 1.048645
```


### Intervalo de confianza para $\mu$: $\sigma^2$ desconocida

En la ecuaci칩n \@ref(eq:icz) asumimos que la varianza de la poblaci칩n $\sigma^2$
es conocida. Pero esto rara vez lo podemos dar por hecho, y en su lugar
lo que tenemos es una estimaci칩n a trav칠s de una muestra y el estad칤stico $s^2$.
Si sustituimos en la ecuaci칩n \@ref(eq:dmz), la distribuci칩n en el muestreo ya no 
es una distribuci칩n normal sino una $t$ de Student.

$$\frac{\overline X- \mu}{\frac{s}{\sqrt{n}}}\sim t_{n-1},$$

Par un nivel de confianza $1-\alpha$ determinado, si buscamos un **intervalo bilateral** tenemos que:

$$P\left[-t_{n-1,\frac{\alpha}{2}}<\frac{\overline x- \mu}{\frac{s}{\sqrt{n}}}<t_{n-1,\frac{\alpha}{2}}\right] = 1-\alpha.$$

Y despejando $\mu$ tendremos que, con una confianza de $1-\alpha$, el verdadero valor del par치metro $\mu$ estar치 en el 
intervalo: 

$$\boxed{IC_\mu=\bar x \pm t_{n-1, \frac{\alpha}{2}}\cdot \frac{s}{\sqrt{n}}}$$


La distribuci칩n $t$ de Student tiene un 칰nico par치metro $n$, que son los grados de libertad.
Sean las variables aleatorias $X, X_1, X_n \sim N(0;1)$. Entonces, la variable aleatoria
definida por: 

$$T = \frac{X}{\frac{1}{n}\sum X_i^2}\sim t_{n},$$
sigue una distribuci칩n $t$ de Student con $n$ grados de libertad, y que tiene
las siguientes caracter칤sticas:

* $E[T]=0$

* $V[T]=\frac{n}{n-2}$

* $n>30 \implies t_n \sim N(0;1)$

En la pr치ctica, obtendremos los valores $t_{n-1; \frac\alpha 2}$ en tablas o con
software, y sustituiremos los valores en la f칩rmula. O bien obtendremos directamente los
intervalos con el software.


:::{.rmdcafe data-latex=""}
쯇or qu칠 este nombre tan raro de la distribuci칩n? Realmente Student es el seud칩nimo
que utiliz칩 el estad칤stico ingl칠s William Sealy Gosset para publicar el trabajo
en el que la defini칩, ya que la empresa en la que trabajaba no permit칤a a sus empleados
publicar con su nombre para no desvelar secretos industriales.
A much@s estad칤stic@s nos gusta la historia, y el producto que fabricaba la empresa
en la que trabajaba el bueno de Gosset^[https://es.wikipedia.org/wiki/Prueba_t_de_Student].
:::



:::{.rmdinfo data-latex=""}
Lo explicado en el apartado anterior sobre los intervalos unilaterales aplica exactamente
igual a este caso, por lo que no lo repetiremos. La distribuci칩n $t$ 
es tambi칠n sim칠trica como la normal est치ndar, y pr치cticamente igual para $n > 30$. La figura
\@ref(fig:t) muestra la distribuci칩n normal est치ndar y la distribuci칩n $t$ para varios valores de $n$.
:::

<div class="figure">
<img src="08-muestreo_files/figure-html/t-1.png" alt="Distribuci칩n $t$ vs la normal" width="672" />
<p class="caption">(\#fig:t)Distribuci칩n $t$ vs la normal</p>
</div>



:::{.rmdpractica data-latex=""}
`<svg aria-hidden="true" role="img" viewBox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:steelblue;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"/></svg>`{=html}
Vamos a obtener los intervalos de confianza para el pH (bilateral) y para el
antimonio (unilateral) de los ejemplos anteriores, pero en este caso
asumiendo que la varianza es desconocida. 

En este caso s칤 tenemos una funci칩n que nos proporciona el intervalo de confianza,
y es la funci칩n `t.test()`. En realidad calcula m치s cosas, pero obtenemos solo
el elemento `conf.int` que tiene el intervalo de confianza. El c칩digo a 
continuaci칩n obtiene los intervalos de confianza pedidos. El argumento `alternative`
controla que sea bilateral (por defecto, _two-sided_) o unilateral (solo l칤mite superior, _less_, o 
solo l칤mite inferior, _greater_). El argumento `conf.level` controla el
nivel de confianza (_confidence level_).

N칩tese c칩mo, para la misma confianza, los intervalos obtenidos son m치s amplios
al no conocer la varianza (tenemos menos informaci칩n, y por tanto el error que
cometemos es mayor).


Se deja como ejercicio comprobar que aplicando la f칩rmula como en los casos
anteriores, se tiene el mismo intervalo. El cuantil de la distribuci칩n $t$
lo obtendr칤amos con la funci칩n `qt()`, por ejemplo para el intervalo unilateral
al 95% de confianza:

    qt(0.975, 29)

:::


```r
t.test(ph1$pH)$conf.int
#> [1] 7.868734 8.213799
#> attr(,"conf.level")
#> [1] 0.95
t.test(ph1$antimonio, alternative = "less", conf.level = 0.99 )$conf.int
#> [1]     -Inf 1.051616
#> attr(,"conf.level")
#> [1] 0.99
```


### Intervalo de confianza para la proporci칩n

Por el teorema central del l칤mite, si $n>30$

$$\boxed{IC_\pi=p\pm z_{\frac{\alpha}{2}}\cdot \sqrt{\frac{p\cdot (1-p)}{n}}}$$


### Intervalo de confianza para la varianza


#### Distribuci칩n en el muestreo

$$\frac{(n-1)s^2}{\sigma^2}\sim \chi^2_{n-1}$$

#### Nivel de confianza

$$P\left[\chi^2_{n-1,\frac{\alpha}{2}}<\frac{s^2\cdot(n-1)}{\sigma^2}<\chi^2_{n-1,1-\frac{\alpha}{2}}\right] = 1-\alpha$$

#### Intervalo de confianza 

$$\boxed{IC_\sigma=\left[ \frac{s^2\cdot(n-1)}{\chi^2_{n-1,\frac{\alpha}{2}}}; \frac{s^2\cdot(n-1)}{\chi^2_{n-1,1-\frac{\alpha}{2}}}\right]}$$

## Intervalos de confianza para comparaciones

* Tenemos dos muestras, $x_1, x_2$

* Posiblemente relacionadas

* Posiblemente con varianza conocida

* Posiblemente con varianzas iguales

* Posiblemente con tama침os distintos $n_1, n_2$

* El inter칠s est치 en comprobar si las muestras son "iguales" o no


游눠 Dependiendo de la combinaci칩n, se utiliza una f칩rmula u otra


### IC diferencia medias: $\mu_1 - \mu_2$, $\sigma_1. \sigma_2$ conocidas


Varianza agrupada, o conjunta (_pooled_): $s_p^2= \frac{(n_1 -1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}$

#### $\sigma_1, \sigma_2$ conocidas

$$IC_{\mu_1-\mu_2} = (\bar x_1 - \bar x_2) \pm z_{\frac \alpha 2}\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}$$

### IC diferencia medias: $\mu_1 - \mu_2$, $\sigma_1, \sigma_2$ desconocidas


#### $\sigma_1, \sigma_2$ desconocidas pero iguales $(\sigma_1 = \sigma_2)$
$$IC_{\mu_1-\mu_2} = (\bar x_1 - \bar x_2) \pm t_{n_1+n_2-2, \frac \alpha 2}s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}$$

#### $\sigma_1, \sigma_2$ desconocidas y distintas $(\sigma_1 \ne \sigma_2)$

$$IC_{\mu_1-\mu_2} = (\bar x_1 - \bar x_2) \pm t_{f, \frac \alpha 2}\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}$$

$$f=\left[ \frac{\left (\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}\right )^2}{\frac{\left(\frac{s_1^2}{n_1}\right)^2}{n_1-1}+\frac{\left(\frac{s_2^2}{n_2}\right)^2}{n_2-1}}\right]$$

游눠 Aproximaci칩n de Welch


### IC raz칩n de varianzas $\sigma_1/\sigma_2$

* Las varianzas son positivas, la diferencia nunca va a ser cero
* Ser치n iguales cuando el cociente sea igual a 1

$$IC_{\frac{\sigma_1}{\sigma_2}} = \left[\frac{\frac{s_1^2}{s_2^2}}{F_{n_1-1, n_2-1, \frac{\alpha}{2}}};\frac{s_1^2}{s_2^2}\cdot F_{n_2-1, n_1-1, \frac{\alpha}{2}} \right]$$



### Distribuci칩n F de Snedecor

$X_1, \ldots, X_{n_1}$; $Y_1, \ldots, Y_{n_2}$ v.a.i.i.d $\sim N(0;1)$:

$$F = \frac{\frac{ 1}{ n_1}\sum\limits_{i=1}^{n_1} X_i^2}{\frac{ 1}{ n_2}\sum\limits_{i=1}^{n_2} Y_i^2}\sim F_{n_1,n_2}$$
* $E[F] = \frac{n}{n-2}, \; n>2$

* $V[F] = \frac{2n^2(m+n-2)}{m(n-2)^2(n-4)}, \; n>4$



### Interpretaci칩n de las comparaciones

* Si el intervalo de confianza de la diferencia de medias contiene el cero, no podremos asegurar que haya diferencias entre las medias de las dos **poblaciones** (en general, nos interesar치 confirmar que s칤 hay diferencias)

* Si el intervalo de confianza de la raz칩n de varianzas contiene el 1, no podremos asegurar que haya diferencias entre las varianzas (en general, nos interesar치 comprobar que no hay diferencias)

游눠 O lo que es lo mismo, las diferencias observadas en las **muestras** son debidas al azar, y no a una diferencia real entre los par치metros poblacionales.


Esto lo hacemos tambi칠n con contrastes de hip칩tesis (siguiente apartado)




## Estimaci칩n no param칠trica

## Inferencia Bayesiana*


