<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capítulo 5 Variable aleatoria univariante | Estadística Aplicada a las Ciencias y la Ingeniería</title>
<meta name="author" content="Emilio L. Cano">
<meta name="description" content="Trabajar con sucesos y todas sus combinaciones posibles puede resultar muy costoso, o incluso imposible. Con las variables aleatorias pasamos del ámbito de los sucesos a los números reales, de...">
<meta name="generator" content="bookdown 0.27 with bs4_book()">
<meta property="og:title" content="Capítulo 5 Variable aleatoria univariante | Estadística Aplicada a las Ciencias y la Ingeniería">
<meta property="og:type" content="book">
<meta property="og:url" content="https://emilopezcano.github.io/estadistica-ciencias-ingenieria/vauni.html">
<meta property="og:image" content="https://emilopezcano.github.io/estadistica-ciencias-ingenieria/images/cover.png">
<meta property="og:description" content="Trabajar con sucesos y todas sus combinaciones posibles puede resultar muy costoso, o incluso imposible. Con las variables aleatorias pasamos del ámbito de los sucesos a los números reales, de...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Capítulo 5 Variable aleatoria univariante | Estadística Aplicada a las Ciencias y la Ingeniería">
<meta name="twitter:description" content="Trabajar con sucesos y todas sus combinaciones posibles puede resultar muy costoso, o incluso imposible. Con las variables aleatorias pasamos del ámbito de los sucesos a los números reales, de...">
<meta name="twitter:image" content="https://emilopezcano.github.io/estadistica-ciencias-ingenieria/images/cover.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><link href="libs/tabwid-1.0.0/tabwid.css" rel="stylesheet">
<link href="libs/tabwid-1.0.0/scrool.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="bs4_book.css">
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Estadística Aplicada a las Ciencias y la Ingeniería</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Buscar" aria-label="Buscar">
</form>

      <nav aria-label="Contenido"><h2>Contenido</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Bienvenida</a></li>
<li class="book-part">Estadística descriptiva</li>
<li><a class="" href="intro.html"><span class="header-section-number">1</span> Introducción</a></li>
<li><a class="" href="aed-uni.html"><span class="header-section-number">2</span> Análisis exploratorio univariante</a></li>
<li><a class="" href="aed-bi.html"><span class="header-section-number">3</span> Análisis exploratorio bivariante</a></li>
<li class="book-part">Probabilidad</li>
<li><a class="" href="introp.html"><span class="header-section-number">4</span> Introducción a la Probabilidad</a></li>
<li><a class="active" href="vauni.html"><span class="header-section-number">5</span> Variable aleatoria univariante</a></li>
<li><a class="" href="vabi.html"><span class="header-section-number">6</span> Variable aleatoria bivariante</a></li>
<li><a class="" href="modelos.html"><span class="header-section-number">7</span> Modelos de distribución de probabilidad</a></li>
<li class="book-part">Inferencia estadística</li>
<li><a class="" href="muestreo.html"><span class="header-section-number">8</span> Muestreo y estimación</a></li>
<li><a class="" href="comparacion2.html"><span class="header-section-number">9</span> Comparación de dos grupos</a></li>
<li><a class="" href="anova.html"><span class="header-section-number">10</span> Análisis de la Varianza</a></li>
<li><a class="" href="doe.html"><span class="header-section-number">11</span> Diseño de experimentos</a></li>
<li><a class="" href="regresion.html"><span class="header-section-number">12</span> Modelos de regresión</a></li>
<li class="book-part">Control estadístico de la calidad</li>
<li><a class="" href="introc.html"><span class="header-section-number">13</span> Introducción</a></li>
<li><a class="" href="spc.html"><span class="header-section-number">14</span> Control Estadístico de Procesos</a></li>
<li><a class="" href="aceptacion.html"><span class="header-section-number">15</span> Inspección por muestreo</a></li>
<li class="book-part">Apéndices</li>
<li><a class="" href="s%C3%ADmbolos-abreviaturas-y-acr%C3%B3nimos.html"><span class="header-section-number">A</span> Símbolos, abreviaturas y acrónimos</a></li>
<li><a class="" href="formulario.html"><span class="header-section-number">B</span> Formulario</a></li>
<li><a class="" href="tablas.html"><span class="header-section-number">C</span> Tablas estadísticas</a></li>
<li><a class="" href="repaso.html"><span class="header-section-number">D</span> Repaso</a></li>
<li><a class="" href="ampliaci%C3%B3n.html"><span class="header-section-number">E</span> Ampliación</a></li>
<li><a class="" href="demostraciones.html"><span class="header-section-number">F</span> Demostraciones</a></li>
<li><a class="" href="creditos.html"><span class="header-section-number">G</span> Créditos</a></li>
<li><a class="" href="referencias.html">Referencias</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/emilopezcano/estadistica-ciencias-ingenieria">Ver repositorio <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="vauni" class="section level1" number="5">
<h1>
<span class="header-section-number">Capítulo 5</span> Variable aleatoria univariante<a class="anchor" aria-label="anchor" href="#vauni"><i class="fas fa-link"></i></a>
</h1>
<p>Trabajar con sucesos y todas sus combinaciones posibles puede resultar muy costoso,
o incluso imposible. Con las variables aleatorias pasamos del ámbito de los sucesos a los números
reales, de forma que podemos hacer cálculos numéricos.
El interés de las variables aleatorias es poder modelizar la incertidumbre mediante
ellas. Es importante tener en cuenta que las
propiedades de las variables aleatorias son teóricas.
Mediante la inferencia estadística, podremos utilizar datos empíricos
de muestras para obtener conclusiones sobre la variable aleatoria que caracteriza a la población,
recuérdese la figura <a href="introp.html#fig:dogma">4.1</a> al principio del capítulo <a href="introp.html#introp">4</a>.</p>
<p>La figura <a href="vauni.html#fig:dogma2b">5.1</a> muestra la relación de las variables aleatorias con la
población. En una muestra tenemos datos con los que calculamos estadísticos (media,
varianza, etc) de esos datos. Representamos las frecuencias mediante histogramas.
Por su parte, la población sigue una distribución de probabilidad teórica, con unas
características teóricas (media, varianza, etc.). Ambos “mundos” se relacionan mediante
la inferencia estadística, que no se trata en este texto.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:dogma2b"></span>
<img src="05-vauni_files/figure-html/dogma2b-1.png" alt="Variables aleatorias vs. datos empíricos" width="70%"><p class="caption">
Figura 5.1: Variables aleatorias vs. datos empíricos
</p>
</div>
<div id="concepto-y-definición-de-variable-aleatoria" class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> Concepto y definición de variable aleatoria<a class="anchor" aria-label="anchor" href="#concepto-y-definici%C3%B3n-de-variable-aleatoria"><i class="fas fa-link"></i></a>
</h2>
<p>Las variables aleatorias son variables numéricas cuyos valores vienen determinados por el azar.
Utilizaremos letras mayúsculas <span class="math inline">\(X, Y, \ldots\)</span> para representar variables aleatorias, y letras minúsculas <span class="math inline">\(x, y, \ldots\)</span> para representar a los valores que toman. En definitiva, asignamos un número a cada posible resultado del experimento.
Matemáticamente, una variable aleatoria es una función definida sobre el espacio muestral <span class="math inline">\(\Omega\)</span>
perteneciente a un espacio de probabilidad <span class="math inline">\((\Omega, \aleph, \wp)\)</span>
y que toma valores en el <strong>conjunto</strong> de los números reales <span class="math inline">\(\mathbb{R}\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
X: \quad &amp; \Omega \longrightarrow \mathbb{R}\\
&amp; \omega \longrightarrow X(\omega)
\end{aligned}
\]</span></p>
<p>La variable aleatoria así definida cumple las siguientes características:</p>
<ol style="list-style-type: decimal">
<li>La imagen de cada elemento del espacio muestral, <span class="math inline">\(X(\omega)\)</span>, es única .</li>
<li>La inversa de la variable aleatoria aplicada a cualquier intervalo de <span class="math inline">\(\mathbb{R}\)</span>
pertenece a la sigma álgebra de sucesos <span class="math inline">\(\aleph\)</span>.</li>
</ol>
<p><span class="math display">\[M \in \mathbb{R} \implies X^{-1}(M) \in \aleph.\]</span></p>
<p>La medida de probabilidad <span class="math inline">\(\wp\)</span> del espacio de probabilidad <span class="math inline">\((\Omega, \aleph, \wp)\)</span>
se aplica entonces a intervalos de los números reales en vez de a sucesos de <span class="math inline">\(\aleph\)</span>:</p>
<p><span class="math display">\[M \in \mathbb{R} \implies \wp(M)=P[X \in M].\]</span>
A esta medida de probabilidad inducida por una variable aleatoria se le suele denominar <strong>modelo de distribución de probabilidad</strong>.</p>

<div class="rmdejemplo">
<p>Consideremos un experimento consistente en lanzar una moneda equilibrada
al aire tres veces. El espacio
muestral de este experimento aleatorio es el siguiente:</p>
<p><span class="math display">\[\Omega=\{ (+,+,+), (c,+,+), (+,c,+), (+,+,c), (c,c,+),(c,+,c),  (+,c,c), (c,c,c) \}\]</span></p>
<p>Definamos ahora la variable aleatoria “Número de caras” en el experimento
anterior. La variable aleatoria quedaría definida como sigue:</p>
<p><span class="math display">\[\begin{aligned}
X: \quad &amp; \Omega &amp; \longrightarrow &amp; \quad \mathbb{R}\\
&amp; (+,+,+) &amp; \longrightarrow &amp; \quad 0\\
&amp; (c,+,+) &amp; \longrightarrow &amp; \quad 1\\
&amp; (+,c,+) &amp; \longrightarrow &amp; \quad 1\\
&amp; (+,+,c) &amp; \longrightarrow &amp; \quad 1\\
&amp; (c,c,+) &amp; \longrightarrow &amp; \quad 2\\
&amp; (c,+,c) &amp; \longrightarrow &amp; \quad 2\\
&amp; (+,c,c) &amp; \longrightarrow &amp; \quad 2\\
&amp; (c,c,c) &amp; \longrightarrow &amp; \quad 3
\end{aligned}\]</span></p>
<p>Por tanto, el campo de variación de la variable aleatoria <span class="math inline">\(X\)</span> o imagen de <span class="math inline">\(X\)</span> (<span class="math inline">\(\mathit{Im}(X)\)</span>) es:</p>
<p><span class="math display">\[\mathit{Im}(X) = \{0, 1, 2, 3\}\]</span></p>
<p>Ahora, basándonos en el espacio de probabilidad <span class="math inline">\((\Omega, \aleph, \wp)\)</span>, podemos
calcular probabilidades sobre cualquier subconjunto de <span class="math inline">\(\mathbb{R}\)</span>, por ejemplo:</p>
<span class="math display">\[P[X=0] = \frac{1}{8}; \quad P[X \geq 2] = \frac{1}{2}; \quad P[X &gt;10] = 0.\]</span>
</div>
<div id="tipos-de-variables-aleatorias" class="section level3" number="5.1.1">
<h3>
<span class="header-section-number">5.1.1</span> Tipos de variables aleatorias<a class="anchor" aria-label="anchor" href="#tipos-de-variables-aleatorias"><i class="fas fa-link"></i></a>
</h3>
<p>Las variables aleatorias quedan definidas por su <strong>campo de variación</strong> y el
<strong>conjunto de probabilidades</strong> que toman. El campo de variación es el recorrido
de la variable aleatoria, es decir, los valores que puede tomar. El conjunto de probabilidades
es el definido por la medida de probabilidad <span class="math inline">\(\wp\)</span>.</p>
<p>De acuerdo a la naturaleza de su campo de variación, las variables aleatorias
pueden ser principalmente de dos tipos:</p>
<ul>
<li>Discretas: toman un conjunto de valores numerable (<span class="math inline">\(x_i\)</span>).</li>
<li>Continuas: toman un conjunto de valores no numerable (<span class="math inline">\(x\)</span>).</li>
</ul>
<p>También hay variables aleatorias mixtas, que no se tratan en este texto.</p>
</div>
<div id="operaciones-con-variables-aletorias" class="section level3" number="5.1.2">
<h3>
<span class="header-section-number">5.1.2</span> Operaciones con variables aletorias<a class="anchor" aria-label="anchor" href="#operaciones-con-variables-aletorias"><i class="fas fa-link"></i></a>
</h3>
<p>En general, una función de variables aleatorias es otra variable aleatoria.
Sobre una o varias variables aleatorias podemos definir funciones.
En particular, en los próximos apartados
de este capítulo definiremos <strong>funciones</strong> para realizar cálculo de <strong>probabilidades</strong>
sobre los valores que puede tomar la variable aleatoria, <strong>transformaciones</strong>
de la variable aleatoria para calcular características de las mismas,
y <strong>combinaciones</strong> de variables aleatorias y sus propiedades. Matemáticamente:</p>
<p><span class="math display">\[
\begin{aligned}
X: \quad &amp; \Omega  \longrightarrow \mathbb{R}\\
g(X): \quad &amp; \mathbb{R} \longrightarrow \mathbb{R}\\
g(X,Y): \quad &amp; \mathbb{R}^2 \longrightarrow \mathbb{R}\\
\end{aligned}
\]</span></p>
<p>Los siguientes son ejemplos de funciones aplicadas a variables aleatorias:</p>
<p><span class="math display">\[X^2; \quad 1.5\cdot X; \quad aX + b; \quad X\cdot Y; \quad \ldots\]</span></p>
<hr>
</div>
<div id="variables-aleatorias-y-conjuntos" class="section level3" number="5.1.3">
<h3>
<span class="header-section-number">5.1.3</span> Variables aleatorias y conjuntos<a class="anchor" aria-label="anchor" href="#variables-aleatorias-y-conjuntos"><i class="fas fa-link"></i></a>
</h3>
<p>El paso de sucesos a variables aleatorias nos va a permitir operar con probabilidades
de la misma forma que hacíamos con los sucesos. Las mismas operaciones
que hacíamos con sucesos, las vamos a poder realizar con subconjuntos
de los números reales, ya que, en definitiva,
<span class="math inline">\(\mathbb{R}\)</span> es un conjunto. Así, el complementario de un suceso,
pasa a ser el complementario de un intervalo o
conjunto de intervalos de los números reales, la unión de dos sucesos pasa a ser el conjunto de
números que pertenecen a alguno de los dos subconjuntos de números reales, y la
intersección de sucesos pasa a ser el conjunto de números que pertenecen a los dos
subconjuntos de números reales. Algunos ejemplos:</p>
<ul>
<li>Complementario de un suceso: <span class="math inline">\([X \leq 1]^c\)</span>= <span class="math inline">\(X&gt;1\)</span>.</li>
<li>Unión de sucesos: <span class="math inline">\([10, 20] \cup (15, 30) = [10, 30)\)</span>.</li>
<li>Intersección de sucesos: <span class="math inline">\([10, 20] \cap (15, 30) = (15, 20]\)</span>.</li>
</ul>
</div>
</div>
<div id="función-de-distribución" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> Función de distribución<a class="anchor" aria-label="anchor" href="#funci%C3%B3n-de-distribuci%C3%B3n"><i class="fas fa-link"></i></a>
</h2>
<p>Definamos una función sobre una variable aleatoria que le asigne a cada
valor de <span class="math inline">\(X\)</span>, <span class="math inline">\(x\)</span>, la probabilidad de que la variable aleatoria <span class="math inline">\(X\)</span> tome
valores menores o iguales que dicho valor <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[\boxed{F(x) = P[X \leq x]}.\]</span></p>
<p><span class="math inline">\(F\)</span> será por tanto una función cuyo dominio es <span class="math inline">\(\mathbb{R}\)</span> y
recorrido el intervalo <span class="math inline">\([0, 1]\)</span>:</p>
<p><span class="math display">\[\begin{aligned}F: &amp; \mathbb{R}  \longrightarrow &amp; [0, 1]\\
&amp; x \longrightarrow &amp; F(x)
\end{aligned}\]</span></p>
<p>Propiedades de la función de distribución:</p>
<ul>
<li>Está acotada en el intervalo <span class="math inline">\([0, 1]\)</span>: <span class="math inline">\(0 \leq F(x) \leq 1\)</span>.</li>
<li>Monóntona no decreciente: <span class="math inline">\(a &lt; b \implies F(a) \leq F(b) \;\;\forall a, b \in \mathbb{R}\)</span>.</li>
<li>Continua por la derecha: <span class="math inline">\(\lim\limits_{x \to x_0^+} F(x) = F(x_0)\)</span>.</li>
<li>
<span class="math inline">\(\lim\limits_{x \to \infty} F(x) = 1\)</span>.</li>
<li>
<span class="math inline">\(\lim\limits_{x \to -\infty} F(x) = 0\)</span>.</li>
</ul>
<p>Una consecuencia de estas propiedades es la siguiente, que nos proporciona
una forma de calcular probabilidades para cualquier intervalo a partir de la
función de distribución:</p>
<p><span class="math display">\[\boxed{P[a &lt; X \leq b] = F(b)- F(a)}.\]</span></p>
<p>Podemos comprobarlo fácilmente pensando en los números reales como conjuntos y
aplicando las propiedades de la probabilidad. Efectivamente, a partir de <span class="math inline">\(F(b)\)</span>,
que se corresponde con la <span class="math inline">\(P[X\leq b]\)</span>, y como <span class="math inline">\(a &lt; b\)</span>:</p>
<p><span class="math display">\[X \leq b = (-\infty, b] = (-\infty , a] \cup (a, b]. \]</span>
Como <span class="math inline">\((-\infty , a]\)</span> y <span class="math inline">\((a, b]\)</span> con conjuntos disjuntos (sucesos mutuamente excluyentes):</p>
<p><span class="math display">\[P[X \in (-\infty, b]\, ] = P[X \in (-\infty , a]\,] + P[X \in (a, b]\,]\implies\\
P[X \in (a, b]\,] = P[X \in (-\infty, b]\, ] - P[X \in (-\infty , a]\,] = F(b)- F(a).\]</span></p>
<p>Además, por las propiedades de la probabilidad<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;O visto de otro modo, haciendo &lt;span class="math inline"&gt;\(b=\infty\)&lt;/span&gt;, y entonces &lt;span class="math inline"&gt;\(F(b)=1\)&lt;/span&gt;.&lt;/p&gt;'><sup>60</sup></a>:</p>
<p><span class="math display">\[\boxed{P[X&gt;a] = 1-F(a)},\]</span>
dado que <span class="math inline">\(P[X&gt;a] = P[(X\leq a)^c]=1 -P[X\leq a]=1-F(a).\)</span></p>
</div>
<div id="sec:vadi" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> Variable aleatoria discreta<a class="anchor" aria-label="anchor" href="#sec:vadi"><i class="fas fa-link"></i></a>
</h2>
<p>Son variables aleatorias discretas aquellas que pueden tomar un conjunto de valores
finito o infinito numerable,
<span class="math inline">\(x_i\)</span>, <span class="math inline">\(i=1, 2, \ldots, n\)</span> o <span class="math inline">\(i=1, 2, \ldots, \infty\)</span>.
Formalmente, son aquellas cuya <strong>función de distribución no es continua</strong>.
Esta discontinuidad es de salto finito,
y los saltos se producen en los valores que toma la variable, <span class="math inline">\(x_i\)</span>.
A cada posible valor <span class="math inline">\(x_i\)</span> se le asigna una probabilidad <span class="math inline">\(p(x_i) = P[X=x_i]\)</span>.
Los saltos son de longitud igual a <span class="math inline">\(p(x_i)\)</span>.</p>
<div id="función-de-probabilidad" class="section level3" number="5.3.1">
<h3>
<span class="header-section-number">5.3.1</span> Función de probabilidad<a class="anchor" aria-label="anchor" href="#funci%C3%B3n-de-probabilidad"><i class="fas fa-link"></i></a>
</h3>
<p>Dado que la variable aleatoria <span class="math inline">\(X\)</span> no toma valores entre <span class="math inline">\(x_{i-1}\)</span>, y <span class="math inline">\(x_i\)</span>, podemos
definir la <strong>función de probabilidad de una variable aleatoria discreta</strong> como:</p>
<p><span class="math display">\[\begin{aligned}
p: &amp;\mathbb{R} \longrightarrow [0, 1]\\
&amp;X \longrightarrow p(x_i)
\end{aligned}\]</span></p>
<p><span class="math display">\[p(x_i) = P[X=x_i]=P[x_{i-1}&lt;X \leq x_i] = F(x_i)-F(x_{i-1}).\]</span></p>
<p>Nótese que la expresión anterior demuestra la magnitud de los saltos en las discontinuidades
de la función de distribución de una variable aleatoria discreta. La función de probabilidad
de una variable aleatoria discreta también se puede llamar función de cuantía o
función de masa de probabilidad. Se puede encontrar también la notación abreviada <span class="math inline">\(p_i\)</span>
para referirse a <span class="math inline">\(p(x_i)\)</span>.</p>
<p>Para que una función <span class="math inline">\(p(x_i)\)</span> sea función de probabilidad debe cumplir las siguientes
condiciones:</p>
<ul>
<li>
<span class="math inline">\(p(x_i) \geq 0 \; \forall i\)</span>.</li>
<li>
<span class="math inline">\(\sum\limits_{i=1}^\infty p(x_i) = 1\)</span>.</li>
</ul>
<p>A partir de la función de probabilidad podemos llegar a la función de distribución
de cualquier variable aleatoria discreta como sigue:</p>
<p><span class="math inline">\(F(x_i) = \sum\limits_{j=1}^i p(x_j),\)</span></p>
<p>esto es, <em>acumulando</em> la probabilidad de los valores iguales o inferiores a
cada valor <span class="math inline">\(x_i\)</span>.</p>

<div class="rmdejemplo">
<p>En el experimento descrito anteriormente de lanzar tres monedas, definíamos la
variable aleatoria:</p>
<p><span class="math display">\[X: \text{Número total de caras}.\]</span></p>
<p>La función de probabilidad de esta variable aleatoria la podemos
calcular por la definición de Laplace contando los casos favorables de
<span class="math inline">\(\Omega\)</span> para cada valor de la variable aleatoria <span class="math inline">\(X\)</span>, y sería la siguiente:</p>
<p><span class="math display">\[\begin{aligned}
p: &amp; \quad \mathbb{R} &amp; \longrightarrow &amp; \quad [0,1]\\
&amp; \quad X &amp; \longrightarrow &amp; \quad p(x_i) = P[X = x_i]\\
&amp; \quad 0 &amp; \longrightarrow &amp; \quad P[X = 0] = \frac{1}{8}\\
&amp; \quad 1 &amp; \longrightarrow &amp; \quad P[X = 1] = \frac{3}{8}\\
&amp; \quad 2 &amp; \longrightarrow &amp; \quad P[X = 2] = \frac{3}{8}\\
&amp; \quad 3 &amp; \longrightarrow &amp; \quad P[X = 3] = \frac{1}{8}
\end{aligned}\]</span></p>
<p>La figura <a href="vauni.html#fig:ddiscretam">5.2</a> representa gráficamente la función de
probabilidad<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Normalmente se representan líneas verticales en vez de únicamente el punto para una mejor visualización.&lt;/p&gt;"><sup>61</sup></a>.</p>
<p>A partir de la función de probabilidad, aplicando que <span class="math inline">\(F(x_i) = \sum\limits_{j=1}^i p(x_j)\)</span>, la función de distribución
sería la siguiente:</p>
<p><span class="math display">\[\begin{aligned}
F: &amp; \quad \mathbb{R} &amp; \longrightarrow &amp; \quad [0,1]\\
&amp; \quad X &amp; \longrightarrow &amp; \quad F(x_i) = P[X \leq x_i]\\
&amp; \quad 0 &amp; \longrightarrow &amp; \quad P[X \leq 0] = \frac{1}{8}\\
&amp; \quad 1 &amp; \longrightarrow &amp; \quad P[X \leq 1] = \frac{4}{8}=\frac{1}{2}\\
&amp; \quad 2 &amp; \longrightarrow &amp; \quad P[X \leq 2] = \frac{7}{8}\\
&amp; \quad 3 &amp; \longrightarrow &amp; \quad P[X \leq 3] = \frac{8}{8}=1
\end{aligned}\]</span></p>
<p>La figura <a href="vauni.html#fig:pdiscretam">5.3</a> representa gráficamente la función de distribución, que
se puede expresar de la siguiente forma:</p>
<span class="math display">\[F(x)=
\begin{cases}
0  \quad \;\,\text{si } \quad x &lt; 0\\
\frac{1}{8}  \quad \text{ si } \quad  0\leq x &lt; 1\\
\frac{1}{2}  \quad \text{ si }  \quad 1\leq x &lt; 2\\
\frac{7}{8}  \quad \text{ si }  \quad 2\leq x &lt; 3\\
1  \quad \;\,\text{si }  \quad x \geq 3\\
\end{cases}\]</span>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ddiscretam"></span>
<img src="05-vauni_files/figure-html/ddiscretam-1.png" alt="Representación de la función de probabilidad para el experimento de las monedas" width="70%"><p class="caption">
Figura 5.2: Representación de la función de probabilidad para el experimento de las monedas
</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:pdiscretam"></span>
<img src="05-vauni_files/figure-html/pdiscretam-1.png" alt="Representación de la función de distribución para el ejemplo de las monedas" width="70%"><p class="caption">
Figura 5.3: Representación de la función de distribución para el ejemplo de las monedas
</p>
</div>
<p>Otros ejemplos de variables aleatorias discretas serían aquellos en los
que realizamos recuentos u observamos características, por ejemplo:</p>
<ul>
<li>Número de defectos por m<sup>2</sup> en una superficie.</li>
<li>Indicador de pieza correcta/incorrecta.</li>
<li>Puntuación en una escala de valoración (por ejemplo <em>Likert</em>).</li>
<li>Número de clientes que llegan a un banco cada hora.</li>
<li>Número de unidades defectuosas en un lote de productos.</li>
</ul>
<div class="rmdejemplo">
Vamos a ampliar el ejemplo ilustrativo de los sujetos en estudio
descrito en el capítulo de introducción a la probabilidad. Supongamos que se envía a los
sujetos una serie de mensajes de seguimiento por correo electrónico de forma
<em>aleatoria</em>, y que el número de mensajes recibidas por un cliente puede ser 20, 36, o 60,
con probabilidades <span class="math inline">\(\frac{36}{52}\)</span>, <span class="math inline">\(\frac{12}{52}\)</span> y <span class="math inline">\(\frac{4}{52}\)</span> respectivamente.
Podemos así definir la variable aleatoria <span class="math inline">\(X:\)</span> <em>Número de mensajes remitidos por correo electrónico en un año a los sujetos en estudio</em>, cuyo campo de variación es <span class="math inline">\(\{20, 36, 60\}\)</span> y cuyas funciones de probabilidad y distribución se representan respectivamente en las figuras <a href="vauni.html#fig:ddiscreta">5.4</a> y <a href="vauni.html#fig:pdiscreta">5.5</a>. La tabla <a href="vauni.html#tab:ejdiscretat">5.1</a> muestra ambas funciones numéricamente.
</div>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:ejdiscretat">Tabla 5.1: </span>Funciones de probabilidad y distribución para la variable discreta del ejemplo ilustrativo</caption>
<thead><tr class="header">
<th align="right"><span class="math inline">\(x_i\)</span></th>
<th align="right"><span class="math inline">\(p(x_i)\)</span></th>
<th align="right"><span class="math inline">\(F(x_i)\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">20</td>
<td align="right">0,6923</td>
<td align="right">0,6923</td>
</tr>
<tr class="even">
<td align="right">36</td>
<td align="right">0,2308</td>
<td align="right">0,9231</td>
</tr>
<tr class="odd">
<td align="right">60</td>
<td align="right">0,0769</td>
<td align="right">1,0000</td>
</tr>
</tbody>
</table></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ddiscreta"></span>
<img src="05-vauni_files/figure-html/ddiscreta-1.png" alt="Representación de la función de probabilidad de una variable aleatoria discreta" width="70%"><p class="caption">
Figura 5.4: Representación de la función de probabilidad de una variable aleatoria discreta
</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:pdiscreta"></span>
<img src="05-vauni_files/figure-html/pdiscreta-1.png" alt="Representación de la función de distribución de la variable aleatoria discreta del ejemplo ilustrativo" width="70%"><p class="caption">
Figura 5.5: Representación de la función de distribución de la variable aleatoria discreta del ejemplo ilustrativo
</p>
</div>
</div>
</div>
<div id="variable-aleatoria-continua" class="section level2" number="5.4">
<h2>
<span class="header-section-number">5.4</span> Variable aleatoria continua<a class="anchor" aria-label="anchor" href="#variable-aleatoria-continua"><i class="fas fa-link"></i></a>
</h2>
<p>Son variables aleatorias continuas aquellas que pueden tomar un
<strong>número infinito no numerable de valores</strong>.
Formalmente, son aquellas cuya función de distribución, <span class="math inline">\(F(x)\)</span>, es continua y
derivable en todo su dominio. Al ser la variable continua, puede tomar
cualquier valor en un intervalo de su dominio. Podemos utilizar las propiedades
de la función de distribución para calcular probabilidades en cualquier intervalo
de la siguiente forma:</p>
<p><span class="math display" id="eq:Fcont">\[\begin{equation}
  P[a&lt;X\leq b]=F(b)-F(a).
  \tag{5.1}
\end{equation}\]</span></p>
<p>Ahora bien, por ser <span class="math inline">\(F\)</span> continua, entre <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> siempre hay masa de probabilidad, y no podemos obtener
una función de probabilidad como en el caso discreto. Esto es porque no existe un valor
anterior a uno dado <span class="math inline">\(x\)</span>. Podemos <em>acercar</em>
los dos extremos del intervalo tanto como queramos, por ejemplo en la ecuación <a href="vauni.html#eq:Fcont">(5.1)</a> para calcular <span class="math inline">\(P[X=b]\)</span> podríamos buscar el valor anterior a <span class="math inline">\(b\)</span> aproximando <span class="math inline">\(a\)</span> a <span class="math inline">\(b\)</span>, pero
siempre habría un valor más allá, y finalmente la
<strong>probabilidad para un valor concreto de la variable aleatoria es igual a cero</strong>.</p>
<p><span class="math display">\[\boxed{P[X=x]=0}\; \forall x \in \mathbb{R}.\]</span></p>

<div class="rmdcafe">
Intuitivamente, podemos entender esta característica pensando en la definición de probabilidad
de Laplace. Si tuviéramos que <em>contar</em> el número de casos favorables para que la
variable aleatoria tome un valor concreto, sería 1. Pero los casos posibles, por
ser variable continua, son infinitos, y por tanto la probabilidad
sería <span class="math inline">\(\frac{1}{\infty}\)</span>.
</div>
<p>Es importante señalar que, en la práctica, el número de valores de una variable
aleatoria que podamos <em>medir</em> será finito, pero la variable aleatoria seguirá siendo
continua conceptualmente, y la aplicación de sus propiedades nos permitirá resolver
aquellos problemas prácticos, aunque el aparato de medida utilizado no
nos permita ir más allá de cierta precisión.</p>
<div class="rmdcafe">
<p>
Piensa en tu marca de cerveza favorita (o cualquier otra bebida), por
ejemplo en el formato de 33 cl (tercio). Cuando la pides en un bar,
¿cuál crees que es la probabilidad de que la botella tenga
<strong>exactamente</strong> 33 cl?
</p>
<p>
En realidad, si medimos con una precisión, por ejemplo, de un
decimal, podemos obtener mediciones de <span class="math inline"><span class="math inline">\(33.0\)</span></span> <em>cl</em>. Pero las mediciones
están sujetas a un error, y en realidad lo que nos está diciendo esa
medición es que el volumen está entre <span class="math inline"><span class="math inline">\(32.95\)</span></span> y <span class="math inline"><span class="math inline">\(33.05\)</span></span>, intervalo del cual sí podemos
calcular su probabilidad.
</p>
</div>
<p>Entonces nos surge la siguiente pregunta: si no podemos calcular la probabilidad
de los <em>sucesos</em> individuales, ¿cómo saber qué valores son más probables?
¿dónde se concentra la probabilidad? Precisamente la continuidad de la
función de distribución nos proporciona la herramienta matemática para resolver
estas cuestiones. La figura <a href="vauni.html#fig:fdistcambio">5.6</a>
muestra la representación gráfica de la función de densidad <span class="math inline">\(F(x)\)</span> de una determinada
variable aleatoria <span class="math inline">\(X\)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fdistcambio"></span>
<img src="05-vauni_files/figure-html/fdistcambio-1.png" alt="Función de distribución de una variable continua y probabilidad de un intervalo" width="70%"><p class="caption">
Figura 5.6: Función de distribución de una variable continua y probabilidad de un intervalo
</p>
</div>
<p>Como podemos ver, la probabilidad en un intervalo cualquiera,
es el <strong>cambio</strong> que se produce en la función de distribución entre los
extremos del intervalo. Si acercamos los extremos del intervalo, es decir, hacemos que
<span class="math inline">\(b\)</span> <em>tienda</em> a <span class="math inline">\(a\)</span>, obtenemos la tasa <strong>instantánea</strong> de cambio en un
punto, que representa la masa de probabilidad en ese punto, y que es la derivada
de la función de distribución en ese punto:</p>
<p><span class="math display">\[\lim\limits_{b \to a}\frac{F(b)- F(a)}{b-a}.\]</span></p>

<div class="rmdcafe">
La derivada de una función en un punto se corresponde con la pendiente de la recta tangente
a la función en ese punto. En nuestro caso, la pendiente de la recta tangente a la
función de distribución es la que nos proporciona la “densidad” de probabilidad.
Se muestra a continuación una aplicación interactiva para visualizar el concepto
de derivada como pendiente de la recta tangente<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;accesible también en &lt;a href="https://elcano.shinyapps.io/derivada/" class="uri"&gt;https://elcano.shinyapps.io/derivada/&lt;/a&gt;&lt;/p&gt;'><sup>62</sup></a>, que se puede aplicar a cualquier función de
distribución.
</div>
<iframe src="https://elcano.shinyapps.io/derivada/?showcase=0" width="100%" height="800px" data-external="1">
</iframe>
<div id="función-de-densidad" class="section level3" number="5.4.1">
<h3>
<span class="header-section-number">5.4.1</span> Función de densidad<a class="anchor" aria-label="anchor" href="#funci%C3%B3n-de-densidad"><i class="fas fa-link"></i></a>
</h3>
<p>Si pensamos en la probabilidad como la tasa de cambio en la función de distribución, entonces podemos definir la densidad de probabilidad como la derivada de la función de distribución, y calcular así probabilidades con esa función, llamada <strong>función de densidad</strong> que se
representa por <span class="math inline">\(f(x)\)</span>:</p>
<p><span class="math display">\[f(x)= \frac{d F(x)}{dx}.\]</span></p>
<p>Además, por el teorema fundamental del cálculo, podemos obtener la función de distribución a
partir de la función de densidad mediante la integral:</p>
<p><span class="math display">\[F(x)=\int_{-\infty}^x f(t) dt =P[X\leq x].\]</span>
La figura <a href="vauni.html#fig:dp">5.7</a> representa la relación entre la función de densidad y
la función de distribución. Como se puede apreciar, el área debajo de la curva
de la función de densidad <span class="math inline">\(f(t)\)</span> se corresponde con las distintas probabilidades
de que la variable aleatoria tome valores en los intervalos que encierran dicha
área.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:dp"></span>
<img src="05-vauni_files/figure-html/dp-1.png" alt="Relación entre las funciones de densidad y de probabilidad" width="70%"><p class="caption">
Figura 5.7: Relación entre las funciones de densidad y de probabilidad
</p>
</div>
<p>Para que una función <span class="math inline">\(f(x)\)</span> sea función de densidad, tiene
que cumplir las siguientes condiciones:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(f(x)\geq 0\)</span>.</p></li>
<li><p><span class="math inline">\(\int_{-\infty}^\infty f(x)dx = 1\)</span>.</p></li>
</ol>
<p>La primera condición impone la condición evidente de que la masa de probabilidad
sea positiva. La segunda condición la impone el segundo axioma de la probabilidad
y las propiedades de la función de distribución, ya que:</p>
<p><span class="math display">\[\int_{-\infty}^\infty f(x)dx = F(\infty)=P[X\leq \infty] = P(\Omega)=1.\]</span>
Esto implica que cualquier función <span class="math inline">\(g(x)\)</span> definida positiva en un determinado intervalo, se
puede convertir en una función de densidad multiplicándola por una constante
<span class="math inline">\(k\)</span> calculada como:</p>
<p><span class="math display">\[k=\frac{1}{\int_{-\infty}^\infty g(x)dx}.\]</span></p>

<div class="rmdejemplo">
<p>Supóngase que la empresa de servicios de nuestro ejemplo quiere hacer una campaña para aplicar entre un 5% y un 25% de descuento a sus clientes de forma aleatoria y lineal de forma que haya más descuentos bajos que altos. Entonces la función de densidad para la variable aleatoria <span class="math inline">\(X=\)</span> <em>Descuento aplicado a un cliente</em> se puede modelizar mediante una recta con esta forma:</p>
<p><span class="math display">\[
f(x) =
\begin{cases}
k(25-x) &amp; \text{si } 5 \leq x \leq 25\\
0 &amp; \text{resto}
\end{cases}
\]</span></p>
<p>que, para que sea función de densidad, debe cumplir que:</p>
<p><span class="math display">\[\int_{-\infty}^\infty f(x) dx=1,\]</span></p>
<p>y por tanto:
<span class="math display">\[k=\frac{1}{\int_{5}^{25} (25-x) dx} = 0.005.\]</span></p>
<p>La figura <a href="vauni.html#fig:ejcontdesc">5.8</a> representa esta función de densidad.</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ejcontdesc"></span>
<img src="05-vauni_files/figure-html/ejcontdesc-1.png" alt="Función de densidad del ejemplo de los descuentos" width="70%"><p class="caption">
Figura 5.8: Función de densidad del ejemplo de los descuentos
</p>
</div>

<div class="rmdpractica">
<p>Aunque las integrales que se presentan en este texto son inmediatas, en la práctica
el uso del software para resolverlas es más rápido y productivo. Se aconseja al lector
realizar las comprobaciones por sí mismo.</p>
<p><strong>MAXIMA</strong></p>
<p>Maxima resuelve integrales de forma simbólica. En el caso de una integral definida
obtenemos directamente el área bajo la curva de una función. En el ejemplo:</p>
<p><code>1 / integrate(25-x, x, 5, 25);</code></p>
<p><strong>R</strong></p>
<p>R puede calcular integrales definidas metiante métodos numéricos. El código a continuación
muestra la expresión para calcular la integral buscada y el valor de <span class="math inline">\(k\)</span>.</p>
</div>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">integral</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span>f <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span> <span class="fl">25</span> <span class="op">-</span> <span class="va">x</span> <span class="op">}</span>, </span>
<span>                      lower <span class="op">=</span> <span class="fl">5</span>, </span>
<span>                      upper <span class="op">=</span> <span class="fl">25</span><span class="op">)</span></span>
<span><span class="va">integral</span></span>
<span><span class="co">#&gt; 200 with absolute error &lt; 2.2e-12</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">/</span><span class="va">integral</span><span class="op">$</span><span class="va">value</span></span>
<span><span class="va">k</span></span>
<span><span class="co">#&gt; [1] 0.005</span></span></code></pre></div>

<div class="rmdejemplo">
<p>Sea la variable aleatoria <span class="math inline">\(X\)</span> con función de densidad:</p>
<p><span class="math display">\[f(x)=
\begin{cases}
\frac{1}{8}x \quad \text{si} \quad 0&lt;x&lt;4\\
0 \quad \quad \text{resto}
\end{cases}\]</span></p>
<p>Comprobar que es función de densidad, y obtener la función de distribución.</p>
<p>Para comprobar si es función de densidad, verificamos las dos condiciones:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(f(x)\geq 0\)</span> según está definida (véase la figura <a href="vauni.html#fig:ejfdensidad">5.9</a>)</p></li>
<li><p>Integral en todo <span class="math inline">\(\mathbb{R}\)</span>:</p></li>
</ol>
<p><span class="math display">\[\int_{-\infty}^\infty f(x)dx = \int_{0}^4 \frac{1}{8}x dx = \left [ \frac{x^2}{16} \right]_{0}^4=1.\]</span></p>
<p>Para calcular la función de distribución, tenemos en cuenta que:</p>
<p><span class="math display">\[F(x)=\int_{-\infty}^x f(t) dt =P[X\leq x].\]</span></p>
<p>Como lo que queremos obtener es una <strong>función</strong>, y no un número, el límite
superior de la integral definida es variable (x). la función <span class="math inline">\(f\)</span> la ponemos
en función de <span class="math inline">\(t\)</span> simplemente para no utilizar el mismo símbolo <span class="math inline">\(x\)</span> y evitar
confusiones.</p>
<p>Si tenemos una función de densidad definida por trozos, tendremos que ir <em>acumulando trozos</em>.
Recorremos de menor a mayor los intervalos de <span class="math inline">\(\mathbb{R}\)</span> realizando la integral
definida completa para los intervalos anteriores al que
estamos considerando. Entonces, para nuestra función:</p>
<ul>
<li>Si <span class="math inline">\(x\leq 0\)</span>:</li>
</ul>
<p><span class="math display">\[F(x)=\int_{-\infty}^x 0 dt =0.\]</span></p>
<ul>
<li>
<p>Si <span class="math inline">\(0 &lt;x &lt; 4\)</span>:</p>
<p><span class="math display">\[F(x)=\int_{-\infty}^0 0 dt + \int_{0}^x \frac{1}{8}t dt = \left [ \frac{t^2}{16} \right]_{0}^x = \frac{x^2}{16}.\]</span></p>
</li>
<li><p>Si <span class="math inline">\(x&gt;4\)</span>:</p></li>
</ul>
<p><span class="math display">\[F(x)=\int_{-\infty}^0 0 dt + \int_{0}^4 \frac{1}{8}t dt + \int_{4}^x 0 dt= \left [ \frac{t^2}{16} \right]_{0}^4 = 1.\]</span></p>
<p>Expresamos por tanto la función de distribución, cuya representación aparece en la figura <a href="vauni.html#fig:ejfdistrib">5.10</a>, de la siguiente forma para todos sus intervalos:</p>
<span class="math display">\[
F(x)=
\begin{cases}
0 \;\; \quad \text{si} \quad x \leq 0\\
\frac{x^2}{16} \quad \text{si} \quad 0 &lt;x &lt;4\\
1 \;\; \quad \text{si} \quad x \geq 4\\
\end{cases}
\]</span>
</div>

<div class="rmdpractica">
<p><strong>MAXIMA</strong></p>
<p>La integral definida para comprobar que vale uno sería:</p>
<p><code>integrate((1/8)*x, x, 0, 4);</code></p>
<p>Podríamos obtener la expresión de la función de distribución en el intervalo en que está definida
con la siguiente expresión:</p>
<p><code>integrate((1/8)*t, t, 0, x);</code></p>
<p><strong>R</strong></p>
<p>El código a continuación realiza la comprobación de que la integral vale 1. R no puede
hacer cálculo simbólico para obtener una expresión de la función de distribución. No obstante,
se puede crear una función que obtenga valores de la función de distribución para utilizar
posteriormente, o representarla gráficamente.</p>
</div>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span>f <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span> <span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">8</span><span class="op">)</span><span class="op">*</span><span class="va">x</span> <span class="op">}</span>, </span>
<span>                      lower <span class="op">=</span> <span class="fl">0</span>, </span>
<span>                      upper <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="co">#&gt; 1 with absolute error &lt; 1.1e-14</span></span>
<span><span class="va">Fx</span> <span class="op">&lt;-</span>  <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span>f <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">t</span><span class="op">)</span> <span class="op">{</span> <span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">8</span><span class="op">)</span><span class="op">*</span><span class="va">t</span> <span class="op">}</span>, </span>
<span>                      lower <span class="op">=</span> <span class="fl">0</span>, </span>
<span>                      upper <span class="op">=</span> <span class="va">x</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu">Fx</span><span class="op">(</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; 0.25 with absolute error &lt; 2.8e-15</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ejfdensidad"></span>
<img src="05-vauni_files/figure-html/ejfdensidad-1.png" alt="Representación de la función de densidad del ejemplo" width="70%"><p class="caption">
Figura 5.9: Representación de la función de densidad del ejemplo
</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ejfdistrib"></span>
<img src="05-vauni_files/figure-html/ejfdistrib-1.png" alt="Representación de la función de distribución del ejemplo" width="70%"><p class="caption">
Figura 5.10: Representación de la función de distribución del ejemplo
</p>
</div>
<hr>
<p>Nótese que la función de densidad <strong>no es una probabilidad</strong>, y, por tanto,
podría tomar valores mayores que 1. Por otra parte, la función de densidad
puede ser discontinua.</p>
<p>Es fácil comprobar que:</p>
<p><span class="math display">\[P[a&lt;X\leq b]=\int_a^b f(x)dx.\]</span></p>
<p>Lo que nos proporciona una forma de calcular probabilidades de una variable
aleatoria continua mediante la función de densidad (aunque no conozcamos la
función de distribución). Las probabilidades son, por lo tanto, equivalentes
al <strong>área bajo la curva</strong> de la función de densidad, que, esta vez
sí, tiene que ser menor o igual que 1. Utilizando las propiedades
de la probabilidad, podemos calcular probabilidades de cualquier intervalo
utilizando tanto la función de densidad como la función de distribución, tal
y como se resume en la figura <a href="vauni.html#fig:cprocont">5.11</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:cprocont"></span>
<img src="05-vauni_files/figure-html/cprocont-1.png" alt="Cálculo de probabilidades de una variable continua" width="672"><p class="caption">
Figura 5.11: Cálculo de probabilidades de una variable continua
</p>
</div>
<p>Para mejorar la comprensión de la función de densidad, cuya importancia
es vital en el cálculo de probabilidades, vamos a relacionarla con otros conceptos
ya conocidos por el lector. En primer lugar, en el tránsito de variables discretas
a continuas, hemos pasado del sencillo cálculo del sumatorio <span class="math inline">\((\sum)\)</span> al
intimidante cálculo con integrales <span class="math inline">\((\int)\)</span>. Sin embargo, una integral es
en realidad una <em>suma infinita</em> de áreas bajo la curva cuando tomamos intervalos
cada vez más pequeños.
En segundo lugar, recordemos la definición de
probabilidad como <strong>frecuencia relativa</strong> en el límite. Entonces decíamos,
que si pudiéramos repetir un experimento un número grande de veces,
la frecuencia relativa de ocurrencia de un suceso tendía a la probabilidad de
ese suceso. En el marco de las variables aleatorias, tendríamos un número
grande de realizaciones de la variable aleatoria, es decir, de números reales.
Como sabemos por la estadística descriptiva, estos valores los podemos
agrupar en intervalos y contar las frecuencias de los valores dentro de cada
intervalo, representándolos en un <strong>histograma</strong>. Pues bien, si tenemos
muchos números, y hacemos la amplitud
de los intervalos muy pequeños, entonces el histograma de los datos
se parece cada vez más a la función de densidad de la variable aleatoria
que describe el experimento<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Se parecerá más cuantos más datos tengamos, pero téngase en cuenta que la forma del histograma, con datos empíricos, será &lt;em&gt;aproximada&lt;/em&gt; (nunca exacta) a la forma de la función, &lt;em&gt;teórica&lt;/em&gt;.&lt;/p&gt;"><sup>63</sup></a>, recuérdese la Figura <a href="vauni.html#fig:dogma2b">5.1</a>. Además, el área de las barras del histograma
representa también las probabilidades de los intervalos que podamos formar.
La figura <a href="vauni.html#fig:densidadfreq">5.12</a> muestra esta relación entre frecuencias
y función de densidad en un determinado experimento.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:densidadfreq"></span>
<img src="05-vauni_files/figure-html/densidadfreq-1.png" alt="Frecuencias, histograma y función de densidad" width="70%"><p class="caption">
Figura 5.12: Frecuencias, histograma y función de densidad
</p>
</div>
<p>Una última consideración en cuanto a las variables aleatorias continuas es
la irrelevancia práctica de incluir o no el símbolo igual en las desigualdades.
Si bien en las variables aleatorias discretas sí habrá una diferencia numérica
que puede ser importante en aplicaciones prácticas, en las variables aleatorias
continuas la utilización del símbolo <span class="math inline">\(\leq\)</span> o el símbolo <span class="math inline">\(&lt;\)</span>, o sus contrarios
<span class="math inline">\(\geq\)</span> y <span class="math inline">\(&gt;\)</span> es irrelevante para el cálculo. Efectivamente, como la probabilidad en un punto, <span class="math inline">\(P[X=x]=0\)</span>,
entonces se cumple para variables continuas que:</p>
<p><span class="math display">\[P[X\leq x] = P[X&lt;x]; \quad P[X\geq x] = P[X&gt;x].\]</span></p>
<p>Pero mucho cuidado porque esto <strong>no pasa con las variables aleatorias discretas</strong>.
Además, siempre es preferible utilizar los símbolos de forma adecuada aunque
no tenga consecuencias prácticas.</p>

<div class="rmdejemplo">
<p>Sea la variable aleatoria del ejemplo anterior, con las siguientes
funciones de densidad y de distribución:</p>
<p><span class="math display">\[f(x)=
\begin{cases}
\frac{1}{8}x \quad \text{si} \quad 0&lt;x&lt;4\\
0 \quad \quad \text{resto}
\end{cases}\;;
F(x)=
\begin{cases}
0 \;\; \quad \text{si} \quad x \leq 0\\
\frac{x^2}{16} \quad \text{si} \quad 0 &lt;x &lt;4\\
1 \;\; \quad \text{si} \quad x \geq 4\\
\end{cases}
\]</span></p>
<p>Calcular:</p>
<p><span class="math display">\[P[1&lt;X&lt;2].\]</span></p>
<p>Lo podemos hacer a través de la función de densidad:</p>
<p><span class="math display">\[P[1&lt;X&lt;2]=\int_{1}^2 f(x)dx = \int_{1}^2 \frac{1}{8}x dx = \left [ \frac{x^2}{16} \right]_{1}^2=\frac{2}{8}-\frac{1}{16} = \frac{3}{16},\]</span></p>
<p>y también a través de la función de distribución:</p>
<span class="math display">\[P[1&lt;X&lt;2]=F(2)-F(1)=\frac{4}{16}-\frac{1}{16} = \frac{3}{16}.\]</span>
</div>

<div class="rmdpractica">
<p><strong>MAXIMA</strong></p>
<p>La probabilidad pedida se calcularía simplemente:</p>
<p><code>integrate((1/8)*x, x, 1, 2);</code></p>
<p><strong>R</strong></p>
<p>El código a continuación calcula la probabilidad pedida.</p>
</div>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span>f <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span> <span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">8</span><span class="op">)</span><span class="op">*</span><span class="va">x</span> <span class="op">}</span>, </span>
<span>                      lower <span class="op">=</span> <span class="fl">1</span>, </span>
<span>                      upper <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; 0.1875 with absolute error &lt; 2.1e-15</span></span></code></pre></div>

<div class="rmdejemplo">
<p>El tiempo de duración (en minutos) de la visita de un potencial usuario de un servicio tras seguir el link de una oferta es una variable aleatoria <span class="math inline">\(X\)</span> que sigue una distribución de probabilidad según la siguiente función de densidad:</p>
<p><span class="math display">\[f(x) =
\begin{cases}
2e^{-2x} &amp; \text{si } x &gt; 0\\
0 &amp; \text{si } x\leq 0
\end{cases}\]</span></p>
<p>La representación gráfica de esta función aparece en la figura <a href="vauni.html#fig:densejilu">5.13</a>.
Podemos comprobar que es una función de densidad verificando que cumple los dos
requisitos. Es una función exponencial multiplicada por un número positivo, por
tanto es siempre positiva. Comprobemos el área debajo de la curva para todo su
dominio:</p>
<p><span class="math display">\[\int_{-\infty}^\infty f(x) dx = 1 \iff \int_0^\infty 2e^{-2x} dx=\left[-e^{-2x}\right ]_0^\infty=1\]</span></p>
<p>La función de distribución de esta variable aleatoria será:</p>
<p><span class="math display">\[F(x) = \int_{-\infty}^x f(x) dx = \int_0^x 2e^{-2t} dt=\left[-e^{-2t}\right ]_0^x=1-e^{-2x},\]</span></p>
<p>y su representación gráfica es la que se muestra en la figura <a href="vauni.html#fig:distejilu">5.14</a>.</p>
<p>¿Qué porcentaje de visitantes abandonarán probablemente la página antes de 10 segundos?
(nótese que 10 segundos = 10/60 minutos).</p>
<p>Dado que tenemos la función de distribución,
es más sencillo obtenerlo a través de esta que resolviendo la integral:</p>
<p><span class="math display">\[P[X&lt;10/60] = F(10/60) = 1-e^{-2\cdot 10/60}= 0.2835.\]</span></p>
<p>Como la pregunta se hace en términos de porcentaje, la respuesta sería
aproximadamente un 28.35% de los visitantes.</p>
</div>

<div class="rmdpractica">
<p><strong>MAXIMA</strong></p>
<p>Las siguientes expresiones obtienen en Maxima los resultados del ejemplo.</p>
<p><code>integrate(2*exp(-2*x), x, 0, inf);</code></p>
<p><code>integrate(2*exp(-2*t),t, 0, x);</code></p>
<p><code>integrate(2*exp(-2*x), x, 0, 10/60);</code></p>
<p><strong>R</strong></p>
<p>En el siguiente código de R se realizan los cálculos explicados en el ejemplo.</p>
</div>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="va">x</span><span class="op">)</span>, <span class="fl">0</span>, <span class="cn">Inf</span><span class="op">)</span></span>
<span><span class="co">#&gt; 1 with absolute error &lt; 5e-07</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="va">x</span><span class="op">)</span>, <span class="fl">0</span>, <span class="fl">10</span><span class="op">/</span><span class="fl">60</span><span class="op">)</span></span>
<span><span class="co">#&gt; 0.2834687 with absolute error &lt; 3.1e-15</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:densejilu"></span>
<img src="05-vauni_files/figure-html/densejilu-1.png" alt="Representación de la función de densidad del ejemplo ilustrativo" width="70%"><p class="caption">
Figura 5.13: Representación de la función de densidad del ejemplo ilustrativo
</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:distejilu"></span>
<img src="05-vauni_files/figure-html/distejilu-1.png" alt="Representación de la función de distribución del ejemplo ilustrativo" width="70%"><p class="caption">
Figura 5.14: Representación de la función de distribución del ejemplo ilustrativo
</p>
</div>
</div>
</div>
<div id="características-de-una-variable-aleatoria" class="section level2" number="5.5">
<h2>
<span class="header-section-number">5.5</span> Características de una variable aleatoria<a class="anchor" aria-label="anchor" href="#caracter%C3%ADsticas-de-una-variable-aleatoria"><i class="fas fa-link"></i></a>
</h2>
<p>Al igual que con los datos concretos de una muestra podemos calcular estadísticos que resumen la información, las variables
aleatorias constan de <strong>parámetros</strong> de centralización, posición y forma que caracterizan la variable aleatoria a través de su distribución de probabilidad.
A través de los posibles valores de una variable aleatoria y sus probabilidades podemos
definir estas características. Las más importantes son la esperanza (media) y la varianza.
Una vez más, téngase en cuenta que estos parámetros de la variable aleatoria
son <strong>valores teóricos de la variable aleatoria</strong>, generalmente referidas a una
población de la cual tenemos sólo información parcial a través de una muestra (recuérdese la figura <a href="vauni.html#fig:dogma2b">5.1</a>).</p>
<div id="esperanza-matemática" class="section level3" number="5.5.1">
<h3>
<span class="header-section-number">5.5.1</span> Esperanza Matemática<a class="anchor" aria-label="anchor" href="#esperanza-matem%C3%A1tica"><i class="fas fa-link"></i></a>
</h3>
<p>La Esperanza matemática se define sobre una función <span class="math inline">\(g(x)\)</span> de una variable aleatoria <span class="math inline">\(X\)</span> como:</p>
<p><span class="math display">\[E[g(X)]=\int_{\mathbb {R}} g(x) dF(x),\]</span></p>
<p>que en el caso discreto resulta en:</p>
<p><span class="math display">\[E[g(X)]=\sum\limits_i g(x_i)\cdot p(x_i),\]</span></p>
<p>y en el caso continuo:</p>
<p><span class="math display">\[E[g(x)] = \int_{-\infty}^\infty g(x) \cdot f(x)dx.\]</span></p>
<p>Así, la esperanza va a ser un número, ya sea calculado como suma de términos
en el caso discreto, o como suma infinita a través de la integral definida.
El uso de integrales no debe intimidar, ya que no se trata más que de áreas debajo
de una curva, cuyo cálculo con el software apropiado es muy sencillo.
Se puede ver como la suma de los valores de la variable aleatoria (o una función
de ella) multiplicado por sus probabilidades. El resultado va a ser el <em>valor esperado</em>,
que se corresponde con la media de la distribución, su valor central.</p>
<div class="rmdcafe">
<p>
El uso de la palabra esperanza en este ámbito tiene su origen, cómo
no, en los juegos de azar. Así, se hablaba de la esperanza de ganar en
el juego (y la ganancia que se esperaba tener era el resultado), y
también del <em>temor</em>, cuando la esperanza era negativa.
</p>
</div>
<p>La esperanza se define como hemos visto sobre una función cualquiera de la variable
aleatoria <span class="math inline">\(g(x)\)</span>. Si <span class="math inline">\(g(x)=x\)</span>, entonces tendremos la
esperanza de la propia variable aleatoria. Se cumplen las
siguientes propiedades para la esperanza matemática:</p>
<ul>
<li>La esperanza de una constante es esa misma constante:</li>
</ul>
<p><span class="math display">\[c \;\;\text{constante} \implies E[c] = c.\]</span></p>
<ul>
<li>Sea una variable aleatoria que es suma de <span class="math inline">\(n\)</span> variables aleatorias. Entonces su esperanza es la suma de las esperanzas de dichas variables aleatorias:</li>
</ul>
<p><span class="math display">\[E\left [ \sum\limits_{i=1}^n X_i\right ] = \sum\limits_{i=1}^n E[X_i].\]</span></p>
<ul>
<li>Sea una variable aleatoria que es producto de <span class="math inline">\(n\)</span> variables aleatorias. Entonces su esperanza es el producto de las esperanzas de dichas variables aleatorias si y solo si dichas variables aleatorias son independientes:</li>
</ul>
<p><span class="math display">\[E\left [ \prod\limits_{i=1}^n X_i\right ] = \prod\limits_{i=1}^n E[X_i] \iff X_i \;\; \text{independientes}.\]</span></p>
<ul>
<li>La esperanza de una variable aleatoria es su valor central:</li>
</ul>
<p><span class="math display">\[E[X] = \mu \implies E[X-\mu]=0.\]</span></p>
<p>A la variable aleatoria transformada <span class="math inline">\(X-\mu\)</span> se le denomina <strong>variable aleatoria centrada</strong>, y su media es cero.</p>
<ul>
<li>Sea una variable aleatoria que es una transformación lineal de otra variable aleatoria. Entonces su esperanza es la misma transformación lineal de la esperanza de la variable original:</li>
</ul>
<p><span class="math display" id="eq:tlesp">\[\begin{equation}
a, b \;\;\text{constantes} \implies E[a + bX] = a + bE[X].
\tag{5.2}
\end{equation}\]</span></p>
<ul>
<li>Si la integral no existe, la variable aleatoria no tiene esperanza.
Esto puede pasar cuando no existe la integral que la define<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;En el caso de variables discretas, cuando la suma no converge.&lt;/p&gt;"><sup>64</sup></a>.</li>
</ul>
</div>
<div id="momentos-de-variables-aleatorias-unidimensionales" class="section level3" number="5.5.2">
<h3>
<span class="header-section-number">5.5.2</span> Momentos de variables aleatorias unidimensionales<a class="anchor" aria-label="anchor" href="#momentos-de-variables-aleatorias-unidimensionales"><i class="fas fa-link"></i></a>
</h3>
<p>Hemos visto que la esperanza se define sobre una determinada función <span class="math inline">\(g(x)\)</span> de la variable aleatoria.
Los momentos se definen sobre unas funciones muy específicas y que nos van a permitir
caracterizar a las variables aleatorias.
Se define el momento de orden <span class="math inline">\(r\)</span> respecto al origen de una variable aleatoria <span class="math inline">\(X\)</span>, <span class="math inline">\(\alpha_r\)</span>, como:</p>
<p><span class="math display">\[\alpha_r = E[X^r].\]</span></p>
<p>El momento de orden 1 respecto del origen es la media de la variable aleatoria, <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[\alpha_1=\boxed{E[X]=\mu}.\]</span></p>
<p>El momento de orden <span class="math inline">\(r\)</span> respecto de la media <span class="math inline">\(\mu\)</span> de una variable aleatoria, <span class="math inline">\(\mu_r\)</span> se define como:</p>
<p><span class="math display">\[\mu_r = E\left [(X - \mu)^r\right ].\]</span>
Nótese que, en realidad, <span class="math inline">\(X-\mu\)</span> es una <strong>variable aleatoria centrada</strong> cuya esperanza
es igual a cero por las propiedades de la esperanza enumeradas anteriormente, y por tanto:</p>
<p><span class="math display">\[X-\mu \implies \mu_1=E\left [X - \mu\right ] = 0.\]</span></p>
<p>En el caso discreto, estos momentos se calcularán respectivamente como:</p>
<p><span class="math display">\[\alpha_r = \sum\limits_{i} x_i^r p(x_i),\]</span></p>
<p>y</p>
<p><span class="math display">\[\mu_r = \sum\limits_{i} (x_i- \mu)^r p(x_i).\]</span></p>
<p>En el caso continuo, se calcularán respectivamente como:</p>
<p><span class="math display">\[\alpha_r = \int_{-\infty}^\infty x^r f(x) dx,\]</span></p>
<p>y</p>
<p><span class="math display">\[\mu_r = \int_{-\infty}^\infty (x-\mu)^r f(x) dx.\]</span></p>
<p>Se verifica la siguiente relación entre los momentos respecto del origen y los momentos
respecto de la media que nos ayudarán, como veremos posteriormente, a simplificar
los cálculos:</p>
<p><span class="math display" id="eq:momentos">\[\begin{equation}
\mu_r = \alpha_r - \binom{r}{1}\alpha_1 \alpha_{r-1} + \binom{r}{2}\alpha_1^2 \alpha_{r-2} + \cdots + (-1)^r\alpha_1^r = \\
=\sum\limits_{k=0}^r (-1)^k\binom{r}{k}\mu^k \alpha_{r-k}.
\tag{5.3}
\end{equation}\]</span></p>
<p>También se verifica que:</p>
<ul>
<li>Si existe <span class="math inline">\(\alpha_r\)</span>, entonces existen también todos los <span class="math inline">\(\alpha_s\)</span> tales que <span class="math inline">\(s&lt;r\)</span>.</li>
<li>Si existe <span class="math inline">\(\mu_r\)</span>, entonces existen también todos los <span class="math inline">\(\mu_s\)</span> tales que <span class="math inline">\(s&lt;r\)</span>.</li>
</ul>
<p>En resumen, podemos calcular momentos respecto de la media (que requieren cálculos más costosos) a través de momentos respecto del origen (cuyos cálculos son más sencillos).
Y si existe un momento, todos los de orden inferior también existen.</p>
</div>
<div id="medidas-de-centralización-de-una-variable-aleatoria" class="section level3" number="5.5.3">
<h3>
<span class="header-section-number">5.5.3</span> Medidas de centralización de una variable aleatoria<a class="anchor" aria-label="anchor" href="#medidas-de-centralizaci%C3%B3n-de-una-variable-aleatoria"><i class="fas fa-link"></i></a>
</h3>
<p>Ya hemos visto que la esperanza matemática de una variable aleatoria se corresponde con su valor central, al que denominaremos <strong>media</strong>, y es el parámetro de centralización de la variable aleatoria.
Es importante no confundir este valor medio o esperado de la variable aleatoria, que es teórico, referido a una población, con la media de unos datos concretos, que es empírica, calculada para una muestra.</p>
<p><span class="math display">\[\mu = \alpha_1= E[X],\]</span></p>
<p>cuyo cálculo para variables discretas es el siguiente:</p>
<p><span class="math display">\[\mu = \boxed{E[X] =  \sum\limits_{i} x_i p(x_i)},\]</span></p>
<p>y para variables continuas:</p>
<p><span class="math display">\[\mu = \boxed{E[X] = \int_{-\infty}^\infty x f(x) dx},\]</span></p>
<p>La <strong>mediana</strong> es otra medida de centralización, y es el valor de la variable aleatoria que <em>divide</em> la probabilidad del espacio muestral en dos <strong>mitades</strong>. Por tanto, será el primer
valor de la variable aleatoria para el cual la función de distribución vale <span class="math inline">\(0.5\)</span>:</p>
<p><span class="math display">\[\mathit{Me}=\inf x : F(x)\geq 0.5.\]</span></p>
<p>En variables discretas a menudo la mediana se puede obtener simplemente de
la tabla de valores de <span class="math inline">\(F(x)\)</span>. Un método más general consiste en obtener la
función inversa de la función de distribución, <span class="math inline">\(F^{-1}(x)\)</span>, que estará en función de la probabilidad
acumulada, y sustituir la probabilidad por <span class="math inline">\(0.5\)</span>:</p>
<p><span class="math display">\[F(x) = p \iff x = F^{-1}(p) \implies Me = F^{-1}(0.5).\]</span>
Cuando no es posible despejar la <span class="math inline">\(x\)</span> hay que recurrir a métodos
numéricos para obtener la inversa de la función de distribución.
La figura <a href="vauni.html#fig:inversaF">5.15</a> muestra gráficamente la mediana
como inversa de la función de distribución en <span class="math inline">\(F(x) = 0.5\)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:inversaF"></span>
<img src="05-vauni_files/figure-html/inversaF-1.png" alt="La mediana a portir de la inversa de la función de distribución" width="70%"><p class="caption">
Figura 5.15: La mediana a portir de la inversa de la función de distribución
</p>
</div>
<p>Por último, la <strong>moda</strong> de una variable aleatoria es el valor donde la función de probabilidad o la función de densidad tienen su máximo. La moda puede no ser única, y en particular para variables continuas se suele hablar de distribuciones <em>bimodales</em> o
<em>multimodales</em> cuando tienen más de un máximo local (aunque solo uno de ellos sea
el máximo absoluto). En la figura <a href="vauni.html#fig:vacentra">5.16</a> se representan las tres medidas
de una determinada variable aleatoria con una determinada función de densidad. Nótese que en una distribución de probabilidad
asimétrica, como es la que se representa, la media se desplaza hacia la cola
más larga.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:vacentra"></span>
<img src="05-vauni_files/figure-html/vacentra-1.png" alt="Medidas de centralización de una variable aleatoria" width="70%"><p class="caption">
Figura 5.16: Medidas de centralización de una variable aleatoria
</p>
</div>

<div class="rmdejemplo">
<p>La media de la variable aleatoria <em>número de caras</em> del experimento
descrito más arriba y consistente en lanzar una moneda tres veces, es la siguiente:</p>
<p><span class="math display">\[\mu=E[X]=0\cdot \frac{1}{8}+1\cdot \frac{3}{8}+2\cdot \frac{3}{8}+3\cdot \frac{1}{8}=1.5.\]</span></p>
<p>Para obtener la mediana, miramos en la función de distribución
el primer valor para el que <span class="math inline">\(F(x)\ge 0.5\)</span>, y entonces la mediana es 1.
La moda es el valor más frecuente, mirando en la función de probabilidad vemos
que los valores 1 y 2 tienen la frecuencia más alta. Como vemos, la moda puede
no ser única (sí lo son siempre la media y la mediana.)</p>
</div>

<div class="rmdpractica">
<p><strong>HOJA DE CÁLCULO</strong></p>
<p>Disponemos los posibles valores de la variable <span class="math inline">\(x_i\)</span> en la primera columna,
las probabilidades en la segunda columna. En la tercera columna calculamos <span class="math inline">\(x_i\cdot p_i\)</span>,
y sumamos los valores.</p>
<p><strong>R</strong></p>
Podemos guardar los valores y sus probabilidades en sendos vectores y calcular la
esperanza calculando la suma del producto de ambos vectores, como se muestra en el siguiente código.
</div>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x_i</span> <span class="op">&lt;-</span> <span class="fl">0</span><span class="op">:</span><span class="fl">3</span></span>
<span><span class="va">p_i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">8</span>, <span class="fl">3</span><span class="op">/</span><span class="fl">8</span>, <span class="fl">3</span><span class="op">/</span><span class="fl">8</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">8</span><span class="op">)</span></span>
<span><span class="va">Ex</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x_i</span><span class="op">*</span><span class="va">p_i</span><span class="op">)</span></span>
<span><span class="va">Ex</span></span>
<span><span class="co">#&gt; [1] 1.5</span></span></code></pre></div>

<div class="rmdejemplo">
<p>La media de la variable aleatoria definida por la función de densidad:</p>
<p><span class="math display">\[f(x)=
\begin{cases}
\frac{1}{8}x \quad \text{si} \quad 0&lt;x&lt;4\\
0 \quad \quad \text{resto}
\end{cases}\]</span></p>
<p>Se calcula de la siguiente forma:</p>
<p><span class="math display">\[\mu=E[X]=\int_{-\infty}^\infty xf(x)dx = \int_{0}^4 \frac{1}{8}x^2 dx = \left [ \frac{x^3}{24} \right]_{0}^4=\frac{64}{24}=\frac{8}{3}\simeq 2.67.\]</span></p>
<p>Para obtener la mediana, tendríamos que obtener la inversa de la función
de distribución, <span class="math inline">\(F^{-1}(p)\)</span>, y sustituir <span class="math inline">\(p\)</span> por <span class="math inline">\(0.5\)</span>. En este caso es sencillo,
basta con despejar <span class="math inline">\(x\)</span> de la función de densidad (nos centramos solo en el tramo
donde la densidad es mayor de cero):</p>
<p><span class="math display">\[F(x) = p = \frac{x^2}{16} \iff x = F^{-1}(p) = +\sqrt{16p}\]</span>
Tomamos solo la raíz positiva puesto que sabemos que la variable está entre 0 y 4.
Entonces la mediana de esta variable aleatoria es:</p>
<p><span class="math display">\[F^{-1}(0.5) = +\sqrt{16\cdot 0.5} = 2\sqrt{2} \approx 2.8284.\]</span></p>
<p>En cuanto a la moda sería 4, ya que es el valor donde la función de densidad
es máximo, al ser una recta de pendiente positiva entre 0 y 4 (véase la figura <a href="vauni.html#fig:ejfdensidad">5.9</a>).</p>
</div>

<div class="rmdpractica">
<p><strong>MAXIMA</strong></p>
<p>La siguiente expresión devuelve el valor la integral definida con el resultado de la esperanza:</p>
<p><code>integrate(x*(1/8)*x, x, 0, 4);</code></p>
<p><strong>R</strong></p>
<p>El código a continuación obtiene la esperanza de la variable aleatoria.</p>
</div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">8</span><span class="op">)</span><span class="op">*</span><span class="va">x</span>, <span class="fl">0</span>, <span class="fl">4</span><span class="op">)</span></span>
<span><span class="co">#&gt; 2.666667 with absolute error &lt; 3e-14</span></span></code></pre></div>
<div class="rmdejemplo">
<p>
Vamos a calcular las medias de las variables aleatorias de los
ejemplos de sujetos en estudio. Para la variable aleatoria discreta:
</p>
<p>
<span class="math inline"><span class="math inline">\(X:\)</span></span> Número de mensajes remitidas
por correo electrónico en un año a los sujetos,
</p>
<p>
la media sería:
</p>
<p>
<span class="math display"><span class="math display">\[\mu=E[X]=\sum\limits_{i=1}^3 x_i p_i =
20\cdot \frac{36}{52} + 36 \cdot \frac{12}{52} +
60\cdot\frac{4}{52}\simeq26.7692.\]</span></span> Para la variable aleatoria
continua:
</p>
<p>
<span class="math inline"><span class="math inline">\(X:\)</span></span> Tiempo de duración de la
visita a la web de un sujeto,
</p>
<p>
la media sería:
</p>
<p>
<span class="math display"><span class="math display">\[\mu=E[X]=\int_{-\infty}^\infty x f(x) dx
= \int_{0}^\infty x \cdot 2 e^{-2x}dx = 0.5,\]</span></span>
</p>
<p>
resolviendo la integral por partes y aplicando la regla de
Barrow.
</p>
</div>

<div class="rmdpractica">
<p><strong>HOJA DE CÁLCULO</strong> (variable discreta)</p>
<p>Disponemos los posibles valores de la variable <span class="math inline">\(x_i\)</span> en la primera columna,
las probabilidades en la segunda columna. En la tercera columna calculamos <span class="math inline">\(x_i\cdot p_i\)</span>,
y sumamos los valores.</p>
<p><strong>MAXIMA</strong></p>
<p>La esperanza de la variable continua la podemos obtener con la siguiente
expresión:</p>
<p><code>integrate(x*2*exp(-2*x), x, 0, inf);</code></p>
<p><strong>R</strong></p>
Para la variable discreta, podemos guardar los valores y sus probabilidades en sendos vectores y calcular la
esperanza calculando la suma del producto de ambos vectores, como se muestra en el siguiente código. Para la variable continua, utilizamos la función <code>integrate</code> para calcular la integral. Nótese que se pueden usar límites infinitos.
</div>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x_i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">20</span>, <span class="fl">36</span>, <span class="fl">60</span><span class="op">)</span></span>
<span><span class="va">p_i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">36</span><span class="op">/</span><span class="fl">52</span>, <span class="fl">12</span><span class="op">/</span><span class="fl">52</span>, <span class="fl">4</span><span class="op">/</span><span class="fl">52</span><span class="op">)</span></span>
<span><span class="va">Ex</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x_i</span><span class="op">*</span><span class="va">p_i</span><span class="op">)</span></span>
<span><span class="va">Ex</span></span>
<span><span class="co">#&gt; [1] 26.76923</span></span></code></pre></div>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span><span class="op">*</span><span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="va">x</span><span class="op">)</span>, <span class="fl">0</span>, <span class="cn">Inf</span><span class="op">)</span></span>
<span><span class="co">#&gt; 0.5 with absolute error &lt; 8.6e-06</span></span></code></pre></div>
</div>
<div id="medidas-de-dispersión-de-una-variable-aleatoria" class="section level3" number="5.5.4">
<h3>
<span class="header-section-number">5.5.4</span> Medidas de dispersión de una variable aleatoria<a class="anchor" aria-label="anchor" href="#medidas-de-dispersi%C3%B3n-de-una-variable-aleatoria"><i class="fas fa-link"></i></a>
</h3>
<p>La <strong>varianza</strong> es el parámetro de dispersión de la variable aleatoria. Se define como el momento de orden 2 respecto de la media, y se representa por <span class="math inline">\(\sigma^2\)</span>.</p>
<p><span class="math display">\[V[X] = \sigma^2 = \mu_2 = E\left [(X- \mu)^2 \right ],\]</span></p>
<p>que para variables discretas se calcula como:</p>
<p><span class="math display">\[\sigma^2 = V[X] =  \sum\limits_{i} (x_i- \mu)^2 p(x_i),\]</span></p>
<p>y para variables continuas como:</p>
<p><span class="math display">\[\sigma^2 = V[X] = \int_{-\infty}^\infty (x-\mu)^2 f(x) dx.\]</span></p>
<p>Aplicando la relación entre los momentos respecto del origen y los momentos respecto de la media
de la ecuación <a href="vauni.html#eq:momentos">(5.3)</a> resulta que:</p>
<p><span class="math display">\[\mu_2 = \alpha_2-\alpha_1^2,\]</span></p>
<p>y podemos calcular la varianza con la siguiente expresión <em>abreviada</em>:</p>
<p><span class="math display">\[\boxed{\sigma^2= E[X^2] - E[X]^2},\]</span>
donde</p>
<p><span class="math display">\[\alpha_2=E[X^2]= \sum\limits_{i} x_i^2 p(x_i)\]</span>
para variables discretas y:</p>
<p><span class="math display">\[\alpha_2=E[X^2]= \int_{-\infty}^\infty x^2 f(x) dx\]</span>
para variables continuas.</p>
<p>La varianza de una variable aleatoria cumple además las siguientes <em>propiedades</em>:</p>
<ul>
<li>La varianza de una constante es nula:</li>
</ul>
<p><span class="math display">\[V[c] = 0.\]</span></p>
<ul>
<li>La varianza de una variable aleatoria es siempre positiva:</li>
</ul>
<p><span class="math display">\[V[X] \geq 0.\]</span></p>
<ul>
<li>Sea una variable aleatoria que es una transformación lineal de otra variable aleatoria. Entonces su varianza es:</li>
</ul>
<p><span class="math display">\[a, b \;\;\text{constantes} \implies \boxed{V[a + bX] = b^2 V[X]}.\]</span></p>
<p>Nótese la diferencia con la esperanza de la transformación lineal vista en la ecuación <a href="vauni.html#eq:tlesp">(5.2)</a>.</p>
<p>La <strong>desviación típica</strong> de la variable aleatoria es la raíz cuadrada positiva de la varianza. La desviación típica viene expresada en las mismas unidades que la variable aleatoria, mientras que la varianza está expresada en las unidades de la variable aleatoria al cuadrado.</p>
<p><span class="math display">\[\sigma = +\sqrt{V[X]}.\]</span></p>
<p>Una característica adimensional de la variabilidad es el <strong>coeficiente de variación</strong>, que es el cociente entre la desviación típica y la media de la variable aleatoria. Si la media fuera negativa, se suele expresar en valor absoluto:</p>
<p><span class="math display">\[\mathit{CV}= \frac{\sigma}{\mu}.\]</span></p>

<div class="rmdejemplo">
<p>Para calcular la varianza de la variable aleatoria <em>número de caras</em> del experimento consistente en lanzar una moneda tres veces, primero calculamos el momento de orden 2 respecto del origen:</p>
<p><span class="math display">\[\alpha_2=E[X^2] = 0^2\cdot \frac{1}{8}+1^2\cdot \frac{3}{8}+2^2\cdot \frac{3}{8}+3^2\cdot \frac{1}{8}=3.\]</span></p>
<p>Como ya sabíamos que la media era <span class="math inline">\(\mu=1.5\)</span>, entonces la varianza es:</p>
<p><span class="math display">\[\sigma^2=\alpha_2 -  \mu^2=3-\left(\frac{3}{2}\right )^2=\frac{3}{4}=0.75.\]</span></p>
<p>La desviación típica y el coeficiente de variación serán:
<span class="math display">\[\sigma = \sqrt{3/4} \simeq 0.8660;\; CV = \frac{\sigma}{\mu} \simeq 0.5774 \]</span></p>
<p>Para calcular la media de la variable aleatoria definida por la función de densidad:</p>
<p><span class="math display">\[f(x)=
\begin{cases}
\frac{1}{8}x \quad \text{si} \quad 0&lt;x&lt;4\\
0 \quad \quad \text{resto}
\end{cases}\]</span></p>
<p>calculamos también en primer lugar el momento de orden 2 respecto del origen,
en este caso a través de la integral:</p>
<p><span class="math display">\[\alpha_2=E[X^2]=\int_{-\infty}^\infty x^2f(x)dx = \int_{0}^4 \frac{1}{8}x^3 dx = \left [ \frac{x^4}{32} \right]_{0}^4=\frac{256}{32}=8.\]</span></p>
<p>Como la media era <span class="math inline">\(\mu=\frac{8}{3}\)</span>, la varianza es:</p>
<p><span class="math display">\[\sigma^2=\alpha_2 -  \mu^2=8-\left(\frac{8}{3}\right )^2=\frac{8}{9}\simeq 0.8889.\]</span></p>
La desviación típica y el coeficiente de variación serán:
<span class="math display">\[\sigma = \sqrt{8/9} \simeq 0.9428;\; CV = \frac{\sigma}{\mu} \simeq 0.3536 \]</span>
</div>

<div class="rmdpractica">
<p><strong>HOJA DE CÁLCULO (variable discreta)</strong></p>
<p>Si tenemos dispuestos los valores y probabilidades como se indicó más arriba,
podemos añadir dos columnas con el cálculo de <span class="math inline">\(x_i^2\)</span> y <span class="math inline">\(x_i^2 \cdot p_i\)</span> en cada fila, sumar esta última para obtener <span class="math inline">\(\alpha_2\)</span> y a continuación restarle
la media calculada anteriormente elevada al cuadrado, para obtener la varianza.</p>
<p><strong>MAXIMA</strong></p>
<p>Para la variable continua obtenemos <span class="math inline">\(\alpha_2\)</span> con la siguiente expresión,
y después podemos hacer operaciones para calcular todas las características:</p>
<p><code>integrate(x^2*(1/8)*x, x, 0, 4);</code></p>
<p><strong>R</strong></p>
El siguiente código realiza todos los cálculos para obtener los distintos parámetros de dispersión.
</div>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">alpha_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span><span class="op">^</span><span class="fl">2</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">8</span><span class="op">)</span><span class="op">*</span><span class="va">x</span>, <span class="fl">0</span>, <span class="fl">4</span><span class="op">)</span><span class="op">$</span><span class="va">value</span></span>
<span><span class="va">alpha_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">8</span><span class="op">)</span><span class="op">*</span><span class="va">x</span>, <span class="fl">0</span>, <span class="fl">4</span><span class="op">)</span><span class="op">$</span><span class="va">value</span></span>
<span><span class="va">varianza</span> <span class="op">&lt;-</span> <span class="va">alpha_2</span> <span class="op">-</span> <span class="va">alpha_1</span><span class="op">^</span><span class="fl">2</span>; <span class="va">varianza</span></span>
<span><span class="co">#&gt; [1] 0.8888889</span></span>
<span><span class="va">desv.tip</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">varianza</span><span class="op">)</span>; <span class="va">desv.tip</span></span>
<span><span class="co">#&gt; [1] 0.942809</span></span>
<span><span class="va">cv</span> <span class="op">&lt;-</span> <span class="va">desv.tip</span><span class="op">/</span><span class="va">alpha_1</span>; <span class="va">cv</span></span>
<span><span class="co">#&gt; [1] 0.3535534</span></span></code></pre></div>
<div class="rmdejemplo">
<p>
Vamos a calcular las varianzas de las variables aleatorias de los
ejemplos de sujetos en estudio. Para la variable aleatoria discreta:
</p>
<p>
<span class="math inline"><span class="math inline">\(X:\)</span></span> Número de mensajes remitidos
por correo electrónico en un año a los sujetos,
</p>
<p>
el momento de orden dos con respecto al origen sería:
</p>
<p>
<span class="math display"><span class="math display">\[\alpha_2=E[X^2]=\sum\limits_{i=1}^3
x_i^2 p_i = 20^2\cdot \frac{36}{52} + 36^2 \cdot \frac{12}{52} +
60^2\cdot\frac{4}{52}\simeq 852.9231.\]</span></span>
</p>
<p>
Y entonces, la varianza es:
</p>
<p>
<span class="math display"><span class="math display">\[\sigma^2=\alpha_2
-  \mu^2=852.9231-(26.7692)^2=136.333.\]</span></span>
</p>
<p>
Para la variable aleatoria continua:
</p>
<p>
<span class="math inline"><span class="math inline">\(X:\)</span></span> Tiempo de duración de la
visita a la web de un sujeto,
</p>
<p>
el momento de orden dos sería:
</p>
<p>
<span class="math display"><span class="math display">\[\alpha_2=E[X^2]=\int_{-\infty}^\infty
x^2 f(x) dx = \int_{0}^\infty x^2 \cdot 2 e^{-2x}dx = 0.5,\]</span></span>
</p>
<p>
y entonces la varianza es:
</p>
<p>
<span class="math display"><span class="math display">\[\sigma^2=\alpha_2
-  \mu^2=0.5-(0.5)^2=0.25.\]</span></span>
</p>
</div>

<div class="rmdpractica">
<p><strong>HOJA DE CÁLCULO (discreta)</strong></p>
<p>Procederíamos igual que en el ejemplo anterior, calculando en columnas,
sumando totales y finalmente aplicando la fórmula.</p>
<p><strong>MAXIMA</strong></p>
<p>La siguiente expresión calcularía <span class="math inline">\(\alpha_2\)</span>, y a partir de ahí se
aplican las fórmulas para obtener los distintos parámetros.</p>
<p><code>integrate(x^2*2*exp(-2*x), x, 0, inf);</code></p>
<p><strong>R</strong></p>
El código a continuación calcula la varianza de la variable
aleatoria de forma análoga
al ejemplo anterior.
</div>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">alpha_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span><span class="op">^</span><span class="fl">2</span><span class="op">*</span><span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="va">x</span><span class="op">)</span>, <span class="fl">0</span>, <span class="cn">Inf</span><span class="op">)</span><span class="op">$</span><span class="va">value</span></span>
<span><span class="va">alpha_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span><span class="op">*</span><span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="va">x</span><span class="op">)</span>, <span class="fl">0</span>, <span class="cn">Inf</span><span class="op">)</span><span class="op">$</span><span class="va">value</span></span>
<span><span class="va">varianza</span> <span class="op">&lt;-</span> <span class="va">alpha_2</span> <span class="op">-</span> <span class="va">alpha_1</span><span class="op">^</span><span class="fl">2</span>; <span class="va">varianza</span></span>
<span><span class="co">#&gt; [1] 0.25</span></span></code></pre></div>

<div class="rmdejemplo">
<p>A partir de la variable aleatoria anterior:</p>
<p><span class="math inline">\(X:\)</span> Tiempo de duración de la visita a la web de un sujeto,</p>
<p>supongamos que esta visita se produce siempre después de haber visto un
anuncio de 10 segundos, y queremos estudiar la variable:</p>
<p><span class="math inline">\(Y:\)</span> Tiempo total de conexión con el servidor en segundos.</p>
<p>Esta nueva variable aleatoria se puede expresar como:</p>
<p><span class="math display">\[Y = 10 + 60 \cdot X\]</span></p>
<p>y tendrá una determinada distribución de
probabilidad cuya determinación no se trata en este texto. En cualquier caso,
a través de las propiedades de la esperanza y la varianza, sí podemos
calcular el valor de estas características para la nueva distribución.
Así:</p>
<p><span class="math display">\[E[Y] = 10 + 60 \cdot E[X] = 10 + 60 \cdot 0.5 = 40,\]</span>
<span class="math display">\[V[Y] =60^2 \cdot V[X] = 60^2 \cdot 0.5 = 1800.\]</span></p>
</div>
</div>
<div id="variable-aleatoria-estandarizada" class="section level3" number="5.5.5">
<h3>
<span class="header-section-number">5.5.5</span> Variable aleatoria estandarizada<a class="anchor" aria-label="anchor" href="#variable-aleatoria-estandarizada"><i class="fas fa-link"></i></a>
</h3>
<p>La última de las propiedades de la varianza enumeradas anteriormente, es decir:</p>
<p><span class="math display">\[a, b \;\;\text{constantes}, Y=a+bX \implies V[Y] = b^2 V[X],\]</span></p>
<p>nos va a permitir <em>escalar</em> cualquier variable aleatoria transformándola en otra que tenga desviación típica igual a uno. Efectivamente, si en la transformación lineal anterior hacemos <span class="math inline">\(b=\frac{1}{\sigma}\)</span>:</p>
<p><span class="math display">\[V[Y]=\left(\frac{1}{\sigma}\right)^2 \cdot\sigma^2=1.\]</span></p>
<p>Si aplicamos esta transformación a una variable aleatoria centrada <span class="math inline">\(X-\mu\)</span>, entonces tenemos una <strong>variable aleatoria estandarizada</strong> con media cero y desviación típica 1 y que normalmente se denota por <span class="math inline">\(Z\)</span>:</p>
<p><span class="math display">\[Z=\frac{X-\mu}{\sigma}\implies \mu_Z=0;\; \sigma_Z=1.\]</span></p>
<p>Utilizaremos esta transformación para realizar cálculo de probabilidades del modelo de distribución normal en el capítulo <a href="modelos.html#modelos">7</a>. Además, tiene mucho interés en Estadística inferencial y en técnicas multivariantes que no se tratan en este texto.</p>
</div>
<div id="otros-parámetros" class="section level3" number="5.5.6">
<h3>
<span class="header-section-number">5.5.6</span> Otros parámetros<a class="anchor" aria-label="anchor" href="#otros-par%C3%A1metros"><i class="fas fa-link"></i></a>
</h3>
<p>Al igual que se definió la mediana, podemos definir cualquier <strong>cuantil</strong> <span class="math inline">\(X_p\)</span> para una
probabilidad dada:</p>
<p><span class="math display">\[X_{p}= \inf x: F(x)\leq p\]</span></p>
<p>Por ejemplo, los cuantiles <span class="math inline">\(0.25\)</span> y <span class="math inline">\(0.75\)</span> serían los valores
<span class="math inline">\(X_{0.25}\)</span> y <span class="math inline">\(X_{0.75}\)</span> que dejan por debajo una probabilidad de <span class="math inline">\(0.25\)</span> y <span class="math inline">\(0.75\)</span> respectivamente<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;A estos valores se les conoce como cuartiles&lt;/p&gt;"><sup>65</sup></a>.
El método más general para calcular cualquier cuantil consiste en obtener
la inversa de la función de distribución <span class="math inline">\(x = F^{-1}(p)\)</span> y dar valores a
<span class="math inline">\(p\)</span> (véase el ejemplo de la mediana más arriba).
La figura <a href="vauni.html#fig:cuartil">5.17</a> muestra la representación del cuantil 0.75
en relación con una determinada función de densidad.</p>
<p>También se pueden calcular a partir de los momentos otros parámetros como los coeficientes de asimetría y de curtosis de una variable aleatoria, que no se tratan en este texto.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:cuartil"></span>
<img src="05-vauni_files/figure-html/cuartil-1.png" alt="Cuantiles de una variable aleatoria" width="70%"><p class="caption">
Figura 5.17: Cuantiles de una variable aleatoria
</p>
</div>
</div>
<div id="desigualdad-de-chebyshev" class="section level3" number="5.5.7">
<h3>
<span class="header-section-number">5.5.7</span> Desigualdad de Chebyshev<a class="anchor" aria-label="anchor" href="#desigualdad-de-chebyshev"><i class="fas fa-link"></i></a>
</h3>
<p>En ocasiones, es posible que conozcamos la media, <span class="math inline">\(\mu\)</span>, y la varianza, <span class="math inline">\(\sigma^2\)</span>, de una variable aleatoria, pero no conozcamos nada sobre su distribución de probabilidad. En estos casos, no podemos calcular la probabilidad en un intervalo, pero podemos acotar la probabilidad entre dos valores entorno a la media conocida. La fórmula general para
esta acotación es la siguiente:</p>
<p><span class="math display">\[P[|X-\mu|\geq k\sigma] \leq \frac{1}{k^2},\]</span>
conocida como <strong>desigualdad de Chebyshev</strong><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Podemos encontrar diversas grafías del apellido de este matemático ruso (1821-1894) como Chebyshov, Tchebychev, Tchebycheff, Tschebyscheff, Chebyshev o Čebišëv.&lt;/p&gt;"><sup>66</sup></a> y que nos permite acotar la probabilidad de una variable aleatoria de dos formas:</p>
<ul>
<li>La probabilidad de que la variable aleatoria tome valores más extremos de <span class="math inline">\(k\)</span> desviaciones típicas desde la media es, como mucho, <span class="math inline">\(\frac{1}{k^2}\)</span>, véase la figura <a href="vauni.html#fig:cheby">5.18</a>:</li>
</ul>
<p><span class="math display">\[P[\mu-k\sigma \geq X \geq \mu+k\sigma] \leq \frac{1}{k^2}.\]</span></p>
<ul>
<li>La probabilidad de que la variable aleatoria tome valores dentro de <span class="math inline">\(k\)</span> desviaciones típicas desde la media es, como poco, <span class="math inline">\(1-\frac{1}{k^2}\)</span>, véase la figura <a href="vauni.html#fig:cheby2">5.19</a>:</li>
</ul>
<p><span class="math display">\[P[\mu-k\sigma &lt; X &lt; \mu+k\sigma] \geq 1- \frac{1}{k^2}.\]</span>
Si lo que queremos es acotar la probabilidad para un valor concreto <span class="math inline">\(x\)</span>, entonces podemos encontrar primero <span class="math inline">\(k\)</span> despejando de <span class="math inline">\(\mu+k\sigma=x\)</span> y después aplicar las propiedades de la probabilidad para encontrar una cota.</p>
<p>De la desigualdad de Chebyshev se deduce que, por ejemplo, para cualquier variable aleatoria la probabilidad de que esa variable aleatoria tome valores entre su media y dos desviaciones típicas es de, al menos, <span class="math inline">\(0.75\)</span>:</p>
<p><span class="math display">\[P[\mu-2\sigma &lt; X &lt; \mu+2\sigma] \geq 1- \frac{1}{2^2}=0.75.\]</span>
También podemos determinar mediante esta desigualdad, entre qué valores estará, al menos, una determinada probabilidad.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:cheby"></span>
<img src="05-vauni_files/figure-html/cheby-1.png" alt="Cota superior externa Desigualdad de Chebyshev" width="70%"><p class="caption">
Figura 5.18: Cota superior externa Desigualdad de Chebyshev
</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:cheby2"></span>
<img src="05-vauni_files/figure-html/cheby2-1.png" alt="Cota inferior interna Desigualdad de Chebyshev" width="70%"><p class="caption">
Figura 5.19: Cota inferior interna Desigualdad de Chebyshev
</p>
</div>

<div class="rmdejemplo">
<p>Se sabe que la media de una variable aleatoria es 9 y su varianza 4. ¿Entre qué dos valores tendremos, al menos, una probabilidad de 0.75?</p>
<p>De la propiedad que acabamos de ver, esto se cumple para <span class="math inline">\(k=2\)</span>, y por tanto esos valores serán <span class="math inline">\(\mu\pm 2\sigma=9\pm 2 \cdot \sqrt{4} = [5, 13].\)</span></p>
<p>¿Entre qué valores tendremos una probabilidad de, al menos, 0.84?</p>
<p>Para contestar a esta pregunta, calculamos primero <span class="math inline">\(k\)</span> teniendo en cuenta:</p>
<p><span class="math display">\[P[\mu-k\sigma &lt; X &lt; \mu+k\sigma] \geq 1- \frac{1}{k^2} \implies 1- \frac{1}{k^2}=0.84 \implies k=2.5,\]</span>
y calculamos los valores como:</p>
<p><span class="math display">\[\mu \pm k\sigma = 9 \pm 2.5\cdot\sqrt{4} = [4,\; 14].\]</span>
Entre <span class="math inline">\(4\)</span> y <span class="math inline">\(14\)</span> tendremos, al menos, una probabilidad de <span class="math inline">\(0.84\)</span>. Y
a la inversa, más allá de estos valores tendremos, como mucho, una
probabilidad de <span class="math inline">\(0.16\)</span>.</p>
<p>¿Cuál sería la probabilidad de que esta variable aleatoria tome valores mayores de 15?</p>
<p>No podemos contestar exactamente a esta pregunta puesto que no disponemos de la distribución de probabilidad. Pero sí podemos dar una cota de dicha probabilidad. En este caso tenemos que obtener <span class="math inline">\(k\)</span> sabiendo cuánto vale
<span class="math inline">\(\mu + k\sigma\)</span>:</p>
<p><span class="math display">\[\mu + k\sigma = 15 \iff k = \frac{15-9}{2}=3\]</span></p>
<p>Entonces:</p>
<p><span class="math display">\[P[9-3\cdot 2 &gt; X &gt; 9+3\cdot 2] \le \frac{1}{k^2} \iff P[3 &gt; X &gt; 15] \le \frac{1}{9} \approx 0.1111\]</span></p>
<p>Nótese que esto significa que:</p>
<p><span class="math display">\[P[X \le 3] + P[X \ge 15] \le 0.1111,\]</span></p>
y por tanto si la suma de dos números es menor que 0.1111, entonces cada uno de ellos será como mucho ese valor, y podemos asegurar que la probabilidad de que esta variable aleatoria con media 9 y varianza 4 tome valores de 15 es menor de 0.1111.
</div>

</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="introp.html"><span class="header-section-number">4</span> Introducción a la Probabilidad</a></div>
<div class="next"><a href="vabi.html"><span class="header-section-number">6</span> Variable aleatoria bivariante</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="Índice capítulo"><h2>Índice capítulo</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#vauni"><span class="header-section-number">5</span> Variable aleatoria univariante</a></li>
<li>
<a class="nav-link" href="#concepto-y-definici%C3%B3n-de-variable-aleatoria"><span class="header-section-number">5.1</span> Concepto y definición de variable aleatoria</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#tipos-de-variables-aleatorias"><span class="header-section-number">5.1.1</span> Tipos de variables aleatorias</a></li>
<li><a class="nav-link" href="#operaciones-con-variables-aletorias"><span class="header-section-number">5.1.2</span> Operaciones con variables aletorias</a></li>
<li><a class="nav-link" href="#variables-aleatorias-y-conjuntos"><span class="header-section-number">5.1.3</span> Variables aleatorias y conjuntos</a></li>
</ul>
</li>
<li><a class="nav-link" href="#funci%C3%B3n-de-distribuci%C3%B3n"><span class="header-section-number">5.2</span> Función de distribución</a></li>
<li>
<a class="nav-link" href="#sec:vadi"><span class="header-section-number">5.3</span> Variable aleatoria discreta</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#funci%C3%B3n-de-probabilidad"><span class="header-section-number">5.3.1</span> Función de probabilidad</a></li></ul>
</li>
<li>
<a class="nav-link" href="#variable-aleatoria-continua"><span class="header-section-number">5.4</span> Variable aleatoria continua</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#funci%C3%B3n-de-densidad"><span class="header-section-number">5.4.1</span> Función de densidad</a></li></ul>
</li>
<li>
<a class="nav-link" href="#caracter%C3%ADsticas-de-una-variable-aleatoria"><span class="header-section-number">5.5</span> Características de una variable aleatoria</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#esperanza-matem%C3%A1tica"><span class="header-section-number">5.5.1</span> Esperanza Matemática</a></li>
<li><a class="nav-link" href="#momentos-de-variables-aleatorias-unidimensionales"><span class="header-section-number">5.5.2</span> Momentos de variables aleatorias unidimensionales</a></li>
<li><a class="nav-link" href="#medidas-de-centralizaci%C3%B3n-de-una-variable-aleatoria"><span class="header-section-number">5.5.3</span> Medidas de centralización de una variable aleatoria</a></li>
<li><a class="nav-link" href="#medidas-de-dispersi%C3%B3n-de-una-variable-aleatoria"><span class="header-section-number">5.5.4</span> Medidas de dispersión de una variable aleatoria</a></li>
<li><a class="nav-link" href="#variable-aleatoria-estandarizada"><span class="header-section-number">5.5.5</span> Variable aleatoria estandarizada</a></li>
<li><a class="nav-link" href="#otros-par%C3%A1metros"><span class="header-section-number">5.5.6</span> Otros parámetros</a></li>
<li><a class="nav-link" href="#desigualdad-de-chebyshev"><span class="header-section-number">5.5.7</span> Desigualdad de Chebyshev</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/emilopezcano/estadistica-ciencias-ingenieria/blob/master/05-vauni.Rmd">Ver fuente <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/emilopezcano/estadistica-ciencias-ingenieria/edit/master/05-vauni.Rmd">Editar esta página <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Estadística Aplicada a las Ciencias y la Ingeniería</strong>" escrito por <a href="http://emilio.lcano.com" class="text-light">Emilio L. Cano</a>. Generado por última vez el día 2022-07-17.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Este libro ha sido generado con el paquete de R <a class="text-light" href="https://bookdown.org">bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
